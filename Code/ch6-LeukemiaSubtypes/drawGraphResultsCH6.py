import matplotlib.pyplot as plt

def Average(lst): 
    return sum(lst) / len(lst) 

def getList(list1, list2, list3, list4, list5, index):
	return [list1[index], list2[index], list3[index], list4[index], list5[index]]

def createListToAverage(list1, list2, list3, list4, list5): 
	myFinalList = []
	for i in range(len(list1)):
		myFinalList.append(Average(getList(list1, list2, list3, list4, list5, i)))
	return myFinalList


# ----------------------------------------------------------------------------
# ==> UNCOMMENT THE DESIRED PART TO DRAW THE GRAPH RESULTS OF THE EXPERIMENT 
# ----------------------------------------------------------------------------

# ---- ALL IDB 1 ------ 

# Baseline results (no dropout, no data augmentation) with color 

'''
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.3181818127632141, 0.3181818127632141, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859]
accuracy_2 = [0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.6363636255264282, 0.6818181872367859, 0.3636363744735718, 0.6818181872367859, 0.6818181872367859, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.5909090638160706, 0.4545454680919647, 0.3636363744735718, 0.5454545617103577, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282]
accuracy_3 = [0.40909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.6363636255264282, 0.6363636255264282, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.6363636255264282, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706]
accuracy_4 = [0.5454545617103577, 0.5, 0.5, 0.5, 0.5909090638160706, 0.6363636255264282, 0.5, 0.5, 0.5, 0.5, 0.5909090638160706, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6818181872367859, 0.6818181872367859, 0.6363636255264282]
accuracy_5 = [0.7272727489471436, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3181818127632141, 0.3181818127632141, 0.3181818127632141, 0.3181818127632141, 0.3181818127632141, 0.3181818127632141, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.4545454680919647, 0.7272727489471436, 0.7272727489471436, 0.7272727489471436, 0.7272727489471436, 0.7272727489471436, 0.7272727489471436, 0.7272727489471436, 0.7272727489471436, 0.7272727489471436, 0.7272727489471436, 0.7272727489471436]
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3,color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB1 test set using baseline')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [10.860726356506348, 10.989609718322754, 5.128484725952148, 3.4271066188812256, 5.128484725952148, 5.128484725952148, 5.128484725952148, 5.128484725952148, 5.128484725952148, 5.128484725952148, 5.128484725952148, 5.013681888580322, 4.877547740936279, 4.74442195892334, 5.128484725952148, 5.128484725952148, 5.128484725952148, 5.128484725952148, 5.064172744750977, 4.8915557861328125, 4.777514934539795, 4.633288860321045, 4.446059703826904, 4.06113338470459, 3.5315287113189697]
loss_2 = [10.256969451904297, 10.256969451904297, 10.256969451904297, 5.861125469207764, 0.5555139780044556, 1.9634205102920532, 0.5979896187782288, 0.5218682885169983, 2.0946290493011475, 2.434819459915161, 1.3444393873214722, 0.9758774042129517, 4.489085674285889, 6.435612678527832, 1.0361485481262207, 5.861125469207764, 5.861125469207764, 5.861125469207764, 4.110635757446289, 1.2575827836990356, 0.9331750273704529, 1.4974989891052246, 5.861125469207764, 5.861125469207764, 5.861125469207764]
loss_3 = [8.923234939575195, 6.518603324890137, 3.0646398067474365, 3.6687185764312744, 2.206103563308716, 1.2324050664901733, 0.8592746257781982, 4.740390300750732, 6.593766689300537, 6.593766689300537, 6.593766689300537, 6.593766689300537, 6.593766689300537, 6.593766689300537, 6.593766689300537, 6.593766689300537, 6.593766689300537, 6.593766689300537, 4.877714157104492, 0.7397823333740234, 0.5848303437232971, 1.5807124376296997, 5.068933010101318, 6.593766689300537, 6.5507707595825195]
loss_4 = [4.069908142089844, 8.05904769897461, 7.317843437194824, 6.302114486694336, 4.6861066818237305, 3.741422176361084, 8.05904769897461, 8.05904769897461, 7.548720836639404, 6.511351108551025, 2.2456750869750977, 1.7538944482803345, 1.6938934326171875, 1.3235936164855957, 0.8836476802825928, 0.7812187671661377, 0.8503684401512146, 1.3233282566070557, 2.166358232498169, 2.4086432456970215, 2.137887716293335, 1.3554469347000122, 0.6184871196746826, 0.5250462889671326, 0.5504066348075867]
loss_5 = [1.1889376640319824, 10.19235897064209, 9.870301246643066, 8.553719520568848, 10.989609718322754, 10.555326461791992, 10.412962913513184, 10.311490058898926, 10.989609718322754, 10.730525970458984, 6.925204753875732, 4.0957183837890625, 3.781385898590088, 1.529961109161377, 0.5184679627418518, 0.8967580199241638, 0.9118385314941406, 0.7962351441383362, 0.7575719952583313, 0.8181332945823669, 0.8468183279037476, 0.9145693182945251, 0.9964994788169861, 0.9632871747016907, 0.8269202709197998]
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3,color='black')

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALL-IDB1 test set using baseline')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.5930232488831808, 0.8372092967809632, 0.9534883720930233, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_2 = [0.5697674432466197, 0.7441860437393188, 0.9069767511168192, 0.9883720888647922, 0.976744181888048, 1.0, 0.9767441860465116, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9883720888647922, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_3 = [0.5930232488831808, 0.8139534897582476, 0.8604651107344516, 1.0, 0.9883720930232558, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_4 = [0.5813953502233639, 0.8604651218236878, 0.8372093009394269, 0.9302325539810713, 0.9883720930232558, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9883720930232558, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_5 = [0.5232558153396429, 0.872093023255814, 0.9651162749113038, 1.0, 1.0, 1.0, 0.9534883707068688, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)

plt.plot(x_values, acc_train_1, label="Run 1")
plt.plot(x_values, acc_train_2, label="Run 2")
plt.plot(x_values, acc_train_3, label="Run 3") 
plt.plot(x_values, acc_train_4, label="Run 4") 
plt.plot(x_values, acc_train_5, label="Run 5")  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB1 train set using baseline')
plt.legend(loc='best')
plt.show()
'''

# ---------------------------------------------------------------------- 

# Dropout with color 

# Accuracy 
'''
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.6363636255264282, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706]
accuracy_2 = [0.5909090638160706, 0.5454545617103577, 0.4545454680919647, 0.4545454680919647, 0.7272727489471436, 0.5909090638160706, 0.5909090638160706, 0.6818181872367859, 0.7272727489471436, 0.7272727489471436, 0.8181818127632141, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.8181818127632141, 0.4545454680919647, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.40909090638160706]
accuracy_3 = [0.5454545617103577, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.5, 0.5, 0.7727272510528564, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]
accuracy_4 = [0.5909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.7727272510528564, 0.7272727489471436, 0.5, 0.7272727489471436, 0.7727272510528564, 0.6818181872367859, 0.5909090638160706, 0.5909090638160706, 0.6818181872367859, 0.6818181872367859, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.6818181872367859, 0.6818181872367859, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706]
accuracy_5 = [0.6363636255264282, 0.6363636255264282, 0.5454545617103577, 0.6363636255264282, 0.3636363744735718, 0.40909090638160706, 0.6818181872367859, 0.6363636255264282, 0.5454545617103577, 0.40909090638160706, 0.40909090638160706, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282]
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB1 test set using dropout = 0.1')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [8.05904769897461, 8.05904769897461, 8.05904769897461, 2.5631890296936035, 2.0428717136383057, 8.05904769897461, 3.459536552429199, 8.05904769897461, 0.7169586420059204, 0.5791741013526917, 1.8455383777618408, 2.0623834133148193, 1.8441524505615234, 1.9960980415344238, 2.6576852798461914, 2.3452253341674805, 1.9624005556106567, 1.5233845710754395, 1.3327370882034302, 1.3986053466796875, 1.2993663549423218, 0.9717216491699219, 0.8888998627662659, 0.9445068836212158, 1.0709928274154663]
loss_2 = [6.593766689300537, 0.7411497235298157, 1.128179669380188, 0.9282355904579163, 0.5317974090576172, 0.5864481329917908, 0.9755628705024719, 0.555095911026001, 0.541374146938324, 0.5357537865638733, 0.5129740238189697, 0.5907649397850037, 0.8042030930519104, 1.1990290880203247, 2.0767555236816406, 2.4036948680877686, 3.817147970199585, 4.723072528839111, 1.1356868743896484, 0.6693211793899536, 1.0639424324035645, 4.771357536315918, 2.4453868865966797, 2.0367956161499023, 9.52432918548584]
loss_3 = [0.7234945297241211, 0.9710228443145752, 1.7401707172393799, 8.05904769897461, 1.505240559577942, 2.0109293460845947, 1.7085576057434082, 1.0716720819473267, 0.8757418990135193, 0.859067976474762, 0.8167935013771057, 2.40164852142334, 1.2370549440383911, 0.4826163053512573, 1.7045142650604248, 1.7801467180252075, 2.095665216445923, 2.0580179691314697, 1.9861549139022827, 1.923364520072937, 1.912440538406372, 1.9631695747375488, 1.8388237953186035, 1.4246726036071777, 8.05904769897461]
loss_4 = [6.4952497482299805, 0.9723514318466187, 3.2213475704193115, 9.52432918548584, 0.7040002942085266, 0.582131564617157, 0.530444860458374, 0.7220636010169983, 0.5952973365783691, 0.561686098575592, 1.2962807416915894, 5.579890251159668, 3.580796718597412, 0.8587595224380493, 0.6827843189239502, 9.52432918548584, 2.512392997741699, 1.237767219543457, 0.9551165103912354, 2.579209089279175, 6.593766689300537, 5.927389144897461, 6.08464241027832, 6.254020690917969, 6.111974716186523]
loss_5 = [5.861125469207764, 5.861125469207764, 0.7602820992469788, 0.5991165041923523, 3.6657559871673584, 1.1784181594848633, 0.5998011231422424, 0.6424077749252319, 0.7185759544372559, 0.9822999835014343, 1.0905251502990723, 5.861125469207764, 2.7164976596832275, 1.6136317253112793, 1.1950600147247314, 1.3760441541671753, 1.3352590799331665, 1.5680568218231201, 3.2918927669525146, 3.5896637439727783, 3.064586877822876, 3.0461220741271973, 5.383739948272705, 4.526933670043945, 4.153433799743652]
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALL-IDB1 test set using dropout = 0.1')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.6279069822888041, 0.5930232502693353, 0.6162790628366692, 0.720930231171985, 0.6860465102417524, 0.6627906921298005, 0.6860465046971344, 0.6162790642228237, 0.5930232599724171, 0.5000000034653863, 0.6511627879253653, 0.5697674390881561, 0.6976744116738786, 0.5813953529956729, 0.6744186060373173, 0.6627906990605731, 0.7093023200367772, 0.6976744130600331, 0.6976744241492693, 0.7674418549204982, 0.6627906949021095, 0.6627906921298005, 0.7209302270135214, 0.7093023269675499, 0.6279069809026496]
acc_train_2 = [0.5581395341906437, 0.5930232613585716, 0.5813953488372093, 0.7209302339442941, 0.755813947943754, 0.6627907032190368, 0.6976744172184967, 0.5813953419064366, 0.6511627879253653, 0.6395348809486212, 0.6046511669491612, 0.6860465088555979, 0.7093023228090863, 0.651162792083829, 0.7441860409670098, 0.604651166256084, 0.6976744130600331, 0.6976744241492693, 0.7441860395808553, 0.7209302339442941, 0.6162790642228237, 0.6279069698134134, 0.5813953488372093, 0.5581395348837209, 0.5813953502233639]
acc_train_3 = [0.5813953460649003, 0.5697674446327742, 0.6511627879253653, 0.546511631372363, 0.5232558153396429, 0.5813953488372093, 0.5465116320654403, 0.5348837209302325, 0.6162790690743646, 0.5232558111811794, 0.6046511600183886, 0.5697674390881561, 0.5465116251346677, 0.627906976744186, 0.6162790739259054, 0.5930232572001081, 0.6511627934699835, 0.5697674411673879, 0.5930232592793399, 0.6976744172184967, 0.5813953502233639, 0.6860465060832889, 0.5697674453258514, 0.5930232558139535, 0.5465116272138995]
acc_train_4 = [0.5813953432925912, 0.651162792083829, 0.5813953488372093, 0.5813953419064366, 0.6976744199908057, 0.5465116279069767, 0.5697674390881561, 0.6046511669491612, 0.6511627851530563, 0.6744185991065447, 0.6279069822888041, 0.6627906907436459, 0.6395348878793938, 0.7093023186506227, 0.6976744241492693, 0.7441860409670098, 0.6860465130140615, 0.6162790628366692, 0.6627906949021095, 0.6627906907436459, 0.5813953432925912, 0.6976744158323421, 0.6744186101957809, 0.6860465171725251, 0.604651155859925]
acc_train_5 = [0.5930232613585716, 0.6279069781303406, 0.686046514400216, 0.6395348878793938, 0.6627906990605731, 0.627906973971877, 0.5813953523025956, 0.6511627837669017, 0.651162794856138, 0.6162790683812873, 0.6511627851530563, 0.6744186060373173, 0.6395348809486212, 0.6511627837669017, 0.6744185977203901, 0.5930232530416444, 0.5930232530416444, 0.7093023269675499, 0.6744185977203901, 0.6627906921298005, 0.6279069802095724, 0.7209302381027577, 0.6627906976744186, 0.6860465088555979, 0.7325581423071927]
avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)

plt.plot(x_values, acc_train_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, acc_train_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, acc_train_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, acc_train_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, acc_train_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB1 train set using dropout = 0.1')
plt.legend(loc='best')
plt.show() 
'''

# ---------------------------------------------------------------------- 

# Data aug results with color 
'''
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.6363636417822405, 0.7272727218541232, 0.6363636417822405, 0.6363636417822405, 0.6363636417822405, 0.7045454545454546, 0.5454545454545454, 0.75, 0.6818181872367859, 0.6590909145095132, 0.6363636417822405, 0.6363636417822405, 0.6363636417822405, 0.6363636417822405, 0.6363636417822405, 0.7272727326913313, 0.5000000054186041, 0.5000000054186041, 0.7272727326913313, 0.6363636417822405, 0.6363636417822405, 0.6363636417822405, 0.6363636417822405, 0.6363636417822405, 0.7272727326913313]
accuracy_2 = [0.5, 0.5454545400359414, 0.43181817910887976, 0.4545454518361525, 0.4545454518361525, 0.4545454518361525, 0.5227272727272727, 0.6590909145095132, 0.5, 0.5227272727272727, 0.5, 0.36363636634566565, 0.5227272727272727, 0.5227272727272727, 0.5909090854904868, 0.5227272727272727, 0.5, 0.47727272456342523, 0.5, 0.5, 0.5, 0.6136363582177595, 0.6136363582177595, 0.6136363582177595, 0.8181818181818182]
accuracy_3 = [0.43181817910887976, 0.5909090909090909, 0.43181817910887976, 0.43181817910887976, 0.43181817910887976, 0.43181817910887976, 0.43181817910887976, 0.43181817910887976, 0.43181817910887976, 0.43181817910887976, 0.43181817910887976, 0.43181817910887976, 0.49999999729069794, 0.7045454599640586, 0.5454545454545454, 0.5227272727272727, 0.43181817910887976, 0.5681818127632141, 0.5681818127632141, 0.5681818127632141, 0.659090903672305, 0.6136363636363636, 0.5681818127632141, 0.5227272727272727, 0.659090903672305]
accuracy_4 = [0.5454545427452434, 0.6136363582177595, 0.45454545454545453, 0.5454545454545454, 0.45454544912685046, 0.45454545454545453, 0.5454545427452434, 0.5454545427452434, 0.5454545427452434, 0.5681818154725161, 0.4772727272727273, 0.45454545454545453, 0.43181817910887976, 0.6136363636363636, 0.5454545427452434, 0.5454545427452434, 0.5909090909090909, 0.5909090909090909, 0.5681818181818182, 0.5909090909090909, 0.5909090881997888, 0.6136363609270616, 0.6363636336543343, 0.6363636336543343, 0.6363636336543343]
accuracy_5 = [0.4090909118002111, 0.43181818452748383, 0.43181818452748383, 0.590909096327695, 0.5681818236004222, 0.590909096327695, 0.590909096327695, 0.590909096327695, 0.590909096327695, 0.590909096327695, 0.590909096327695, 0.590909096327695, 0.8181818236004222, 0.6818181818181818, 0.6818181818181818, 0.7499999945813959, 0.590909096327695, 0.6136363582177595, 0.5909090854904868, 0.6818181872367859, 0.6590909145095132, 0.500000002709302, 0.7499999945813959, 0.7727272673086687, 0.7727272673086687]
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB1 test set using data augmentation')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [3.868530945344405, 0.6748220974748785, 5.861125555905429, 1.345178246498108, 1.3813102462074973, 0.5674765651876276, 0.8309580412777987, 0.5231284390796315, 1.2840051325884732, 1.6313133348118176, 5.861125555905429, 5.861125555905429, 5.6806300336664375, 5.8290370160883125, 3.3338136672973633, 0.5415563583374023, 1.5764798792925747, 2.2329009771347046, 0.7978036891330372, 3.388523643667048, 5.65629261190241, 5.653054627505216, 3.810036550868641, 4.665354772047563, 1.1780800277536565]
loss_2 = [8.05904769897461, 0.7221690253777937, 1.4276494979858398, 2.455242785540494, 2.384993163022128, 1.5073993747884578, 7.692727522416548, 5.494805032556707, 4.798712123524059, 1.352008266882463, 6.073975172909823, 2.4468127380717886, 1.1326322663914075, 0.888973284851421, 0.6141975792971525, 1.3437939232045955, 2.021380229429765, 3.174787629734386, 2.7651098424738105, 2.032957142049616, 1.4181485717946833, 0.6779254512353377, 0.6076381640000776, 0.5869145555929705, 0.46458201516758313]
loss_3 = [9.050460728732022, 1.3661441261118108, 5.926965149966153, 8.250320868058639, 5.136569499969482, 4.216999704187566, 4.641525571996516, 8.01225098696622, 3.880170778794722, 5.324751290408048, 3.2073036540638316, 2.652306643399325, 1.6746545921672473, 0.7916329773989591, 1.337489745833657, 0.6272176558321173, 2.4020505168221216, 5.8233160972595215, 6.603900909423828, 6.1693642356178975, 0.9228822968222878, 0.9717051441019232, 6.181481101296165, 2.7807882699099453, 1.2572992064736106]
loss_4 = [6.410077875310725, 1.6262173652648926, 4.236257206309926, 1.5847833915190264, 2.1759433204477485, 2.2657463550567627, 3.4148243990811435, 2.152336012233387, 3.730186115611683, 1.1205104372718118, 3.45540469343012, 2.5446241335435347, 1.2330391623757102, 0.847901463508606, 1.3321059400385076, 1.8520627455277876, 3.953496976332231, 2.7660835439508613, 5.512530240145597, 3.5881518017161977, 0.9913862293416803, 1.0829144391146572, 0.9554242112419822, 0.9195923046632246, 2.7660835439508613]
loss_5 = [9.52432866529985, 9.15800883553245, 9.11133878881281, 6.593766602602872, 5.5084593079306865, 6.593766602602872, 6.593766602602872, 6.593766602602872, 6.593766602602872, 6.43441239270297, 5.163070331920277, 4.745108691128817, 0.5360064858740027, 0.8701193549416282, 1.0807020230726763, 0.4621112427928231, 2.7449995170940054, 1.1799881566654553, 1.4958000291477551, 1.1307537447322498, 0.9789176529104059, 1.2157874432477085, 0.5215150226246227, 0.4338899119333787, 0.911300924691287]
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALL-IDB1 test set using data augmentation')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.5755813953488372, 0.7499999986138455, 0.784883722316387, 0.8779069753580315, 0.9186046511627907, 0.9593023255813954, 0.9825581409210382, 0.9709302325581395, 0.9767441860465116, 0.9825581395348837, 0.9767441846603571, 0.9883720930232558, 0.9825581395348837, 0.9767441874326661, 0.9883720930232558, 1.0, 0.9709302325581395, 0.9941860465116279, 0.9941860465116279, 0.9709302325581395, 0.9534883734791778, 0.9534883720930233, 0.9767441874326661, 1.0, 0.9883720930232558]
acc_train_2 = [0.5639534897582476, 0.7732558125673339, 0.7965116292931312, 0.9244186060373173, 0.8837209288464036, 0.8604651162790697, 0.9302325567533803, 0.9476744172184967, 0.9302325581395349, 0.9534883707068688, 0.9476744172184967, 0.9534883734791778, 0.9709302325581395, 0.9534883720930233, 0.9883720930232558, 0.9825581409210382, 0.9709302325581395, 0.9883720930232558, 0.9941860465116279, 1.0, 0.9883720930232558, 1.0, 1.0, 1.0, 1.0]
acc_train_3 = [0.6511627906976745, 0.8837209302325582, 0.9244186060373173, 0.965116277683613, 0.9767441860465116, 0.9825581395348837, 0.9883720930232558, 0.9941860465116279, 1.0, 0.9941860465116279, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9941860465116279, 0.9941860465116279, 0.9941860465116279, 0.9941860478977824, 1.0, 0.9941860465116279, 1.0, 1.0, 1.0]
acc_train_4 = [0.5697674404743106, 0.8255813953488372, 0.9127906976744186, 0.9069767455722011, 0.9534883734791778, 0.9709302325581395, 0.970930231171985, 0.9534883720930233, 0.9883720930232558, 0.9941860465116279, 0.9883720944094103, 1.0, 1.0, 0.9941860478977824, 0.9651162790697675, 0.9941860478977824, 1.0, 1.0, 1.0, 0.9941860465116279, 1.0, 1.0, 1.0, 0.9941860465116279, 0.9941860478977824]
acc_train_5 = [0.5930232544277989, 0.848837207916171, 0.9418604665024336, 0.9534883734791778, 0.9593023255813954, 0.9825581395348837, 0.9709302339442941, 0.9941860465116279, 0.9767441874326661, 0.9883720944094103, 0.9941860465116279, 0.9941860465116279, 0.9883720930232558, 0.9941860465116279, 0.9941860465116279, 1.0, 0.9941860465116279, 0.9941860465116279, 0.9941860465116279, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)

plt.plot(x_values, acc_train_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, acc_train_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, acc_train_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, acc_train_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, acc_train_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB1 train set using data augmentation')
plt.legend(loc='best')
plt.show() 
'''
# ---------------------------------------------------------------------- 

# Data aug + dropout results with color 
'''
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.6136363582177595, 0.7272727218541232, 0.47727273269133136, 0.47727273269133136, 0.5681818181818182, 0.47727273269133136, 0.47727273269133136, 0.47727273269133136, 0.47727273269133136, 0.47727273269133136, 0.47727273269133136, 0.6136363582177595, 0.7954545508731495, 0.6818181763995778, 0.9090909145095132, 0.5454545508731495, 0.4772727218541232, 0.4545454599640586, 0.7727272781458768, 0.5454545481638475, 0.5454545481638475, 0.5454545481638475, 0.47727273269133136, 0.5909090881997888, 0.5454545481638475]
accuracy_2 = [0.6136363636363636, 0.6136363636363636, 0.6136363636363636, 0.6363636363636364, 0.38636363636363635, 0.38636363636363635, 0.500000002709302, 0.4772727272727273, 0.4772727272727273, 0.500000002709302, 0.500000002709302, 0.4318181818181818, 0.500000002709302, 0.6136363690549677, 0.659090903672305, 0.38636363636363635, 0.45454545454545453, 0.500000002709302, 0.500000002709302, 0.6363636417822405, 0.6136363636363636, 0.6136363636363636, 0.6363636363636364, 0.6818181763995778, 0.5909090909090909]
accuracy_3 = [0.3863636417822404, 0.4090909145095132, 0.3863636417822404, 0.3863636417822404, 0.4318181818181818, 0.3863636417822404, 0.3863636417822404, 0.3863636417822404, 0.3863636417822404, 0.3863636417822404, 0.49999999458139593, 0.8181818236004222, 0.4318181818181818, 0.3863636417822404, 0.8409090854904868, 0.4090909090909091, 0.4090909090909091, 0.5454545400359414, 0.3863636417822404, 0.3863636417822404, 0.7045454545454546, 0.7727272781458768, 0.6818181791088798, 0.7727272781458768, 0.7727272781458768]
accuracy_4 = [0.40909090638160706, 0.6590909090909091, 0.6590909090909091, 0.40909090638160706, 0.7272727326913313, 0.7272727326913313, 0.7954545400359414, 0.5909090854904868, 0.7954545508731495, 0.6136363582177595, 0.5909090854904868, 0.5909090854904868, 0.5909090854904868, 0.5909090854904868, 0.6818181818181818, 0.6363636363636364, 0.590909096327695, 0.6590909090909091, 0.6590909090909091, 0.7272727326913313, 0.5454545400359414, 0.40909090638160706, 0.6590909090909091, 0.7500000054186041, 0.6590909090909091]
accuracy_5 = [0.6363636309450323, 0.6363636309450323, 0.6363636309450323, 0.3636363609270616, 0.45454545454545453, 0.6363636309450323, 0.7272727218541232, 0.6363636309450323, 0.6136363582177595, 0.6136363582177595, 0.6818181763995778, 0.45454545454545453, 0.45454545454545453, 0.45454545454545453, 0.45454545454545453, 0.45454545454545453, 0.45454545454545453, 0.4318181818181818, 0.5, 0.5681818236004222, 0.7045454491268505, 0.590909096327695, 0.590909096327695, 0.4772727272727273, 0.7272727218541232]
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB1 test set using data augmentation and dropout')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [1.1117404265837236, 0.7069399519400164, 8.3375188220631, 8.425367832183838, 1.3157381903041492, 3.3198522437702525, 1.3019722754305059, 0.7626300670883872, 0.8060536709698763, 1.0727032152089206, 0.747673056342385, 0.5788197110999714, 0.5128272500905123, 0.4969954328103499, 0.4793344058773734, 0.6751347617669539, 0.839769260449843, 2.1141981103203515, 0.680057867006822, 0.9150824546813965, 1.1708008159290662, 1.3679531595923684, 3.555288553237915, 0.7791596759449352, 1.1380457552996548]
loss_2 = [2.0234508622776377, 1.4423114549029956, 1.03114530173215, 0.9174479246139526, 9.84117689999667, 1.774559129368175, 1.1740541458129883, 1.5901664603840222, 1.8530167666348545, 1.8970663330771707, 1.5198592381043867, 2.2188774238933218, 1.5944187099283391, 0.7453510978005149, 0.6526032821698622, 4.230720216577703, 2.075837720524181, 1.003151156685569, 0.9568247903477062, 0.702942588112571, 2.1532985080372202, 1.9504800601439043, 1.4592474753206426, 0.7666449763558127, 1.9504800601439043]
loss_3 = [7.501146966760809, 0.9829782410101457, 4.785237637433139, 0.8265409415418451, 0.683493744243275, 2.5070523890581997, 2.4116454883055254, 3.053058375011791, 3.8070931976491753, 2.984996286305514, 0.6176380542191592, 0.5196438458832827, 0.6345643970099363, 0.7662069309841503, 0.5404223068193956, 0.8371084495024248, 0.8817971673878756, 0.5943570760163394, 6.109508319334551, 2.0104454213922676, 0.5375046296553179, 0.45823632045225665, 0.587344922802665, 0.8445505554025824, 0.8445505554025824]
loss_4 = [7.986715533516624, 0.7762484116987749, 0.6111456670544364, 3.8495162183588203, 0.5534667453982614, 0.557350979609923, 0.5372122634540905, 0.710768228227442, 0.5657172392715107, 0.6030500477010553, 0.7131642915985801, 2.628279274160212, 0.9923866066065702, 0.7665870027108626, 0.624583672393452, 0.7535460645502264, 0.9359299486333673, 0.5532441112128171, 0.5846050029451196, 0.5486127002672716, 0.9684914783997969, 1.2167115319858899, 0.6752261302687905, 0.5482070202177222, 1.2167115319858899]
loss_5 = [5.861125469207764, 2.3966231562874536, 2.7163353833285244, 7.653724627061323, 2.1690464236519555, 1.2114302895285867, 0.667034999890761, 5.861125469207764, 2.6796814528378574, 1.6444519107992, 1.6610260985114358, 3.074514150619507, 2.204493533481251, 1.3466233123432507, 1.350017786026001, 1.5271977186203003, 1.3255083994431929, 1.1770010482181201, 0.929537139155648, 0.8553786061026833, 0.7868655053052035, 0.7553399042649702, 0.7062080719254233, 0.7299842238426208, 0.702356604012576]
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALL-IDB1 test set using data augmentation and dropout')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.5465116265208222, 0.5697674418604651, 0.6686046511627907, 0.6104651148929152, 0.5988372086092483, 0.6395348844140075, 0.563953488372093, 0.622093023255814, 0.6162790711535964, 0.7093023255813954, 0.6569767441860465, 0.6976744199908057, 0.6279069753580315, 0.6220930246419685, 0.6104651155859925, 0.651162792083829, 0.6569767441860465, 0.7209302325581395, 0.6511627893115199, 0.6511627906976745, 0.6918604651162791, 0.6569767455722011, 0.6511627906976745, 0.6046511627906976, 0.6453488372093024]
acc_train_2 = [0.598837207916171, 0.6395348851070848, 0.6569767455722011, 0.5697674425535424, 0.5813953488372093, 0.6046511627906976, 0.6569767441860465, 0.6395348851070848, 0.6337209316187127, 0.6337209302325582, 0.6279069760511088, 0.6279069781303406, 0.6511627906976745, 0.6569767427998919, 0.6802325595256894, 0.6395348837209303, 0.6395348851070848, 0.5697674404743106, 0.6162790683812873, 0.6046511620976204, 0.6046511627906976, 0.6744186046511628, 0.6802325581395349, 0.6220930218696594, 0.6511627906976745]
acc_train_3 = [0.5872093030186587, 0.598837207916171, 0.6046511627906976, 0.6104651148929152, 0.5581395341906437, 0.5406976730324501, 0.6279069781303406, 0.5988372086092483, 0.6569767455722011, 0.6627906990605731, 0.6569767455722011, 0.627906976744186, 0.6976744172184967, 0.6511627893115199, 0.6453488372093024, 0.6744186032650082, 0.6686046511627907, 0.6569767441860465, 0.6686046511627907, 0.6104651148929152, 0.6569767455722011, 0.6279069753580315, 0.6453488358231478, 0.6976744186046512, 0.6860465102417524]
acc_train_4 = [0.4941860478977824, 0.6220930246419685, 0.6104651162790697, 0.622093023255814, 0.5639534876790158, 0.5930232572001081, 0.6046511627906976, 0.6162790711535964, 0.6046511641768522, 0.5465116272138995, 0.5697674411673879, 0.5697674418604651, 0.5697674432466197, 0.5813953488372093, 0.5116279076698215, 0.5930232558139535, 0.534883719544078, 0.6046511627906976, 0.5988372099954028, 0.598837207916171, 0.5755813939626827, 0.5872093030186587, 0.529069768828015, 0.627906976744186, 0.5872093009394269]
acc_train_5 = [0.5697674404743106, 0.5872093009394269, 0.6627906969813413, 0.6918604665024336, 0.598837207916171, 0.6860465102417524, 0.6337209316187127, 0.662790696288264, 0.7034883720930233, 0.6802325595256894, 0.639534883027853, 0.6569767455722011, 0.6511627906976745, 0.6220930218696594, 0.662790696288264, 0.6627906990605731, 0.6627906976744186, 0.6395348837209303, 0.6860465102417524, 0.6744186046511628, 0.598837207916171, 0.7325581395348837, 0.5813953502233639, 0.6744186046511628, 0.6802325595256894]
avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)

plt.plot(x_values, acc_train_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, acc_train_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, acc_train_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, acc_train_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, acc_train_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB1 train set using data augmentation and dropout')
plt.legend(loc='best')
plt.show() 
'''

# ---------------------------------------------------------------------- 

# Greyscale
'''
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.6363636255264282, 0.6363636255264282, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.6363636255264282, 0.6363636255264282, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718]
accuracy_2 = [0.5, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.4545454680919647, 0.4545454680919647, 0.5, 0.5, 0.5454545617103577, 0.4545454680919647, 0.4545454680919647, 0.4545454680919647, 0.4545454680919647, 0.4545454680919647, 0.4545454680919647, 0.4545454680919647, 0.4545454680919647, 0.4545454680919647, 0.4545454680919647, 0.4545454680919647, 0.4545454680919647, 0.4545454680919647, 0.4545454680919647, 0.4545454680919647]
accuracy_3 = [0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282]
accuracy_4 = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5909090638160706, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]
accuracy_5 = [0.3636363744735718, 0.3636363744735718, 0.27272728085517883, 0.6363636255264282, 0.6363636255264282, 0.3636363744735718, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282]
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)
print(avg_acc)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB1 test set using greyscale')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [4.310165882110596, 4.976646900177002, 10.256969451904297, 10.256969451904297, 10.256969451904297, 10.256969451904297, 6.495138168334961, 1.1717555522918701, 1.9281786680221558, 3.587286949157715, 1.9240044355392456, 3.972440242767334, 9.918274879455566, 5.861125469207764, 5.861125469207764, 10.256969451904297, 10.256969451904297, 10.256969451904297, 10.256969451904297, 10.256969451904297, 10.256969451904297, 10.256969451904297, 10.256969451904297, 10.256969451904297, 10.256969451904297]
loss_2 = [1.8417115211486816, 7.00926399230957, 6.4751691818237305, 5.934533596038818, 4.926774978637695, 3.43437123298645, 3.0875585079193115, 1.461647868156433, 2.048799991607666, 2.136200428009033, 6.7433061599731445, 8.791687965393066, 8.791687965393066, 8.791687965393066, 8.791687965393066, 8.791687965393066, 8.791687965393066, 8.791687965393066, 8.791687965393066, 8.791687965393066, 8.791687965393066, 8.791687965393066, 8.759757995605469, 8.791687965393066, 8.791687965393066]
loss_3 = [5.861125469207764, 5.861125469207764, 0.8777948617935181, 2.8330602645874023, 3.70269775390625, 5.696011543273926, 5.768177509307861, 5.829623699188232, 5.861125469207764, 5.861125469207764, 5.861125469207764, 5.861125469207764, 5.861125469207764, 5.861125469207764, 5.861125469207764, 5.861125469207764, 5.861125469207764, 5.787757873535156, 5.760186195373535, 5.861125469207764, 5.861125469207764, 5.739609241485596, 5.599655628204346, 5.675957202911377, 5.522504806518555]
loss_4 = [1.042543610861135, 0.6386998004691545, 0.4326300482417262, 0.43976208151772966, 0.28599009749501253, 0.2583707324987234, 0.2443125320728435, 0.22883840563685395, 0.11336846043204152, 0.11229927629925483, 0.0953925236366516, 0.09864807059598524, 0.04987025668108186, 0.04410917467849199, 0.024248936841654224, 0.044396306886229406, 0.0905552939620129, 0.02952203977593156, 0.053572602916595546, 0.026063335539643153, 0.045399829355436704, 0.03716129861598791, 0.025427005491977513, 0.01946194171039171, 0.01820489798867425]
loss_5 = [10.256969451904297, 10.256969451904297, 1.048120379447937, 4.0874342918396, 5.861125469207764, 10.256969451904297, 5.861125469207764, 5.861125469207764, 5.861125469207764, 5.861125469207764, 5.861125469207764, 5.861125469207764, 5.861125469207764, 5.861125469207764, 5.861125469207764, 5.861125469207764, 5.861125469207764, 5.861125469207764, 5.861125469207764, 5.861125469207764, 5.861125469207764, 5.861125469207764, 5.861125469207764, 5.861125469207764, 5.861125469207764]
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)
print(avg_loss)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALL-IDB1 test set using greyscale')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.4186046497766362, 0.7558139521022176, 0.7790697660557059, 0.8953488330508388, 0.8604651176652243, 0.9418604609578155, 0.9534883790237959, 0.9767441860465116, 0.9069767441860465, 0.9767441860465116, 1.0, 0.9651162790697675, 1.0, 0.9767441860465116, 0.9767441860465116, 0.9883720888647922, 1.0, 1.0, 1.0, 1.0, 0.9883720888647922, 0.9883720888647922, 0.9767441860465116, 1.0, 1.0]
acc_train_2 = [0.5581395348837209, 0.872093026028123, 0.9069767511168192, 0.9651162749113038, 0.976744181888048, 0.9883720888647922, 0.976744181888048, 1.0, 1.0, 0.9883720888647922, 0.9883720930232558, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_3 = [0.4186046511627907, 0.7906976688739865, 0.9302325581395349, 0.8953488330508388, 0.9302325581395349, 0.9534883790237959, 0.9534883790237959, 1.0, 1.0, 0.9883720930232558, 0.9883720888647922, 0.976744181888048, 0.9883720888647922, 0.9883720930232558, 0.9883720888647922, 1.0, 1.0, 1.0, 0.9883720930232558, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_4 = [0.4651162818420765, 0.7093023311260135, 0.8837209330048672, 0.8488372120746347, 0.9186046539350997, 0.9186046511627907, 0.9418604651162791, 0.9186046511627907, 1.0, 0.9883720888647922, 1.0, 0.9651162790697675, 1.0, 0.9883720888647922, 1.0, 0.9883720888647922, 0.9651162860005401, 1.0, 0.9883720930232558, 1.0, 0.9883720930232558, 0.9883720888647922, 1.0, 1.0, 1.0]
acc_train_5 = [0.4883720957955649, 0.7674418632374254, 0.9418604651162791, 0.9651162860005401, 0.9418604651162791, 0.9651162860005401, 0.9651162860005401, 0.9418604678885881, 0.9767441860465116, 0.9883720930232558, 0.9534883707068688, 0.9883720930232558, 1.0, 1.0, 1.0, 0.9651162860005401, 0.9883720888647922, 0.9767441860465116, 1.0, 0.9534883720930233, 0.9883720930232558, 1.0, 0.9883720930232558, 0.9883720930232558, 1.0]
avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)
print(avg_acc_train)

plt.plot(x_values, acc_train_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, acc_train_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, acc_train_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, acc_train_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, acc_train_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB1 train set using greyscale')
plt.legend(loc='best')
plt.show()
'''

# ---------------------------------------------------------------------- 

# Contrast increase
# Accuracy 
'''
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6818181872367859, 0.8181818127632141, 0.8636363744735718, 0.8636363744735718, 0.8636363744735718, 0.8636363744735718, 0.8636363744735718, 0.6818181872367859, 0.7272727489471436, 0.9090909361839294, 0.5, 0.40909090638160706, 0.5, 0.5, 0.7727272510528564, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282]
accuracy_2 = [0.5909090638160706, 0.9545454382896423, 0.7272727489471436, 0.7272727489471436, 0.7272727489471436, 0.7727272510528564, 0.7727272510528564, 0.7272727489471436, 0.7272727489471436, 0.7272727489471436, 0.7272727489471436, 0.7272727489471436, 0.7272727489471436, 0.7272727489471436, 0.7272727489471436, 0.7272727489471436, 0.7272727489471436, 0.7272727489471436, 0.7727272510528564, 0.8181818127632141, 0.8181818127632141, 0.8181818127632141, 0.8636363744735718, 0.9090909361839294, 0.9090909361839294]
accuracy_3 = [0.4545454680919647, 0.9090909361839294, 0.8636363744735718, 0.6818181872367859, 0.8636363744735718, 0.9090909361839294, 0.7727272510528564, 0.7727272510528564, 0.6363636255264282, 0.9090909361839294, 0.8636363744735718, 0.8636363744735718, 0.8636363744735718, 0.8636363744735718, 0.9090909361839294, 0.8636363744735718, 0.9090909361839294, 0.9090909361839294, 0.8636363744735718, 0.8636363744735718, 0.8636363744735718, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9545454382896423]
accuracy_4 = [0.5909090638160706, 0.5454545617103577, 0.6818181872367859, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.6363636255264282, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.8181818127632141, 0.9090909361839294, 0.8636363744735718, 0.8636363744735718, 0.7272727489471436, 0.7272727489471436, 0.8636363744735718, 0.8636363744735718, 0.8636363744735718, 0.8636363744735718, 0.8636363744735718, 0.8636363744735718, 0.9090909361839294, 0.9090909361839294]
accuracy_5 = [0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.6818181872367859, 0.8636363744735718, 0.9545454382896423, 0.8636363744735718, 0.8636363744735718, 0.7272727489471436, 0.7272727489471436, 0.7272727489471436, 0.7727272510528564, 0.7727272510528564, 0.8181818127632141, 0.8181818127632141, 0.9090909361839294, 0.8636363744735718, 0.8181818127632141]
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)
print(avg_acc)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB2 test set with contrast increase')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [5.861125469207764, 5.861125469207764, 4.889482498168945, 4.8078813552856445, 2.7448058128356934, 1.207173466682434, 0.37032249569892883, 0.32266098260879517, 0.6400229930877686, 0.6212992668151855, 0.405777245759964, 0.5165644884109497, 1.076331377029419, 0.5085036754608154, 0.3116166889667511, 1.385498285293579, 2.1352148056030273, 1.9869353771209717, 1.5307015180587769, 0.39343369007110596, 5.753194808959961, 5.861126899719238, 5.861126899719238, 5.861126899719238, 5.861128330230713]
loss_2 = [1.033239722251892, 0.2166338562965393, 4.395843982696533, 4.395843982696533, 1.9123479127883911, 0.9094995260238647, 1.027997374534607, 2.2272627353668213, 4.395843982696533, 4.395843982696533, 3.1296815872192383, 2.1396000385284424, 1.616176724433899, 1.4781814813613892, 1.8591556549072266, 1.9496852159500122, 1.9051951169967651, 1.730112910270691, 1.4038392305374146, 1.049783706665039, 0.8575014472007751, 0.8630443811416626, 0.792436420917511, 0.6663254499435425, 0.5420531034469604]
loss_3 = [3.8351926803588867, 0.4462074339389801, 0.6443132162094116, 3.6637513637542725, 0.7124744057655334, 0.4367983639240265, 0.46691837906837463, 0.3932548761367798, 0.7623619437217712, 0.5019311308860779, 0.3598703444004059, 0.3286060392856598, 0.3632965385913849, 0.28817203640937805, 0.2889626622200012, 0.358306348323822, 0.2841891944408417, 0.22099488973617554, 0.20457148551940918, 0.19676633179187775, 0.19312430918216705, 0.19388574361801147, 0.19883579015731812, 0.16826225817203522, 0.18810270726680756]
loss_4 = [6.593766689300537, 0.6283928751945496, 0.7805461883544922, 6.593766689300537, 2.7325899600982666, 1.5820000171661377, 1.4197630882263184, 1.3469228744506836, 1.1638585329055786, 0.9696537256240845, 1.0749824047088623, 0.7962013483047485, 0.44979411363601685, 0.4105602204799652, 0.6321090459823608, 0.9510068297386169, 0.9059175848960876, 0.5987510681152344, 0.34475114941596985, 0.36988943815231323, 0.37170714139938354, 0.3649265468120575, 0.3414602279663086, 0.30158302187919617, 0.2840845286846161]
loss_5 = [7.326406955718994, 7.326406955718994, 7.132101058959961, 4.974776744842529, 7.326406955718994, 4.734298229217529, 2.3307137489318848, 1.5778312683105469, 7.326406955718994, 1.6873164176940918, 0.46092990040779114, 0.3273974657058716, 0.31709420680999756, 0.3236573338508606, 0.3452540636062622, 0.425672322511673, 0.4965643882751465, 0.49355050921440125, 0.4403129816055298, 0.3593240976333618, 0.32440057396888733, 0.3027626872062683, 0.2965741455554962, 0.29865890741348267, 0.31892451643943787]
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)
print(avg_loss)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALL-IDB1 test set with contrast increase')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.6395348864932393, 0.8953488330508388, 0.9534883720930233, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9767441929772843, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9883720888647922, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_2 = [0.7093023283537044, 0.9069767400275829, 1.0, 0.9883720930232558, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_3 = [0.6627906921298005, 0.872093026028123, 0.9069767386414284, 0.9534883679345597, 0.9767441929772843, 0.9767441860465116, 1.0, 1.0, 1.0, 0.9883720930232558, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_4 = [0.5697674390881561, 0.8488372148469437, 0.9767441860465116, 1.0, 0.9767441860465116, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_5 = [0.5813953419064366, 0.9069767386414284, 0.9302325581395349, 0.9767441860465116, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)
print(avg_acc_train)

plt.plot(x_values, acc_train_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, acc_train_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, acc_train_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, acc_train_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, acc_train_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB1 train set with contrast increase')
plt.legend(loc='best')
plt.show()
'''

# ---------------------------------------------------------------------- 
'''
# hist eq
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.4545454680919647, 0.4545454680919647, 0.4545454680919647, 0.5454545617103577, 0.6818181872367859, 0.4545454680919647, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.6363636255264282, 0.6818181872367859, 0.6818181872367859, 0.7272727489471436, 0.7727272510528564, 0.7727272510528564, 0.8181818127632141, 0.8636363744735718, 0.8636363744735718, 0.8636363744735718]
accuracy_2 = [0.3636363744735718, 0.3636363744735718, 0.7272727489471436, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.7272727489471436, 0.7727272510528564, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294]
accuracy_3 = [0.4545454680919647, 0.5454545617103577, 0.4545454680919647, 0.4545454680919647, 0.5454545617103577, 0.5454545617103577, 0.4545454680919647, 0.4545454680919647, 0.4545454680919647, 0.4545454680919647, 0.5, 0.5454545617103577, 0.5, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5909090638160706, 0.8181818127632141, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294]
accuracy_4 = [0.5454545617103577, 0.6363636255264282, 0.7272727489471436, 0.7727272510528564, 0.7727272510528564, 0.7727272510528564, 0.7727272510528564, 0.7727272510528564, 0.7272727489471436, 0.7727272510528564, 0.7727272510528564, 0.8181818127632141, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294, 0.9090909361839294]
accuracy_5 = [0.8636363744735718, 0.6818181872367859, 0.8636363744735718, 0.6818181872367859, 0.6818181872367859, 0.7272727489471436, 0.9090909361839294, 0.9090909361839294, 0.9545454382896423, 0.9545454382896423, 0.9545454382896423, 0.9545454382896423, 0.9545454382896423, 0.9545454382896423, 0.9545454382896423, 0.9545454382896423, 0.9545454382896423, 0.9545454382896423, 0.9545454382896423, 0.9545454382896423, 0.9545454382896423, 0.9545454382896423, 0.9545454382896423, 0.9545454382896423, 0.9545454382896423]
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)
print(avg_acc)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB1 test set with histogram equalizer')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [8.791687965393066, 8.791687965393066, 8.791687965393066, 7.326406955718994, 0.7170959711074829, 2.2623865604400635, 7.326406955718994, 7.326406955718994, 7.326406955718994, 7.056834697723389, 6.285278797149658, 5.368631362915039, 4.211904525756836, 3.3561911582946777, 2.6425940990448, 2.007718563079834, 1.5258069038391113, 1.2361184358596802, 1.0517916679382324, 0.8969877362251282, 0.7890011072158813, 0.699408233165741, 0.6351205706596375, 0.5983731746673584, 0.564568042755127]
loss_2 = [10.256969451904297, 10.256969451904297, 1.1191540956497192, 5.861125469207764, 5.368051052093506, 3.399580478668213, 1.871674656867981, 0.9841541051864624, 0.49773740768432617, 0.2928384840488434, 0.17377443611621857, 0.13456274569034576, 0.12277781218290329, 0.1369314044713974, 0.1369314044713974, 0.1369314044713974, 0.1369314044713974, 0.1369314044713974, 0.1369314044713974, 0.1369314044713974, 0.1369314044713974, 0.1369314044713974, 0.1369314044713974, 0.1369314044713974, 0.1369314044713974]
loss_3 = [8.791687965393066, 3.168804407119751, 8.791687965393066, 8.791687965393066, 7.326406955718994, 7.326406955718994, 8.791687965393066, 6.3582916259765625, 4.766982078552246, 3.512904405593872, 2.6300840377807617, 2.2936928272247314, 1.9587452411651611, 1.6893718242645264, 1.4348781108856201, 7.326406955718994, 4.055056571960449, 1.5178090333938599, 0.7354540228843689, 0.5558397173881531, 0.4589899778366089, 0.413821816444397, 0.38895919919013977, 0.38019683957099915, 0.37622806429862976]
loss_4 = [6.6453046798706055, 0.8434457182884216, 0.5487855672836304, 0.5122111439704895, 0.5378788113594055, 0.5405838489532471, 0.62892085313797, 0.6588334441184998, 0.6972410082817078, 0.6302871108055115, 0.5419971942901611, 0.39526990056037903, 0.28621163964271545, 0.261931449174881, 0.26713037490844727, 0.25705692172050476, 0.2592458426952362, 0.2592085897922516, 0.25825464725494385, 0.25512850284576416, 0.2543874979019165, 0.25647732615470886, 0.24897193908691406, 0.2527782917022705, 0.25668174028396606]
loss_5 = [1.3339639902114868, 1.8774738311767578, 0.13666976988315582, 1.0407060384750366, 1.082582712173462, 0.6658753752708435, 0.36001405119895935, 0.2090814709663391, 0.13722139596939087, 0.11257951706647873, 0.10523449629545212, 0.09840384125709534, 0.09747826308012009, 0.10475626587867737, 0.11374861747026443, 0.1226426437497139, 0.1301955133676529, 0.1295984536409378, 0.12827375531196594, 0.12043210864067078, 0.11370692402124405, 0.10758263617753983, 0.10312198847532272, 0.09963707625865936, 0.09618766605854034]
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)
print(avg_loss)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALL-IDB1 test set with histogram equalizer')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.6976744213769602, 0.9534883720930233, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_2 = [0.6511627851530563, 0.9534883720930233, 0.9883720888647922, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_3 = [0.6976744241492693, 0.9883720930232558, 0.9883720888647922, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_4 = [0.7209302394889122, 0.9883720930232558, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_5 = [0.6976744213769602, 0.9651162790697675, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)
print(avg_acc_train)

plt.plot(x_values, acc_train_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, acc_train_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, acc_train_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, acc_train_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, acc_train_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB1 train set with histogram equalizer')
plt.legend(loc='best')
plt.show()
'''

'''
# 3 filters comparison 
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.5272727251052857, 0.5363636374473572, 0.4636363685131073, 0.5363636374473572, 0.5363636374473572, 0.4636363685131073, 0.5181818187236786, 0.5272727251052857, 0.5272727251052857, 0.5363636374473572, 0.5181818187236786, 0.5363636314868927, 0.5181818187236786, 0.5727272689342499, 0.5727272689342499, 0.5181818187236786, 0.5181818187236786, 0.5181818187236786, 0.5181818187236786, 0.5181818187236786, 0.5181818187236786, 0.5181818187236786, 0.5181818187236786, 0.5181818187236786, 0.5181818187236786]
accuracy_2 = [0.5636363565921784, 0.718181824684143, 0.6909090995788574, 0.6363636374473571, 0.6727272748947144, 0.7, 0.699999988079071, 0.7090909123420716, 0.6909090995788574, 0.7454545617103576, 0.7636363744735718, 0.8272727370262146, 0.8272727370262146, 0.8090909242630004, 0.8545454740524292, 0.7090909242630005, 0.7000000178813934, 0.7454545617103576, 0.7545454502105713, 0.8181818127632141, 0.8, 0.8090909123420715, 0.8363636493682861, 0.8454545617103577, 0.8454545497894287]
accuracy_3 = [0.5363636493682862, 0.5363636434078216, 0.6454545617103576, 0.6181818187236786, 0.6636363625526428, 0.6272727310657501, 0.6636363685131073, 0.6818181931972503, 0.6909090936183929, 0.7272727310657501, 0.7363636374473572, 0.7545454621315002, 0.7727272748947144, 0.7818181872367859, 0.7818181872367859, 0.7909090995788575, 0.800000011920929, 0.8090909123420715, 0.8636363744735718, 0.8909090995788574, 0.8909090995788574, 0.9000000119209289, 0.9090909242630005, 0.9090909242630005, 0.9090909242630005]

plt.plot(x_values, accuracy_1, label="Greyscale", linewidth=1)
plt.plot(x_values, accuracy_2, label="Contrast increased", linewidth=1)
plt.plot(x_values, accuracy_3, label="Histogram equalizer", linewidth=1) 

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Average model accuracy on ALL-IDB1 test set by applied filters')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [4.662503187046495, 5.748541122813558, 3.818136784642242, 4.7103519371775695, 5.006711550230204, 5.980538482513539, 4.291262437368548, 2.9105981988962304, 3.1625196116954783, 3.511607518376306, 4.096990811512914, 4.917005443434382, 6.096416807989049, 5.28383470953897, 5.2798626619716025, 6.163060932519825, 6.172292729934981, 6.145412559963242, 6.144708336959051, 6.1593943382505065, 6.163261637013665, 6.137310685321342, 6.10058711008277, 6.121040406225379, 6.090098518202471]
loss_2 = [4.929946303367615, 2.8957533180713653, 3.5684573888778686, 4.887204027175903, 3.0857250094413757, 1.7739539206027986, 1.1231430172920227, 1.1735865473747253, 2.857698881626129, 1.6352089047431946, 1.0862482964992524, 0.8216738760471344, 0.7645385921001434, 0.6018149495124817, 0.6874196231365204, 1.0140338003635407, 1.1454162180423737, 1.0060689508914948, 0.7848352730274201, 0.47383945286273954, 1.499985656142235, 1.5171492516994476, 1.4980866968631745, 1.459191307425499, 1.4388586372137069]
loss_3 = [7.163922810554505, 4.987676274776459, 3.8775970727205276, 4.70642751455307, 3.0064031004905702, 2.8389666438102723, 3.795740896463394, 3.1073535203933718, 2.685117769241333, 2.321088843047619, 1.9472737923264503, 1.658112135529518, 1.3354234963655471, 1.109836420416832, 0.9190565213561058, 1.9701512977480888, 1.2214472472667695, 0.6559331834316253, 0.4621410995721817, 0.3930638939142227, 0.3506033822894096, 0.3228442832827568, 0.30262102037668226, 0.293583357334137, 0.2861193835735321]

plt.plot(x_values, loss_1, label="Greyscale", linewidth=1)
plt.plot(x_values, loss_2, label="Contrast increased", linewidth=1)
plt.plot(x_values, loss_3, label="Histogram equalizer", linewidth=1) 

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Average model loss on ALL-IDB1 test set by applied filters')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.4697674426921578, 0.7790697682735532, 0.8883720946866411, 0.9139534878176312, 0.9255813953488372, 0.9534883732019468, 0.9581395382104917, 0.9674418610195781, 0.9767441860465116, 0.9860465099645215, 0.9860465105189833, 0.9790697666101676, 0.9976744177729584, 0.9906976735869119, 0.9930232549822607, 0.9883720927460248, 0.9906976749730665, 0.9953488372093023, 0.9953488372093023, 0.9906976744186047, 0.9930232549822607, 0.9953488355459168, 0.9930232558139535, 0.9976744186046511, 1.0]
acc_train_2 = [0.6325581375942674, 0.8860465105189835, 0.9534883709840996, 0.9837209294008655, 0.9906976758047591, 0.9953488372093023, 1.0, 1.0, 1.0, 0.9976744186046511, 1.0, 0.9953488385954568, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9976744177729584, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_3 = [0.6976744210997293, 0.9651162782380748, 0.9953488355459168, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

plt.plot(x_values, acc_train_1, label="Greyscale", linewidth=1)
plt.plot(x_values, acc_train_2, label="Contrast increased", linewidth=1)
plt.plot(x_values, acc_train_3, label="Histogram equalizer", linewidth=1) 

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Average model accuracy on ALL-IDB1 train set by applied filters')
plt.legend(loc='best')
plt.show()
'''


# 200X200
'''
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.6818181872367859, 0.6363636255264282, 0.6363636255264282, 0.3636363744735718, 0.3636363744735718, 0.5454545617103577, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.3636363744735718, 0.4545454680919647, 0.4545454680919647, 0.4545454680919647, 0.4545454680919647, 0.4545454680919647, 0.6363636255264282, 0.6363636255264282]
accuracy_2 = [0.5909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.7272727489471436, 0.40909090638160706, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5909090638160706, 0.40909090638160706]
accuracy_3 = [0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.8636363744735718, 0.6818181872367859, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5909090638160706, 0.5909090638160706, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5, 0.5909090638160706, 0.6818181872367859, 0.5454545617103577]
accuracy_4 = [0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.6363636255264282, 0.7727272510528564, 0.6363636255264282, 0.5909090638160706, 0.5909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.4545454680919647, 0.40909090638160706, 0.5909090638160706, 0.4545454680919647, 0.6818181872367859, 0.7727272510528564]
accuracy_5 = [0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.40909090638160706, 0.4545454680919647, 0.40909090638160706, 0.6363636255264282, 0.6818181872367859, 0.6818181872367859, 0.6363636255264282, 0.5454545617103577, 0.6818181872367859, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.7272727489471436, 0.5454545617103577, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.7727272510528564, 0.5909090638160706]
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB1 test set using larger rescale (200x200)')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [1.041910171508789, 4.588733196258545, 2.6691477298736572, 10.256969451904297, 5.45399808883667, 3.6070947647094727, 5.160052299499512, 7.572490215301514, 10.256969451904297, 10.256969451904297, 7.099823474884033, 3.1201136112213135, 3.429121255874634, 5.532759666442871, 7.510488510131836, 8.36005687713623, 8.252959251403809, 7.630681991577148, 7.094362258911133, 5.790379047393799, 5.069392681121826, 4.77028751373291, 4.429121017456055, 3.7687559127807617, 2.4745194911956787]
loss_2 = [6.593766689300537, 9.52432918548584, 9.52432918548584, 9.52432918548584, 9.427285194396973, 9.141583442687988, 9.233847618103027, 9.157330513000488, 8.841358184814453, 9.52432918548584, 9.52432918548584, 9.472868919372559, 9.317028045654297, 9.118002891540527, 8.853766441345215, 8.513595581054688, 7.00791597366333, 7.263543605804443, 7.260044574737549, 6.971210956573486, 6.585245132446289, 6.2635178565979, 6.208726406097412, 6.026331901550293, 5.941586017608643]
loss_3 = [7.3264079093933105, 7.3264079093933105, 7.3264079093933105, 7.279986381530762, 5.366553783416748, 4.673522472381592, 2.944166421890259, 3.458240509033203, 5.072935104370117, 4.173501014709473, 1.781995415687561, 0.4785972833633423, 0.6805482506752014, 1.1792011260986328, 1.7854163646697998, 1.4082386493682861, 0.8813587427139282, 0.7872138619422913, 1.0372191667556763, 1.780187726020813, 2.9444329738616943, 3.8976621627807617, 3.423220634460449, 2.426846504211426, 1.9646235704421997]
loss_4 = [9.52432918548584, 9.52432918548584, 7.125316143035889, 1.3684382438659668, 0.5064635872840881, 0.49824047088623047, 1.6734440326690674, 1.2760963439941406, 9.52432918548584, 9.52432918548584, 9.52432918548584, 7.835614204406738, 8.572525978088379, 8.269750595092773, 6.860578536987305, 6.942758083343506, 6.1856231689453125, 4.923307418823242, 2.8560268878936768, 1.6420884132385254, 2.7442870140075684, 3.4273102283477783, 2.3529469966888428, 0.6103074550628662, 0.5183922648429871]
loss_5 = [9.52432918548584, 9.52432918548584, 9.52432918548584, 9.092982292175293, 8.0733003616333, 2.940229654312134, 6.330564498901367, 1.0954209566116333, 0.7665683627128601, 0.7623712420463562, 1.3047382831573486, 2.458042621612549, 0.7446956634521484, 2.652428388595581, 4.011516094207764, 3.891073703765869, 0.8226402401924133, 3.988603353500366, 1.7485049962997437, 1.7812392711639404, 3.743338108062744, 3.927403211593628, 2.3195059299468994, 0.8053140640258789, 0.9630135893821716]
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALL-IDB1 test set using larger rescale (200x200)')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.6395348781763122, 0.9883720930232558, 0.9883720930232558, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_2 = [0.6511627893115199, 0.755813947943754, 0.8488372037577074, 0.8023255869399669, 0.9418604609578155, 0.9418604651162791, 0.9883720930232558, 0.9883720888647922, 1.0, 1.0, 0.9883720888647922, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_3 = [0.5232558111811794, 0.6511627962422926, 0.7906976813493773, 0.8953488372093024, 0.8953488330508388, 0.9534883720930233, 0.9883720888647922, 0.8255813898042191, 1.0, 0.9534883720930233, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_4 = [0.6976744172184967, 0.8953488316646842, 0.9651162790697675, 0.9534883707068688, 0.9418604651162791, 1.0, 0.9883720930232558, 0.9883720888647922, 0.9883720930232558, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_5 = [0.5697674349296925, 0.7790697632833968, 0.9186046580935634, 0.8720930177111959, 0.9651162860005401, 0.9651162790697675, 0.9767441860465116, 0.9883720930232558, 0.976744181888048, 0.9883720930232558, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)

plt.plot(x_values, acc_train_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, acc_train_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, acc_train_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, acc_train_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, acc_train_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB1 train set using larger rescale (200x200)')
plt.legend(loc='best')
plt.show()
'''

# Noise test 
'''
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.4545454680919647, 0.5909090638160706, 0.6818181872367859, 0.6818181872367859, 0.8181818127632141, 0.8181818127632141, 0.8181818127632141, 0.8181818127632141, 0.8181818127632141, 0.8181818127632141, 0.7727272510528564, 0.7727272510528564, 0.7727272510528564, 0.8181818127632141, 0.7727272510528564, 0.8181818127632141, 0.8181818127632141, 0.8181818127632141, 0.8181818127632141, 0.8181818127632141, 0.8181818127632141, 0.7727272510528564, 0.7727272510528564, 0.7727272510528564, 0.7727272510528564]
accuracy_2 = [0.4545454680919647, 0.4545454680919647, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.6363636255264282, 0.5454545617103577, 0.5454545617103577, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.5454545617103577, 0.5909090638160706, 0.5909090638160706, 0.6363636255264282, 0.6363636255264282, 0.5454545617103577, 0.6363636255264282, 0.6363636255264282]
accuracy_3 = [0.5, 0.5, 0.6818181872367859, 0.5, 0.5909090638160706, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.4545454680919647, 0.5, 0.4545454680919647, 0.5909090638160706, 0.6363636255264282, 0.5454545617103577, 0.5909090638160706, 0.5909090638160706]
accuracy_4 = [0.40909090638160706, 0.5909090638160706, 0.6818181872367859, 0.6818181872367859, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.6363636255264282, 0.6818181872367859, 0.5909090638160706, 0.6363636255264282, 0.6363636255264282, 0.6363636255264282, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706, 0.5, 0.5, 0.5909090638160706, 0.5909090638160706, 0.5909090638160706]
accuracy_5 = [0.5, 0.5909090638160706, 0.5909090638160706, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577, 0.5454545617103577]

plt.plot(x_values, accuracy_1, label="noise=0.1", linewidth=1)
plt.plot(x_values, accuracy_2, label="noise=0.2", linewidth=1)
plt.plot(x_values, accuracy_3, label="noise=0.4", linewidth=1) 
plt.plot(x_values, accuracy_4, label="noise=0.6", linewidth=1) 
plt.plot(x_values, accuracy_5, label="noise=0.8", linewidth=1)  


plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB1 test set with different level of noise')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [8.05904769897461, 2.930562734603882, 2.930562734603882, 2.930562734603882, 2.2007439136505127, 1.0486531257629395, 1.2627105712890625, 1.206253170967102, 0.7826654314994812, 0.5040712952613831, 0.6566429734230042, 0.6465520262718201, 0.6014344692230225, 0.48601454496383667, 0.6159271597862244, 0.907444179058075, 0.9221891164779663, 0.9023247361183167, 0.8140146732330322, 0.4644862115383148, 1.1083236932754517, 2.053605556488037, 2.0989151000976562, 1.2634053230285645, 0.6715890765190125]
loss_2 = [8.791687965393066, 7.671147346496582, 7.326406955718994, 7.326406955718994, 3.123629570007324, 3.802682399749756, 3.7329635620117188, 2.830634355545044, 1.1803600788116455, 0.7827958464622498, 1.3837367296218872, 1.177714228630066, 0.577510416507721, 0.6079190969467163, 1.0298689603805542, 0.8615656495094299, 0.8650984168052673, 0.9497911930084229, 0.9806594848632812, 1.0700181722640991, 1.2077884674072266, 1.3053933382034302, 1.4771087169647217, 1.7415317296981812, 1.7581607103347778]
loss_3 = [8.05904769897461, 0.9749903082847595, 2.7836382389068604, 4.690518379211426, 0.578180730342865, 2.4761922359466553, 5.401787281036377, 5.33834981918335, 4.020674228668213, 3.0447609424591064, 2.234431266784668, 2.1708426475524902, 2.976107597351074, 1.6185075044631958, 3.1185014247894287, 3.235089063644409, 3.3933985233306885, 3.33437180519104, 3.206892490386963, 2.950183629989624, 2.027377128601074, 1.856844425201416, 1.8698348999023438, 2.138420581817627, 1.641783595085144]
loss_4 = [5.4723052978515625, 0.6450403332710266, 0.6481742858886719, 0.4917811453342438, 0.6042562127113342, 0.6538404822349548, 0.5426589250564575, 0.8457900881767273, 0.9397932291030884, 0.7081589102745056, 0.6287030577659607, 0.4127208888530731, 0.42893508076667786, 0.5740635991096497, 1.0467524528503418, 2.2295141220092773, 3.2063138484954834, 3.8240396976470947, 4.3390398025512695, 3.403852701187134, 4.3390398025512695, 4.3390398025512695, 4.3390398025512695, 4.3390398025512695, 4.3390398025512695]
loss_5 = [1.5091782808303833, 0.7697896361351013, 1.6609779596328735, 2.381199359893799, 2.3056256771087646, 2.240079641342163, 2.0185546875, 2.00618052482605, 2.40645432472229, 2.9094245433807373, 3.1707770824432373, 3.615903615951538, 4.012280464172363, 4.371819496154785, 4.657886981964111, 4.912807464599609, 5.100927352905273, 5.408346176147461, 5.639542102813721, 5.841888427734375, 6.472085475921631, 7.128714084625244, 7.30674934387207, 7.326406955718994, 7.326406955718994]

plt.plot(x_values, loss_1, label="noise=0.1", linewidth=1)
plt.plot(x_values, loss_2, label="noise=0.2", linewidth=1)
plt.plot(x_values, loss_3, label="noise=0.4", linewidth=1) 
plt.plot(x_values, loss_4, label="noise=0.6", linewidth=1) 
plt.plot(x_values, loss_5, label="noise=0.8", linewidth=1)  

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALL-IDB1 test set with different level of noise')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.6279069822888041, 0.9069767511168192, 0.9651162749113038, 0.9767441929772843, 1.0, 0.9883720888647922, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_2 = [0.6511627851530563, 0.7093023186506227, 0.7790697646695514, 0.8023255841676579, 0.8720930190973504, 0.8837209288464036, 0.895348844140075, 0.9418604720470517, 0.8953488372093024, 0.9534883720930233, 0.9651162749113038, 0.9651162860005401, 0.9767441860465116, 1.0, 0.9767441860465116, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_3 = [0.5697674460189287, 0.5813953419064366, 0.7093023311260135, 0.7906976730324501, 0.8372093009394269, 0.8255813981211463, 0.8372093009394269, 0.872093026028123, 0.7441860437393188, 0.8837209330048672, 0.9186046470043271, 0.9186046456181726, 0.8837209260740946, 0.976744181888048, 0.9418604651162791, 0.9883720930232558, 1.0, 1.0, 0.9883720888647922, 0.9883720930232558, 0.9883720930232558, 0.9883720930232558, 0.9651162818420765, 1.0, 0.9767441929772843]
acc_train_4 = [0.5697674390881561, 0.5930232488831808, 0.6511627879253653, 0.7325581381487292, 0.755813950716063, 0.7558139548745266, 0.7093023200367772, 0.7209302367166032, 0.7906976688739865, 0.744186052056246, 0.8139534953028656, 0.755813950716063, 0.8372093009394269, 0.8023255800091943, 0.7558139521022176, 0.848837205143862, 0.8837209260740946, 0.8837209330048672, 0.8720930301865866, 0.872093026028123, 0.9186046580935634, 0.9302325539810713, 0.8837209330048672, 0.8837209260740946, 0.9418604651162791]
acc_train_5 = [0.5813953460649003, 0.6395348864932393, 0.7093023311260135, 0.6627906949021095, 0.627906973971877, 0.604651166256084, 0.6395348892655484, 0.627906973971877, 0.6976744116738786, 0.7093023311260135, 0.7093023269675499, 0.6860465130140615, 0.7325581381487292, 0.7209302353304486, 0.7441860423531643, 0.7558139548745266, 0.7441860506700915, 0.7209302270135214, 0.7674418660097344, 0.8023255772368852, 0.848837207916171, 0.8255813939626827, 0.8372093009394269, 0.8604651190513788, 0.8488372037577074]

plt.plot(x_values, acc_train_1, label="noise=0.1", linewidth=1)
plt.plot(x_values, acc_train_2, label="noise=0.2", linewidth=1)
plt.plot(x_values, acc_train_3, label="noise=0.4", linewidth=1) 
plt.plot(x_values, acc_train_4, label="noise=0.6", linewidth=1) 
plt.plot(x_values, acc_train_5, label="noise=0.8", linewidth=1)  

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB1 train set with different level of noise')
plt.legend(loc='best')
plt.show()
'''


# ################################################################################################################################################################################




# ---- ALL IDB 2 ------ 


# Baseline
'''
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.615384619969588, 0.615384619969588, 0.615384619969588, 0.36538461767710173, 0.615384619969588, 0.615384619969588, 0.615384619969588, 0.615384619969588, 0.615384619969588, 0.615384619969588, 0.7692307600608239, 0.7499999908300546, 0.7307692215992854, 0.7692307784007146, 0.7692307600608239, 0.6923076831377469, 0.6730769139069778, 0.615384619969588, 0.615384619969588, 0.615384619969588, 0.4423076923076923, 0.615384619969588, 0.615384619969588, 0.615384619969588, 0.6346153892003573]
accuracy_2 = [0.6153846153846154, 0.7692307646457965, 0.4615384569534889, 0.4615384569534889, 0.4615384569534889, 0.4615384569534889, 0.4615384569534889, 0.4615384569534889, 0.4615384569534889, 0.4615384569534889, 0.4615384569534889, 0.4615384569534889, 0.4615384569534889, 0.4615384569534889, 0.4615384569534889, 0.4807692261842581, 0.6730769184919504, 0.4999999954150273, 0.4999999954150273, 0.5576923168622531, 0.5384615430465112, 0.5384615430465112, 0.5384615430465112, 0.5384615430465112, 0.634615380030412]
accuracy_3 = [0.557692303107335, 0.557692303107335, 0.557692303107335, 0.557692303107335, 0.557692303107335, 0.557692303107335, 0.557692303107335, 0.557692303107335, 0.557692303107335, 0.557692303107335, 0.557692303107335, 0.557692303107335, 0.557692303107335, 0.557692303107335, 0.5769230723381042, 0.6923076877227197, 0.6346153754454392, 0.6730769139069778, 0.557692303107335, 0.557692303107335, 0.557692303107335, 0.557692303107335, 0.557692303107335, 0.6153846153846154, 0.6730769184919504]
accuracy_4 = [0.5000000091699454, 0.5000000022924863, 0.5000000022924863, 0.5000000022924863, 0.5000000022924863, 0.5000000022924863, 0.5000000022924863, 0.5000000022924863, 0.7307692353542035, 0.5000000022924863, 0.5000000091699454, 0.5000000022924863, 0.5000000022924863, 0.5000000022924863, 0.5000000022924863, 0.5000000022924863, 0.5000000022924863, 0.5000000022924863, 0.5000000022924863, 0.5000000022924863, 0.5000000022924863, 0.6923077014776376, 0.5769230677531316, 0.5384615476314838, 0.5576922985223624]
accuracy_5 = [0.5000000091699454, 0.5000000091699454, 0.5000000091699454, 0.5000000091699454, 0.5000000091699454, 0.5000000091699454, 0.5000000091699454, 0.5000000091699454, 0.5000000091699454, 0.5000000091699454, 0.5000000091699454, 0.5000000091699454, 0.5000000091699454, 0.5000000091699454, 0.5000000091699454, 0.5000000091699454, 0.5000000091699454, 0.5576922985223624, 0.5769230677531316, 0.5000000091699454, 0.5000000091699454, 0.5192307784007146, 0.5192307784007146, 0.5384615476314838, 0.5961538415688735]
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB2 test set using baseline')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [6.199267424069918, 6.199267424069918, 6.199267424069918, 3.169847011566162, 3.8724123514615574, 6.199267424069918, 5.876616863104013, 2.9324103868924656, 4.586321225533118, 3.4822220435509315, 0.705171906031095, 1.2120368022185106, 1.3593707359754121, 0.5010929932961097, 1.022888000194843, 2.021117017819331, 3.053236044370211, 6.199267424069918, 6.199267424069918, 6.199267424069918, 2.4977162984701304, 3.2683733243208666, 4.8018101545480585, 2.8865787341044498, 3.322104600759653]
loss_2 = [1.9001869421738844, 0.6490437021622291, 8.67897444504958, 8.67897444504958, 8.67897444504958, 8.67897444504958, 8.67897444504958, 8.67897444504958, 8.67897444504958, 7.91643186715933, 5.971695239727314, 8.459285589364859, 5.273128032684326, 3.6619150821979227, 5.287139892578125, 1.900320603297307, 0.8889404260195218, 1.9138669417454646, 2.146990024126493, 1.4060561840350811, 4.190833385174091, 2.403187256592971, 1.1836662384179921, 1.7157089618536143, 0.6528316369423499]
loss_3 = [7.129157763261062, 7.129157763261062, 7.129157763261062, 7.129157763261062, 7.129157763261062, 7.129157763261062, 7.129157763261062, 7.129157763261062, 7.129157763261062, 7.129157763261062, 7.129157763261062, 5.333855592287504, 3.046956942631648, 2.762004467157217, 1.1363146213384776, 0.6527725962492136, 0.6362463877751277, 0.7974807665898249, 2.9174408545860877, 5.128196019392747, 6.891656068655161, 2.9174408545860877, 5.165099235681387, 1.1610307785180898, 0.7974807665898249]
loss_4 = [8.053968502924992, 6.14585465651292, 7.987697234520545, 7.747427280132587, 7.997463373037485, 6.172429965092586, 8.059047772334171, 6.677529885218694, 0.5214030880194443, 2.4367746206430287, 7.506094272320087, 3.6375942597022424, 8.059047772334171, 8.059047772334171, 4.572322148543138, 4.7856172781724196, 4.6586079597473145, 4.182887334090013, 3.3622736013852634, 2.9174408545860877, 4.936549590184138, 0.6814928788405198, 1.963652464059683, 2.8188494535592885, 2.5845264471494236]
loss_5 = [8.059047919053297, 7.63456601362962, 8.013441159174992, 8.059047919053297, 7.915187799013578, 8.059047919053297, 8.059047919053297, 8.059047919053297, 8.059047919053297, 8.059047919053297, 6.754644724038931, 8.059047919053297, 8.059047919053297, 8.059047919053297, 8.054101723891039, 7.875027216397799, 7.824746425335224, 1.010363757610321, 1.090065360069275, 3.841999200674204, 3.4484568192408633, 2.10619135086353, 1.9762650453127348, 2.3192705466197086, 2.057408562073341]
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALL-IDB2 test set using baseline')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.6586538461538461, 0.8557692307692307, 0.9519230769230769, 0.9807692307692307, 0.9903846153846154, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9951923076923077, 0.9903846153846154, 0.9951923076923077, 0.9951923076923077, 1.0, 1.0, 1.0]
acc_train_2 = [0.6875, 0.8125, 0.8461538461538461, 0.9278846153846154, 0.9951923076923077, 0.9903846153846154, 0.9951923076923077, 1.0, 1.0, 1.0, 0.9951923076923077, 0.9903846153846154, 1.0, 0.9951923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_3 = [0.6442307692307693, 0.8605769230769231, 0.9423076923076923, 0.9230769230769231, 0.9903846153846154, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9951923076923077, 0.9903846153846154, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_4 = [0.6538461538461539, 0.8125, 0.9134615384615384, 0.9230769230769231, 0.9855769230769231, 0.9951923076923077, 0.9903846153846154, 0.9855769230769231, 0.9951923076923077, 1.0, 0.9855769230769231, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_5 = [0.6298076923076923, 0.8942307692307693, 0.9471153846153846, 0.9663461538461539, 0.9855769230769231, 1.0, 0.9951923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)

plt.plot(x_values, acc_train_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, acc_train_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, acc_train_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, acc_train_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, acc_train_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB2 train set using baseline')
plt.legend(loc='best')
plt.show()
'''

# ------------------------------------------------------------------------------------------

# Dropout
'''
# Accuracy
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.557692309984794, 0.6346153754454392, 0.44230770147763765, 0.44230770147763765, 0.44230770147763765, 0.44230770147763765, 0.44230770147763765, 0.44230770147763765, 0.44230770147763765, 0.44230770147763765, 0.44230770147763765, 0.44230770147763765, 0.44230770147763765, 0.6346153754454392, 0.692307696892665, 0.5961538507388189, 0.557692309984794, 0.5961538553237915, 0.557692309984794, 0.557692309984794, 0.557692309984794, 0.692307696892665, 0.5769230723381042, 0.5384615407540247, 0.557692309984794]
accuracy_2 = [0.6346153754454392, 0.6346153937853299, 0.6730769184919504, 0.4615384638309479, 0.5576923168622531, 0.6346153937853299, 0.5769230860930222, 0.5576923168622531, 0.5576923168622531, 0.5576923168622531, 0.5384615476314838, 0.5, 0.615384619969588, 0.4615384638309479, 0.7115384615384616, 0.5192307692307693, 0.6538461630160992, 0.6153846245545608, 0.5384615476314838, 0.5576923168622531, 0.6923077014776376, 0.6538461630160992, 0.5576923168622531, 0.5384615476314838, 0.5384615476314838]
accuracy_3 = [0.5769230815080496, 0.5192307692307693, 0.5384615384615384, 0.5576923076923077, 0.5769230815080496, 0.4807692307692308, 0.4807692307692308, 0.6538461584311265, 0.6730769322468684, 0.5961538369839008, 0.4807692307692308, 0.4807692307692308, 0.4807692307692308, 0.4807692307692308, 0.4807692307692308, 0.5576923168622531, 0.4807692307692308, 0.4807692307692308, 0.5961538553237915, 0.4807692307692308, 0.5961538507388189, 0.4807692307692308, 0.4807692307692308, 0.4807692307692308, 0.4807692307692308]
accuracy_4 = [0.5769230723381042, 0.4807692284767444, 0.6730769184919504, 0.4807692284767444, 0.4807692284767444, 0.4807692284767444, 0.4807692284767444, 0.5384615407540247, 0.4807692284767444, 0.4807692284767444, 0.5192307784007146, 0.6538461446762085, 0.6153846107996427, 0.5576922985223624, 0.5192307600608239, 0.5192307600608239, 0.5192307600608239, 0.5192307600608239, 0.5192307600608239, 0.5192307600608239, 0.5192307600608239, 0.5192307600608239, 0.5192307600608239, 0.5192307600608239, 0.5192307600608239]
accuracy_5 = [0.5384615338765658, 0.6923076877227197, 0.5961538369839008, 0.4807692261842581, 0.4807692261842581, 0.4807692261842581, 0.5961538553237915, 0.6153846107996427, 0.4807692261842581, 0.4615384638309479, 0.4807692261842581, 0.4807692261842581, 0.4807692261842581, 0.4807692261842581, 0.4999999954150273, 0.6538461446762085, 0.6153846062146701, 0.6153846062146701, 0.6538461630160992, 0.6923076877227197, 0.5192307738157419, 0.5576922985223624, 0.4807692261842581, 0.6538461492611811, 0.6730769184919504]
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB2 test set using dropout')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [7.129157506502592, 3.3360726283146787, 2.1746258368858924, 1.2447064106280987, 1.1354241692102873, 6.599132977999174, 1.9747826411173894, 2.4331450095543494, 1.6428577624834502, 1.9989172953825731, 3.7036795799548807, 2.825390265538142, 1.1902068211482122, 0.7126119045110849, 0.5979323731018946, 0.6705795709903424, 1.015129098525414, 1.4527015135838435, 3.3774097515986514, 1.6735702477968657, 0.9445985647348257, 0.6026105284690857, 0.6677361130714417, 0.9282889366149902, 1.257901851947491]
loss_2 = [0.5896646930621221, 0.9150789425923274, 0.5644941009007968, 3.685222790791438, 0.7591887895877545, 0.7059743771186242, 1.5897097862683809, 1.200829029083252, 1.1066186336370616, 0.9344908595085144, 1.9168874942339384, 1.2371866703033447, 0.6179426495845501, 6.100728255051833, 0.8011906330402081, 2.404035604917086, 0.9141272673240075, 1.041019082069397, 1.3518957908336933, 1.220974848820613, 0.5698213944068322, 0.5801378213442289, 1.0814797786565928, 0.8489104509353638, 1.5820827667529767]
loss_3 = [0.687235217828017, 4.490672845106858, 2.2787841833554783, 1.1908367046943078, 0.6986844310393701, 4.551268430856558, 1.7044454721304088, 0.5695980970676129, 0.6558989423971909, 0.5912899099863492, 3.7895153852609487, 2.757384281892043, 3.4184877138871412, 2.8464117783766527, 1.8333807908571684, 0.8874207368263831, 1.462866342984713, 1.4673717388739953, 0.7004688290449289, 7.4958008252657375, 0.7478847503662109, 8.36901121873122, 8.36901121873122, 4.984504369588999, 2.4035092683938832]
loss_4 = [0.6844190359115601, 2.106499121739314, 0.6177399800373957, 8.210576717670147, 8.127382278442383, 4.390499408428486, 2.0033747049478383, 7.085267727191631, 8.369011365450346, 8.30937070112962, 4.998404539548433, 2.143913745880127, 0.6653997072806725, 0.7089438530114981, 1.2040893206229577, 1.832622849024259, 2.7234907883864183, 2.6669233578902025, 2.649085209919856, 2.4848296092106748, 2.56033103282635, 3.0206691301785984, 3.2886573718144345, 3.3746864062089186, 3.594137375171368]
loss_5 = [0.8425434461006751, 0.6199840857432439, 0.597023436656365, 4.51887402167687, 1.6397968347256, 1.0702235698699951, 0.6669157972702613, 0.6889578333267798, 4.851172887361967, 2.3097807260660024, 4.162711143493652, 3.1971062880295973, 2.137781546666072, 0.9322125682464013, 0.8187653835003192, 0.6125498230640705, 0.6288630458024832, 0.6092255803254935, 0.6101906574689425, 0.5725235984875605, 1.6866717155163105, 1.4904525646796594, 2.957298132089468, 0.5635133477357718, 0.7034581486995404]
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALL-IDB2 test set using dropout')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.5528846153846154, 0.5769230769230769, 0.6586538461538461, 0.6346153846153846, 0.6346153846153846, 0.6153846153846154, 0.6634615384615384, 0.6682692307692307, 0.6346153846153846, 0.625, 0.6875, 0.6346153846153846, 0.6971153846153846, 0.6730769230769231, 0.6826923076923077, 0.6634615384615384, 0.6442307692307693, 0.6586538461538461, 0.7115384615384616, 0.5865384615384616, 0.6778846153846154, 0.6201923076923077, 0.6682692307692307, 0.6346153846153846, 0.7307692307692307]
acc_train_2 = [0.5961538461538461, 0.6105769230769231, 0.6105769230769231, 0.6057692307692307, 0.6442307692307693, 0.6201923076923077, 0.6730769230769231, 0.6826923076923077, 0.6346153846153846, 0.6923076923076923, 0.6682692307692307, 0.6394230769230769, 0.6586538461538461, 0.5673076923076923, 0.6634615384615384, 0.6009615384615384, 0.6778846153846154, 0.6778846153846154, 0.6586538461538461, 0.6971153846153846, 0.7211538461538461, 0.6442307692307693, 0.6875, 0.6730769230769231, 0.7067307692307693]
acc_train_3 = [0.5336538461538461, 0.6298076923076923, 0.6057692307692307, 0.6778846153846154, 0.6538461538461539, 0.6057692307692307, 0.6394230769230769, 0.6586538461538461, 0.7115384615384616, 0.6057692307692307, 0.6778846153846154, 0.6538461538461539, 0.6298076923076923, 0.6298076923076923, 0.6201923076923077, 0.625, 0.7307692307692307, 0.6826923076923077, 0.6682692307692307, 0.6778846153846154, 0.6490384615384616, 0.6201923076923077, 0.5576923076923077, 0.6442307692307693, 0.6442307692307693]
acc_train_4 = [0.5576923076923077, 0.5384615384615384, 0.5576923076923077, 0.5769230769230769, 0.6394230769230769, 0.6442307692307693, 0.6105769230769231, 0.6442307692307693, 0.6586538461538461, 0.5721153846153846, 0.5528846153846154, 0.5384615384615384, 0.5913461538461539, 0.6153846153846154, 0.6730769230769231, 0.6201923076923077, 0.6201923076923077, 0.6298076923076923, 0.6105769230769231, 0.6105769230769231, 0.625, 0.625, 0.6394230769230769, 0.5961538461538461, 0.625]
acc_train_5 = [0.6490384615384616, 0.6634615384615384, 0.6153846153846154, 0.6490384615384616, 0.6298076923076923, 0.6153846153846154, 0.6586538461538461, 0.6586538461538461, 0.6346153846153846, 0.6394230769230769, 0.6442307692307693, 0.6442307692307693, 0.6394230769230769, 0.6394230769230769, 0.6442307692307693, 0.6346153846153846, 0.6682692307692307, 0.5913461538461539, 0.6634615384615384, 0.7451923076923077, 0.6923076923076923, 0.6826923076923077, 0.7115384615384616, 0.6923076923076923, 0.7067307692307693]
avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)

plt.plot(x_values, acc_train_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, acc_train_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, acc_train_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, acc_train_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, acc_train_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB2 train set using dropout')
plt.legend(loc='best')
plt.show()
'''

# ------------------------------------------------------------------------------------------

# Data aug
'''
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.46153846153846156, 0.5480769230769231, 0.5192307692307693, 0.5384615384615384, 0.5192307692307693, 0.49038461538461536, 0.5384615384615384, 0.5384615384615384, 0.5384615384615384, 0.5288461538461539, 0.47115384615384615, 0.46153846153846156, 0.6057692307692307, 0.6634615384615384, 0.6730769230769231, 0.6153846153846154, 0.6153846153846154, 0.5769230769230769, 0.46153846153846156, 0.6826923076923077, 0.5576923076923077, 0.6442307692307693, 0.5192307692307693, 0.6346153846153846, 0.6442307692307693]
accuracy_2 = [0.4807692307692308, 0.4807692307692308, 0.4807692307692308, 0.4807692307692308, 0.4807692307692308, 0.4807692307692308, 0.5192307692307693, 0.5192307692307693, 0.5192307692307693, 0.5192307692307693, 0.5192307692307693, 0.5384615384615384, 0.7211538461538461, 0.6538461538461539, 0.5384615384615384, 0.6346153846153846, 0.7019230769230769, 0.6634615384615384, 0.7596153846153846, 0.7596153846153846, 0.4807692307692308, 0.49038461538461536, 0.7115384615384616, 0.5576923076923077, 0.7596153846153846]
accuracy_3 = [0.4807692307692308, 0.6057692307692307, 0.4807692307692308, 0.4807692307692308, 0.49038461538461536, 0.5192307692307693, 0.5192307692307693, 0.5192307692307693, 0.5192307692307693, 0.5192307692307693, 0.5192307692307693, 0.5192307692307693, 0.5192307692307693, 0.5192307692307693, 0.5192307692307693, 0.5192307692307693, 0.5192307692307693, 0.7211538461538461, 0.625, 0.6826923076923077, 0.6153846153846154, 0.6634615384615384, 0.7211538461538461, 0.7211538461538461, 0.7211538461538461]
accuracy_4 = [0.47115384615384615, 0.5288461538461539, 0.5288461538461539, 0.5288461538461539, 0.6153846153846154, 0.5384615384615384, 0.5288461538461539, 0.47115384615384615, 0.5288461538461539, 0.5288461538461539, 0.6634615384615384, 0.47115384615384615, 0.47115384615384615, 0.5769230769230769, 0.5769230769230769, 0.5769230769230769, 0.5769230769230769, 0.6153846153846154, 0.5384615384615384, 0.6153846153846154, 0.6153846153846154, 0.6153846153846154, 0.6730769230769231, 0.6730769230769231, 0.6730769230769231]
accuracy_5 = [0.5288461538461539, 0.625, 0.5384615384615384, 0.5288461538461539, 0.5288461538461539, 0.5288461538461539, 0.5288461538461539, 0.5288461538461539, 0.5769230769230769, 0.5288461538461539, 0.5384615384615384, 0.6730769230769231, 0.5480769230769231, 0.75, 0.5288461538461539, 0.5865384615384616, 0.5384615384615384, 0.5769230769230769, 0.7211538461538461, 0.7596153846153846, 0.7788461538461539, 0.7788461538461539, 0.7980769230769231, 0.7692307692307693, 0.7980769230769231]
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB2 test set using data augmentation')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [6.034883939302885, 4.385594844818115, 1.7740478148827186, 5.20994861309345, 3.663969956911527, 1.698432812323937, 4.673366656670203, 7.108536830315223, 2.483538132447463, 2.42782447888301, 1.8473541369804969, 5.610324162703294, 2.481885836674617, 0.8473265812947199, 1.6429722767609816, 2.988306082212008, 3.0846389073591967, 1.57790653522198, 2.9600324630737305, 1.1914495688218336, 2.101904135483962, 1.393529855287992, 1.8621271206782415, 1.4452681908240685, 1.4452681908240685]
loss_2 = [8.369011365450346, 7.599046083597036, 6.718450087767381, 8.369011365450346, 5.75238037109375, 5.74339431982774, 7.749084325937124, 7.749084325937124, 7.749084325937124, 7.581816526559683, 4.2616490584153395, 1.1291869420271654, 0.5565106043448815, 0.5997196481778071, 3.1864574138934794, 2.357718064234807, 1.352318213536189, 1.8143362632164588, 0.6173523664474487, 0.5731813449126023, 7.219507712584275, 2.319313801251925, 0.6619853148093591, 1.8206612421916082, 0.6721983597828791]
loss_3 = [8.369011072012094, 0.9422680598038894, 7.811781149644118, 8.369011072012094, 3.9517508286696215, 7.749084619375376, 7.749084619375376, 7.70846807039701, 5.380254672123836, 7.749084619375376, 7.749084619375376, 7.749084619375376, 7.585186591515174, 3.1645464713756857, 6.590637867267315, 2.686550103701078, 3.9747437055294332, 0.6500976016888251, 1.2384323248496423, 0.8797645316674159, 1.4758192667594323, 1.1663720172185164, 0.5258145790833694, 0.7858443970863636, 1.307841534797962]
loss_4 = [5.625346660614014, 3.2019597933842587, 3.8410296073326697, 3.770006986764761, 0.9313143606369312, 1.8935946317819448, 3.3253492208627553, 4.366023540496826, 7.594102639418382, 3.4208643986628604, 1.0799899468055139, 3.4639968872070312, 3.339703138058002, 0.7058906463476328, 1.1908281583052416, 4.880542131570669, 3.4760376856877255, 3.3132069294269266, 3.9066021625812235, 2.301914801964393, 1.6138017177581787, 1.5817110171684852, 1.9894196528654833, 1.6745697535001314, 1.6745697535001314]
loss_5 = [7.594102639418382, 2.4042452023579526, 1.1927171762172992, 7.541698895967924, 4.1200582430912895, 5.364261957315298, 6.007071715134841, 5.609856898968037, 1.190799383016733, 4.027746860797588, 4.082559035374568, 1.0818024140137892, 1.5787021013406606, 0.5487606204473056, 3.679063026721661, 1.4040602353902965, 3.948591158940242, 2.103640262897198, 0.9605796153728778, 0.7531196199930631, 0.6072824047161982, 0.6986557153555063, 0.868248462677002, 0.7495580223890451, 0.610065588584313]
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALL-IDB2 test set using data augmentation')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.6481927693608296, 0.8120481909039509, 0.9036144558205662, 0.9325301186147943, 0.939759036288204, 0.9710843374930233, 0.9783132531556739, 0.983132530120482, 0.9975903614457832, 1.0, 0.9975903614457832, 0.9927710844809751, 0.9951807228915662, 0.9975903614457832, 0.9855421686746988, 0.9951807228915662, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9927710843373494, 1.0, 0.9975903614457832]
acc_train_2 = [0.6481927716588399, 0.8698795185031661, 0.9204819255564586, 0.9542168674698795, 0.9759036144578314, 0.963855421686747, 0.9783132530120482, 0.9855421686746988, 0.9927710843373494, 0.9975903614457832, 0.9975903614457832, 0.9951807207371816, 0.9951807228915662, 0.9951807207371816, 0.9975903614457832, 0.9975903614457832, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9975903592913984, 0.9975903614457832]
acc_train_3 = [0.6457831329609974, 0.7831325308386102, 0.8819277109869992, 0.9012048171227237, 0.9373493955796024, 0.985542166520314, 0.9927710823265903, 0.975903614601457, 0.9951807228915662, 0.9927710821829646, 0.9951807228915662, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_4 = [0.6120481937764639, 0.7951807231788176, 0.8795180704220231, 0.9373493954359767, 0.9518072290592883, 0.9542168674698795, 0.9831325279660972, 0.9855421686746988, 0.9783132530120482, 0.987951805074531, 0.9951807228915662, 0.9903614457831326, 0.9927710843373494, 0.9951807228915662, 0.9903614459267582, 0.9951807228915662, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_5 = [0.62168674770608, 0.8265060246708882, 0.8843373496848417, 0.9493975905050714, 0.9614457832761558, 0.9903614457831326, 0.9903614457831326, 0.9903614457831326, 0.9831325302641076, 0.9927710843373494, 0.9951807228915662, 0.9975903614457832, 0.9927710843373494, 0.9951807228915662, 0.9975903614457832, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)

plt.plot(x_values, acc_train_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, acc_train_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, acc_train_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, acc_train_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, acc_train_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB2 train set using data augmentation')
plt.legend(loc='best')
plt.show()
'''

# ------------------------------------------------------------------------------------------

# Data aug + dropout
'''
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.6346153846153846, 0.5288461538461539, 0.6346153846153846, 0.4230769230769231, 0.4230769230769231, 0.47115384615384615, 0.5865384615384616, 0.6634615384615384, 0.47115384615384615, 0.4230769230769231, 0.5576923076923077, 0.6153846153846154, 0.4230769230769231, 0.7211538461538461, 0.5769230769230769, 0.5769230769230769, 0.5769230769230769, 0.6346153846153846, 0.4326923076923077, 0.5096153846153846, 0.5576923076923077, 0.5288461538461539, 0.5769230769230769, 0.6730769230769231, 0.6634615384615384]
accuracy_2 = [0.6346153846153846, 0.6346153846153846, 0.5192307692307693, 0.5, 0.5, 0.5, 0.7115384615384616, 0.6346153846153846, 0.5, 0.5, 0.5096153846153846, 0.4230769230769231, 0.5, 0.5096153846153846, 0.5096153846153846, 0.5865384615384616, 0.625, 0.5480769230769231, 0.5, 0.5, 0.7019230769230769, 0.49038461538461536, 0.5192307692307693, 0.625, 0.6442307692307693]
accuracy_3 = [0.6346153846153846, 0.6442307692307693, 0.6153846153846154, 0.4230769230769231, 0.5961538461538461, 0.6442307692307693, 0.5865384615384616, 0.4519230769230769, 0.4230769230769231, 0.4230769230769231, 0.4230769230769231, 0.4230769230769231, 0.4230769230769231, 0.4230769230769231, 0.4230769230769231, 0.4519230769230769, 0.6730769230769231, 0.4230769230769231, 0.5865384615384616, 0.6057692307692307, 0.5865384615384616, 0.5865384615384616, 0.5, 0.5865384615384616, 0.5865384615384616]
accuracy_4 = [0.5384615384615384, 0.5480769230769231, 0.5769230769230769, 0.5384615384615384, 0.5480769230769231, 0.5384615384615384, 0.5384615384615384, 0.5384615384615384, 0.5384615384615384, 0.5576923076923077, 0.5384615384615384, 0.5384615384615384, 0.5384615384615384, 0.5384615384615384, 0.4519230769230769, 0.5384615384615384, 0.5384615384615384, 0.5384615384615384, 0.5384615384615384, 0.5384615384615384, 0.5480769230769231, 0.6538461538461539, 0.6538461538461539, 0.6538461538461539, 0.6538461538461539]
accuracy_5 = [0.5384615384615384, 0.5865384615384616, 0.5480769230769231, 0.5, 0.6057692307692307, 0.6538461538461539, 0.5480769230769231, 0.5576923076923077, 0.5576923076923077, 0.5576923076923077, 0.5576923076923077, 0.5480769230769231, 0.5480769230769231, 0.5480769230769231, 0.5480769230769231, 0.5480769230769231, 0.5480769230769231, 0.5480769230769231, 0.5480769230769231, 0.5576923076923077, 0.49038461538461536, 0.5, 0.5288461538461539, 0.5865384615384616, 0.6826923076923077]
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB2 test set using data augmentation and dropout')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [0.6155453186768752, 1.0332956130688007, 1.2825252826397235, 5.6580071816077595, 2.7296344500321608, 2.195044810955341, 0.630128800868988, 0.7334180886928852, 1.4373284853421724, 1.442870488533607, 0.7090104726644663, 0.784976445711576, 3.8968709065363956, 0.5761629755680377, 0.8648826984258798, 0.9071173851306622, 0.8254566192626953, 0.7998597713617178, 9.143919724684496, 3.968236593099741, 1.7251675587434034, 1.219994251544659, 1.0515003296045156, 0.694499841103187, 0.7974524773084201]
loss_2 = [0.6705943231399243, 0.7106515490091764, 1.1032596734853892, 8.059047478895922, 1.6593132936037505, 1.536381565607511, 0.6320252235119159, 0.643060720883883, 0.8621186522337106, 1.121633768081665, 1.0703350030458891, 1.8823170845325177, 6.1822829980116625, 2.9747387720988345, 1.8655734153894277, 0.8920091986656189, 1.1618441480856676, 0.7760218565280621, 0.976232858804556, 1.5040707404796894, 0.6507451419646924, 1.471941507779635, 1.2195476568662202, 0.7762671617361215, 0.7044586172470679]
loss_3 = [0.6374854307908279, 1.2773682887737567, 0.9414571431966928, 9.255103844862719, 3.2594037789564867, 1.0550165268091054, 0.6060236325630775, 0.9401078040783222, 1.3996293819867647, 0.9608548146027786, 1.4455423538501446, 0.8925546728647672, 1.0439399755918062, 1.0876002311706543, 1.321941192333515, 0.8483671958629901, 0.5857575214826144, 1.8577505350112915, 0.7240110819156353, 0.5938345835759089, 0.9017634024986854, 1.1965361283375666, 0.7044778236976037, 1.0669427468226507, 0.9301656026106614]
loss_4 = [1.4863809989048884, 0.861062242434575, 0.7067245428378766, 0.7718453957484319, 1.2850183707017164, 7.301298434917744, 7.439121099618765, 3.0545872908372145, 2.622528442969689, 0.8151423747722919, 1.7539785825289214, 1.8800017100114088, 2.0798064195192776, 1.4889078873854418, 0.8083926806083093, 0.9369827233828031, 0.6884970389879667, 0.7144543207608737, 0.7469235842044537, 0.9874784029447116, 0.8955102333655725, 1.3886269422677846, 1.3371456586397612, 1.6684029835921068, 1.5343588498922496]
loss_5 = [0.607761942423307, 1.0903122975276067, 1.422483939390916, 1.2363085815539727, 0.8999752356455877, 1.025094564144428, 3.941232736294086, 0.9727338369076068, 1.4537194325373723, 1.5435291803800142, 1.6079040215565608, 1.7447206240433912, 1.5883229145636926, 1.4376207223305335, 1.011099242247068, 1.4465112594457774, 1.3084858472530658, 1.2330851279772246, 1.5356180117680476, 1.0144656162995558, 2.193765016702505, 1.3388913594759428, 0.900824601833637, 0.8471430356685932, 0.6887516287656931]
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALL-IDB2 test set using data augmentation and dropout')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.5686746972152986, 0.609638552780611, 0.6409638539854302, 0.6240963864039226, 0.6216867455516953, 0.616867470741272, 0.6433734922523958, 0.6698795166360326, 0.6843373502593443, 0.6361445771642478, 0.6409638562834407, 0.6578313238649484, 0.6530120489108994, 0.6650602418256093, 0.6746987940317177, 0.6939759017473244, 0.6843373481049595, 0.6891566250697676, 0.6722891573446342, 0.6819277096943683, 0.640963856139815, 0.6168674681560102, 0.6650602416819836, 0.677108434453068, 0.6722891573446342]
acc_train_2 = [0.5156626493097788, 0.5903614463576351, 0.5662650591637715, 0.6650602396712245, 0.6361445767333709, 0.6481927697917065, 0.6481927699353321, 0.6506024076277951, 0.6192771092954888, 0.6746987958988512, 0.6674698780818158, 0.6433734926832728, 0.6698795190776687, 0.626506022660129, 0.6240963864039226, 0.6506024105003081, 0.6337349383227796, 0.6722891573446342, 0.6289156632251051, 0.5783132518630429, 0.6361445790313812, 0.6819277091198657, 0.6481927719460913, 0.6457831332482488, 0.6674698805234518]
acc_train_3 = [0.5566265067422246, 0.6144578323306807, 0.640963853698179, 0.6000000010053795, 0.6192771068538528, 0.602409637261586, 0.6361445791750069, 0.6361445771642478, 0.6433734948376575, 0.6626506012606334, 0.616867470741272, 0.6265060228037547, 0.6337349384664053, 0.6650602401739143, 0.6578313241521996, 0.6554216851671057, 0.6987951811537685, 0.6578313238649484, 0.669879516492407, 0.6746987958988512, 0.6891566250697676, 0.6939759044762117, 0.681927709407117, 0.6891566270805267, 0.6433734923960215]
acc_train_4 = [0.5638554202504905, 0.6313253019229476, 0.6216867458389466, 0.6024096374770245, 0.6626506008297564, 0.6361445767333709, 0.5879518082342952, 0.5734939769089941, 0.5566265051623425, 0.5975903601531523, 0.6289156613579716, 0.6554216874651162, 0.645783131093864, 0.6144578303199216, 0.6240963845367892, 0.6746987957552255, 0.6578313237213227, 0.6192771091518632, 0.640963856139815, 0.6361445773796863, 0.63373494062079, 0.6481927696480808, 0.621686745695321, 0.6216867458389466, 0.6216867454080697]
acc_train_5 = [0.6120481913348278, 0.6072289162371532, 0.6481927696480808, 0.6385542178728494, 0.6120481913348278, 0.6915662656347435, 0.6457831313811153, 0.62168674770608, 0.6385542152875877, 0.6024096394159708, 0.6361445790313812, 0.5879518078034183, 0.6939759020345757, 0.6650602418256093, 0.6337349384664053, 0.6385542158620904, 0.6313253020665732, 0.5927710829010929, 0.6674698799489492, 0.6554216874651162, 0.6843373501157186, 0.6602409627782293, 0.669879516492407, 0.6433734945504063, 0.6578313258757075]
avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)

plt.plot(x_values, acc_train_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, acc_train_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, acc_train_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, acc_train_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, acc_train_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB2 train set using data augmentation and dropout')
plt.legend(loc='best')
plt.show()
'''
'''
# Greyscale

# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5576923122772803, 0.5, 0.75, 0.7884615476314838, 0.75, 0.7884615384615384, 0.7884615384615384, 0.7692307692307693, 0.5961538461538461, 0.7500000045849726, 0.5384615384615384, 0.7115384615384616, 0.7692307738157419, 0.7115384615384616, 0.7500000045849726, 0.7692307738157419, 0.7115384615384616, 0.7115384615384616, 0.7115384615384616, 0.7115384615384616]
accuracy_2 = [0.5769230723381042, 0.7692307692307693, 0.6730769276618958, 0.6538461538461539, 0.5961538461538461, 0.6923076923076923, 0.75, 0.6730769276618958, 0.6346153846153846, 0.7307692261842581, 0.7307692261842581, 0.75, 0.7115384569534888, 0.692307696892665, 0.6730769276618958, 0.6153846153846154, 0.6730769276618958, 0.7307692215992854, 0.7499999954150274, 0.7692307692307693, 0.7692307692307693, 0.7884615384615384, 0.7692307692307693, 0.8269230860930222, 0.7499999908300546]
accuracy_3 = [0.5384615430465112, 0.5384615430465112, 0.5384615430465112, 0.5384615430465112, 0.4615384569534889, 0.615384619969588, 0.6923076831377469, 0.7884615476314838, 0.6923076923076923, 0.7884615476314838, 0.5576923122772803, 0.7692307738157419, 0.4615384569534889, 0.4615384569534889, 0.4615384569534889, 0.4615384569534889, 0.4615384569534889, 0.5769230815080496, 0.7500000045849726, 0.5961538507388189, 0.5961538507388189, 0.6346153937853299, 0.7115384661234342, 0.6730769276618958, 0.6538461584311265]
accuracy_4 = [0.5769230677531316, 0.6153846107996427, 0.5769230677531316, 0.5769230677531316, 0.5769230677531316, 0.5961538369839008, 0.6153846062146701, 0.6730769139069778, 0.6153846062146701, 0.7884615384615384, 0.5576923122772803, 0.8076923076923077, 0.7500000045849726, 0.5769230677531316, 0.5769230677531316, 0.7115384569534888, 0.8461538553237915, 0.7115384615384616, 0.6153846062146701, 0.5769230677531316, 0.6538461492611811, 0.7884615384615384, 0.8461538553237915, 0.7884615476314838, 0.8461538553237915]
accuracy_5 = [0.442307690015206, 0.5576922985223624, 0.5576922985223624, 0.5576922985223624, 0.5576922985223624, 0.5576922985223624, 0.5576922985223624, 0.5576922985223624, 0.5576922985223624, 0.5576922985223624, 0.5576922985223624, 0.6346153846153846, 0.5576922985223624, 0.5576922985223624, 0.5576922985223624, 0.5576922985223624, 0.5576922985223624, 0.5576922985223624, 0.5576922985223624, 0.5576922985223624, 0.5576922985223624, 0.5576922985223624, 0.5769230723381042, 0.5769230723381042, 0.7307692353542035]
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)
print(avg_acc)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB2 test set using greyscale')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [8.059048065772423, 8.059048065772423, 8.059048065772423, 7.403459475590632, 3.397338261971107, 2.019991838015043, 3.3741796750288744, 0.9978661353771503, 0.8137507026012127, 0.5259228807229263, 0.5860035602863019, 0.6334565327717707, 0.6150246766897348, 1.7145951161017785, 0.6495263072160574, 2.2446999549865723, 0.7527853067104633, 0.9506644010543823, 2.124811896911034, 0.9506644010543823, 0.9506644010543823, 2.124811896911034, 0.9506644010543823, 0.9506644010543823, 0.9506644010543823]
loss_2 = [6.819193913386418, 0.4321920115214128, 1.2482318236277654, 1.760635522695688, 2.6313733137570896, 0.599175865833576, 0.6599103670853835, 0.6503034921792837, 0.7321503735505618, 0.6507158737916213, 0.5798293397976801, 0.5982428720364203, 0.5029999338663541, 1.235704174408546, 2.5119532438424916, 4.00090111218966, 1.2973783016204834, 0.9472176661858192, 0.8224225411048303, 0.6369455869381244, 0.6808611154556274, 0.7941864362129798, 0.5511162235186651, 0.4277327198248643, 1.16271134523245]
loss_3 = [7.439121246337891, 5.935476229741023, 7.439121246337891, 4.921676855820876, 8.666347577021671, 1.1017230840829701, 0.86645180445451, 0.41108920023991513, 0.4853384540631221, 0.37383472002469575, 2.270271741426908, 0.6773445697931143, 8.678974811847393, 8.580059051513672, 5.274279557741606, 6.380793057955229, 5.092827980334942, 1.9911360373863807, 0.6078050411664523, 1.8520731925964355, 1.5285820777599628, 1.257789079959576, 1.3703172573676476, 2.247182791049664, 1.5615410713049083]
loss_4 = [6.124577962435209, 1.8073864533351018, 5.436448867504414, 4.475047313250029, 2.5299582481384277, 1.44458741408128, 1.0400920601991506, 0.5016840788034292, 0.9400160771149856, 0.41101862834050107, 0.8763379958959726, 0.35360952065541196, 0.6947994140478281, 2.3252651508037863, 3.755363794473501, 1.3974264401655931, 0.3906552791595459, 1.1360594859490027, 1.7266203623551588, 3.251713275909424, 1.0919539378239558, 0.37905460137587327, 0.3222599900685824, 0.6033415381725018, 1.0080512807919428]
loss_5 = [8.261747653667744, 7.129157653221717, 7.129157653221717, 6.795080478374775, 6.920125851264367, 4.320798287024865, 2.887266452495868, 4.250064519735483, 2.992388468522292, 3.1498719362112193, 3.3117593068342943, 0.70769929427367, 2.9741545090308557, 6.619099433605488, 7.129157653221717, 4.75134303019597, 7.016035446753869, 5.91988101372352, 3.976350344144381, 3.3269934470836935, 3.2819269620455227, 3.739975012265719, 3.032052461917584, 2.2919604044694166, 0.8037187778032743]
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)
print(avg_loss)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALL-IDB2 test set using greyscale')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.7163461538461539, 0.8605769230769231, 0.9230769230769231, 0.9423076923076923, 0.9711538461538461, 0.9903846153846154, 0.9951923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9951923076923077, 0.9951923076923077, 0.9855769230769231, 0.9951923076923077, 0.9951923076923077, 1.0, 1.0, 1.0, 0.9951923076923077, 1.0, 0.9903846153846154, 0.9951923076923077, 0.9951923076923077]
acc_train_2 = [0.6778846153846154, 0.8413461538461539, 0.8990384615384616, 0.9519230769230769, 0.9759615384615384, 0.9807692307692307, 0.9903846153846154, 0.9951923076923077, 1.0, 1.0, 1.0, 0.9951923076923077, 1.0, 0.9615384615384616, 0.9951923076923077, 0.9903846153846154, 0.9903846153846154, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_3 = [0.7115384615384616, 0.8413461538461539, 0.9038461538461539, 0.9711538461538461, 0.9807692307692307, 0.9951923076923077, 0.9951923076923077, 0.9903846153846154, 1.0, 0.9951923076923077, 0.9951923076923077, 1.0, 0.9951923076923077, 1.0, 1.0, 0.9951923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9951923076923077, 0.9855769230769231, 0.9951923076923077, 1.0]
acc_train_4 = [0.6634615384615384, 0.8798076923076923, 0.9278846153846154, 0.9326923076923077, 0.9951923076923077, 0.9807692307692307, 0.9951923076923077, 1.0, 0.9951923076923077, 1.0, 0.9903846153846154, 0.9951923076923077, 1.0, 1.0, 0.9903846153846154, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_5 = [0.6538461538461539, 0.8605769230769231, 0.9182692307692307, 0.9471153846153846, 0.9615384615384616, 0.9759615384615384, 0.9855769230769231, 0.9903846153846154, 1.0, 0.9951923076923077, 1.0, 0.9951923076923077, 1.0, 1.0, 1.0, 1.0, 0.9951923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)
print(avg_acc_train)

plt.plot(x_values, acc_train_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, acc_train_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, acc_train_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, acc_train_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, acc_train_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB2 train set using greyscale')
plt.legend(loc='best')
plt.show()
'''
'''
# Contrast increase 
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.8269230677531316, 0.7115384661234342, 0.6346153892003573, 0.7307692307692307, 0.7692307738157419, 0.8076923168622531, 0.8461538369839008, 0.8076923168622531, 0.7115384661234342, 0.8269230860930222, 0.8461538553237915, 0.8269230860930222, 0.692307696892665, 0.5769230860930222, 0.7115384615384616, 0.5961538369839008, 0.5769230860930222, 0.8269230815080496, 0.75, 0.865384619969588, 0.807692303107335, 0.8461538507388189, 0.8846153892003573, 0.8846153892003573, 0.8653846153846154]
accuracy_2 = [0.7115384615384616, 0.7307692353542035, 0.6346153846153846, 0.6538461584311265, 0.8461538507388189, 0.75, 0.7307692261842581, 0.8461538507388189, 0.8461538507388189, 0.8461538507388189, 0.8461538553237915, 0.8269230815080496, 0.8269230815080496, 0.8076923122772803, 0.6730769184919504, 0.7115384615384616, 0.8269230860930222, 0.8269230860930222, 0.7500000045849726, 0.7307692353542035, 0.7500000045849726, 0.8076923122772803, 0.7500000045849726, 0.7115384661234342, 0.7500000045849726]
accuracy_3 = [0.7115384523685162, 0.8461538507388189, 0.6730769184919504, 0.6346153846153846, 0.7884615430465112, 0.8461538507388189, 0.5961538484463325, 0.8269230769230769, 0.6153846107996427, 0.75, 0.8269230815080496, 0.9038461630160992, 0.9230769322468684, 0.9423077014776376, 0.9230769322468684, 0.9230769322468684, 0.7500000091699454, 0.692307696892665, 0.692307696892665, 0.7307692353542035, 0.7884615292915931, 0.9038461630160992, 0.865384619969588, 0.807692303107335, 0.807692303107335]
accuracy_4 = [0.6346153846153846, 0.615384619969588, 0.5769230860930222, 0.5192307738157419, 0.615384619969588, 0.615384619969588, 0.6346153846153846, 0.615384619969588, 0.6538461584311265, 0.4230769184919504, 0.8269230860930222, 0.6730769184919504, 0.5961538461538461, 0.615384619969588, 0.6346153892003573, 0.6346153846153846, 0.615384619969588, 0.615384619969588, 0.615384619969588, 0.6153846153846154, 0.6346153892003573, 0.615384619969588, 0.615384619969588, 0.7115384707084069, 0.7884615338765658]
accuracy_5 = [0.6538461446762085, 0.6538461630160992, 0.4807692284767444, 0.6730769139069778, 0.7115384661234342, 0.6346153892003573, 0.7692307646457965, 0.7499999954150274, 0.6730769322468684, 0.6923077014776376, 0.6730769322468684, 0.5384615407540247, 0.5769230769230769, 0.6730769322468684, 0.5384615407540247, 0.4615384638309479, 0.5769230769230769, 0.6346153892003573, 0.6923077014776376, 0.4807692330617171, 0.6923076831377469, 0.8653846245545608, 0.7884615384615384, 0.6346153892003573, 0.8076923076923077]
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)
print(avg_acc)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB2 test set with contrast increase')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [0.864364715722891, 0.6957989289210393, 0.6940040634228632, 0.4841446532652928, 0.45380953412789565, 0.44740748634705174, 0.33930665025344264, 0.5158746380072373, 0.9115061301451463, 0.4491606079615079, 0.4642975605451144, 0.5061048177572397, 0.8824005081103399, 1.8098766528643095, 0.7085851201644311, 1.8997184129861684, 1.958901047706604, 0.47011467126699596, 0.462212846829341, 0.3515009513268104, 0.5859225713289701, 0.38457984649218047, 0.2833736722285931, 0.2931985534154452, 0.3394745404903705]
loss_2 = [2.5290605288285475, 0.7967257912342365, 0.8173825740814209, 0.6269093476808988, 0.44235068559646606, 0.7964013173029973, 1.0349697516514704, 0.7083329879320585, 0.6341753097680899, 0.43859070997971755, 0.45305813275850737, 0.5418481139036325, 0.6044567823410034, 0.5906924926317655, 0.9226377973189721, 0.8506774994043204, 0.701022024338062, 0.8135563272696275, 0.8482938271302444, 0.8253875191395099, 0.7396909090188833, 0.6941423461987422, 0.8077180064641513, 0.8748302918214065, 0.8005314973684458]
loss_3 = [0.5619717377882737, 0.44468677043914795, 0.7625426695897028, 0.8980886340141296, 0.5126791160840255, 0.35877471932998073, 1.2986776003470788, 0.4078717552698575, 1.5788256846941435, 1.2321703342291026, 0.5171740788679856, 0.24012158237970793, 0.1728559801211724, 0.16267087826362023, 0.28747984537711513, 0.23109105687875015, 0.5406679648619431, 0.8464937760279729, 0.774848461151123, 0.5939463560397809, 0.39990482422021717, 0.2936849089769217, 0.31948745250701904, 0.364991531922267, 0.3345870283933786]
loss_4 = [0.9435350161332351, 2.8549684377817006, 1.1235549633319561, 1.341278076171875, 5.646051773658166, 1.870518445968628, 0.8337045999673697, 1.2189018726348877, 0.8033162997319148, 5.15783430979802, 0.5948222325398371, 0.6285173296928406, 1.0179103429500873, 2.0446709119356594, 1.179181429056021, 0.8386805424323449, 1.3316906598898082, 1.528894149340116, 1.1060914076291597, 0.9500723802126371, 0.9576230140832754, 1.061726946097154, 1.2566222227536714, 0.5932402885877169, 0.4795816265619718]
loss_5 = [1.725147531582759, 0.7707065022908725, 1.4385396608939538, 0.7685644901715792, 0.6944073942991403, 0.7716818176783048, 0.5344788019473736, 0.5506779597355769, 0.6532694330582252, 0.6063068188153781, 0.744845619568458, 1.408538506581233, 1.2182721541478083, 0.8258318259165838, 1.2909281437213604, 1.6378913109119122, 1.191487770814162, 0.8624618970430814, 0.7500678300857544, 1.8118368295522838, 0.8586284747490516, 0.3213261434665093, 0.45936100299541766, 0.9961569309234619, 0.42389724346307606]
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)
print(avg_loss)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALL-IDB2 test set with contrast increase')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.625, 0.8605769230769231, 0.9423076923076923, 0.9711538461538461, 0.9711538461538461, 0.9903846153846154, 0.9951923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9951923076923077, 1.0, 1.0, 1.0, 0.9903846153846154, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_2 = [0.7115384615384616, 0.8942307692307693, 0.9663461538461539, 0.9615384615384616, 1.0, 0.9711538461538461, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_3 = [0.7019230769230769, 0.9134615384615384, 0.9711538461538461, 0.9855769230769231, 0.9951923076923077, 1.0, 0.9759615384615384, 1.0, 0.9951923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_4 = [0.6971153846153846, 0.8798076923076923, 0.9471153846153846, 0.9615384615384616, 0.9711538461538461, 0.9855769230769231, 0.9951923076923077, 1.0, 0.9951923076923077, 1.0, 1.0, 1.0, 0.9951923076923077, 1.0, 0.9951923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_5 = [0.6778846153846154, 0.8701923076923077, 0.9326923076923077, 0.9903846153846154, 0.9903846153846154, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)
print(avg_acc_train)

plt.plot(x_values, acc_train_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, acc_train_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, acc_train_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, acc_train_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, acc_train_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB2 train set with contrast increase')
plt.legend(loc='best')
plt.show()
'''

# ---------------------------------------------------------------------- 
'''
# hist eq
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.4807692330617171, 0.4807692330617171, 0.4807692330617171, 0.5192307646457965, 0.4807692330617171, 0.4807692330617171, 0.4807692330617171, 0.4807692330617171, 0.4807692330617171, 0.6153846153846154, 0.634615380030412, 0.6730769230769231, 0.4807692330617171, 0.6538461538461539, 0.6538461538461539, 0.7115384661234342, 0.7115384707084069, 0.6923077014776376, 0.6923076831377469, 0.7307692215992854, 0.7115384523685162, 0.7307692215992854, 0.6923077014776376, 0.7115384523685162, 0.7307692215992854]
accuracy_2 = [0.6346153846153846, 0.44230769689266497, 0.44230769689266497, 0.44230769689266497, 0.44230769689266497, 0.5576923168622531, 0.6730769184919504, 0.7499999908300546, 0.7307692399391761, 0.7499999954150274, 0.7307692399391761, 0.7115384661234342, 0.7307692399391761, 0.6346153846153846, 0.7307692215992854, 0.7307692307692307, 0.7115384569534888, 0.7692307784007146, 0.7115384661234342, 0.7307692353542035, 0.7115384615384616, 0.7692307692307693, 0.7692307692307693, 0.7692307692307693, 0.7692307692307693]
accuracy_3 = [0.5769230815080496, 0.5769230815080496, 0.5769230815080496, 0.5769230815080496, 0.7307692307692307, 0.7499999954150274, 0.7499999954150274, 0.7884615384615384, 0.7692307646457965, 0.7307692261842581, 0.8269230769230769, 0.8269230769230769, 0.8269230769230769, 0.8269230769230769, 0.7307692215992854, 0.6730769139069778, 0.7692307646457965, 0.7692307646457965, 0.7499999954150274, 0.7499999954150274, 0.8076923122772803, 0.7884615384615384, 0.7692307692307693, 0.7692307692307693, 0.7884615384615384]
accuracy_4 = [0.5384615476314838, 0.5384615476314838, 0.5384615476314838, 0.5384615476314838, 0.5961538369839008, 0.7500000045849726, 0.7307692307692307, 0.6730769184919504, 0.6923076923076923, 0.6153846245545608, 0.5384615476314838, 0.5384615476314838, 0.5384615476314838, 0.5576922985223624, 0.5961538415688735, 0.7884615476314838, 0.8076923076923077, 0.8076923076923077, 0.8461538507388189, 0.8269230769230769, 0.7692307600608239, 0.7499999908300546, 0.7115384523685162, 0.6923076831377469, 0.7499999908300546]
accuracy_5 = [0.5576922985223624, 0.5576922985223624, 0.5961538369839008, 0.7115384569534888, 0.5576922985223624, 0.6346153754454392, 0.6538461492611811, 0.6730769184919504, 0.6923076923076923, 0.6730769184919504, 0.6538461446762085, 0.6346153937853299, 0.6730769322468684, 0.6730769322468684, 0.6346153937853299, 0.5576922985223624, 0.5576922985223624, 0.5576922985223624, 0.5576922985223624, 0.5576922985223624, 0.5576922985223624, 0.6153846107996427, 0.6538461492611811, 0.6730769184919504, 0.6538461446762085]
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)
print(avg_acc)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB2 test set with histogram equalizer')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [8.369011292090782, 7.842367612398588, 4.600455944354717, 2.818073566143329, 8.369011292090782, 6.99545537508451, 6.107790360083947, 5.738321817838228, 4.421698533571684, 3.1383658922635593, 2.216950930081881, 1.2922651034135084, 5.1992585842426005, 1.9294740420121412, 1.2433793728168194, 1.0287308142735407, 0.9135050040024978, 0.8341373021786029, 0.9170125997983493, 0.9872097052060641, 1.007631595318134, 0.981812073634221, 0.9722012739915115, 1.02547248510214, 1.0324325928321252]
loss_2 = [1.3219596239236684, 7.132320770850549, 5.918105638944185, 3.996590100801908, 8.547991019028883, 2.1107484652445865, 0.6047049256471487, 0.5627756531421955, 0.5314311201755817, 0.4986952726657574, 0.634574124446282, 0.6250216456559988, 0.6366673983060397, 1.1468145755621104, 0.5993159688436068, 0.5486596822738647, 0.5803488813913785, 0.5150236647862655, 0.8907639246720535, 1.0665722947854261, 0.6572527289390564, 0.4998142306621258, 0.4998142306621258, 0.4998142306621258, 0.4998142306621258]
loss_3 = [5.697539146129902, 4.801795739393968, 6.2489753136268025, 2.752475243348342, 0.9622595310211182, 0.4967071001346295, 0.5473283712680523, 0.4751472473144531, 0.5477341871995193, 0.6439992556205163, 0.4574238107754634, 0.47087156084867626, 0.4812429891182826, 0.49167380883143497, 0.48861013925992525, 0.6436143150696387, 0.5253866131489093, 0.5375067270719088, 0.521610466333536, 0.598304597231058, 0.6403449498690091, 0.6335098376640906, 0.6132099399199853, 0.5892881521811852, 0.5594748212740972]
loss_4 = [7.081055274376502, 6.74044942855835, 4.579784961847158, 2.856363241489117, 1.4828473788041334, 0.6042841856296246, 0.4782526515997373, 0.5531037358137277, 0.7030455149137057, 0.7301681912862338, 7.439120879540076, 7.439120879540076, 5.510257610907922, 3.4086158092205343, 1.9492609042387743, 0.5714583534460801, 0.3519130830581372, 0.34262983615581805, 0.34553353832318234, 0.3767409370495723, 0.47092116337556106, 0.5401047834983239, 0.5789078657443707, 0.641141231243427, 0.7136257611788236]
loss_5 = [5.9801153769859905, 5.459784507751465, 2.26524608868819, 0.6966090660828811, 3.6658232028667745, 1.6506521243315477, 1.5192957841433012, 0.9449153725917523, 0.7362904227696933, 0.9396235484343308, 1.0072684012926543, 0.9627452951211196, 0.9294896079943731, 0.9328608971375686, 1.0203795799842248, 7.129157653221717, 7.129157653221717, 7.129157653221717, 7.118138460012583, 6.3543141438410835, 4.458824854630691, 2.683581297214215, 2.2685034641852746, 2.041714072227478, 1.9566265161220844]
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)
print(avg_loss)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALL-IDB2 test set with histogram equalizer')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.6201923076923077, 0.9086538461538461, 0.9519230769230769, 0.9663461538461539, 1.0, 0.9903846153846154, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_2 = [0.6105769230769231, 0.9230769230769231, 0.9807692307692307, 0.9903846153846154, 0.9951923076923077, 1.0, 0.9951923076923077, 1.0, 0.9951923076923077, 0.9903846153846154, 1.0, 0.9903846153846154, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_3 = [0.6057692307692307, 0.8701923076923077, 0.9471153846153846, 0.9855769230769231, 0.9903846153846154, 0.9951923076923077, 1.0, 1.0, 0.9951923076923077, 1.0, 0.9951923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_4 = [0.5528846153846154, 0.8990384615384616, 0.9759615384615384, 0.9807692307692307, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_5 = [0.6442307692307693, 0.9134615384615384, 0.9807692307692307, 0.9759615384615384, 0.9951923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)
print(avg_acc_train)

plt.plot(x_values, acc_train_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, acc_train_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, acc_train_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, acc_train_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, acc_train_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB2 train set with histogram equalizer')
plt.legend(loc='best')
plt.show()
'''
'''
# 3 filters comparison 
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.5269230746305905, 0.5961538443198571, 0.5692307673967801, 0.5653846126336318, 0.5384615338765658, 0.6038461520121647, 0.6230769175749559, 0.688461537544544, 0.6576923058583186, 0.7230769221599285, 0.6384615375445438, 0.7500000009169946, 0.6499999972490162, 0.5769230732550988, 0.6038461510951703, 0.5769230732550987, 0.65, 0.6692307673967801, 0.6769230732550988, 0.649999998166011, 0.6692307683137746, 0.6961538461538461, 0.7230769249109121, 0.7153846190525937, 0.7153846190525937]
accuracy_2 = [0.7076923021903405, 0.7115384670404288, 0.6000000013754919, 0.6423076923076922, 0.7461538507388188, 0.7307692353542036, 0.7153846121751345, 0.7692307719817529, 0.7000000036679781, 0.7076923113602859, 0.8038461620991046, 0.7538461579726293, 0.7230769267449013, 0.7230769304128793, 0.6961538484463325, 0.6653846158431127, 0.6692307756497309, 0.7192307747327364, 0.7000000045849727, 0.6846153878248654, 0.734615381864401, 0.8076923141112694, 0.7807692344372089, 0.7500000036679781, 0.8038461529291594]
accuracy_3 = [0.5576923090677994, 0.5192307715232556, 0.5269230792155633, 0.5576923095262967, 0.5615384592459752, 0.6346153850738819, 0.6576923053998213, 0.6730769198674422, 0.6730769244524148, 0.6769230760060825, 0.6769230778400714, 0.6769230815080496, 0.6500000059604645, 0.6692307692307692, 0.6692307664797855, 0.6923076913906978, 0.7115384597044725, 0.7192307701477637, 0.711538458787478, 0.719230765562791, 0.7115384569534888, 0.7307692261842581, 0.7192307683137746, 0.7230769184919504, 0.7384615329595713]

plt.plot(x_values, accuracy_1, label="Greyscale", linewidth=1)
plt.plot(x_values, accuracy_2, label="Contrast increased", linewidth=1)
plt.plot(x_values, accuracy_3, label="Histogram equalizer", linewidth=1) 

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Average model accuracy on ALL-IDB2 test set by applied filters')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [7.340737768319937, 4.6726520827183355, 5.862401531292842, 5.0711799291464, 4.829028650430533, 1.897255297807547, 1.7655800718527572, 1.3622014852670525, 1.192728815170435, 1.0222728078181926, 1.5248403888482314, 0.5940705579060775, 2.6931906690964333, 4.094944585286654, 3.8640561112990746, 3.7550327190986046, 2.909936462915861, 2.188991720859821, 1.8516020371363713, 2.003677980716412, 1.5067976988278902, 1.6591634053450364, 1.2452820667853721, 1.3041763709141658, 1.0973373752373914]
loss_2 = [1.3248159060111413, 1.1125772861333993, 0.9672047862639793, 0.8237970402607552, 1.5498597007531385, 0.8489567573253926, 0.808227480833347, 0.6803318427159235, 0.916218571479504, 1.5768125561567454, 0.5548395248559805, 0.6650260700629308, 0.7791791535340822, 1.0867485523223877, 0.8777624671275799, 1.0916117645226993, 1.144753893522116, 0.9043041641895588, 0.7883028745651245, 0.9065488072542044, 0.7083539586800796, 0.5510920382463016, 0.6253124713897705, 0.6244835193340595, 0.4756143872554485]
loss_3 = [5.689936142701368, 6.395343611790584, 4.722513589492211, 2.6240222435731155, 4.605586484762339, 2.37156945008498, 1.8514744185484375, 1.6548527653400715, 1.3880399557260368, 1.1901704320540796, 2.351067629227271, 2.158004896915876, 2.5513832381138437, 1.5818878265527578, 1.0601891930286702, 1.9843241636569684, 1.9000622469645279, 1.8716910366828625, 1.9586117978279407, 1.876628335622641, 1.4469950584264903, 1.067764444534595, 0.9865273549006535, 0.9594860342832712, 0.9523947844138512]

plt.plot(x_values, loss_1, label="Greyscale", linewidth=1)
plt.plot(x_values, loss_2, label="Contrast increased", linewidth=1)
plt.plot(x_values, loss_3, label="Histogram equalizer", linewidth=1) 

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Average model loss on ALL-IDB2 test set by applied filters')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.6846153846153846, 0.8567307692307693, 0.9144230769230768, 0.9490384615384617, 0.976923076923077, 0.9846153846153847, 0.9923076923076923, 0.9951923076923077, 0.9990384615384615, 0.998076923076923, 0.9971153846153846, 0.9971153846153845, 0.998076923076923, 0.9913461538461539, 0.9942307692307694, 0.9961538461538462, 0.9961538461538462, 1.0, 1.0, 1.0, 0.9990384615384615, 0.9990384615384615, 0.9951923076923077, 0.998076923076923, 0.9990384615384615]
acc_train_2 = [0.6826923076923077, 0.8836538461538461, 0.951923076923077, 0.9740384615384616, 0.9855769230769231, 0.989423076923077, 0.9932692307692308, 1.0, 0.998076923076923, 1.0, 1.0, 1.0, 0.9990384615384615, 1.0, 0.9990384615384615, 0.9990384615384615, 1.0, 1.0, 1.0, 0.998076923076923, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_3 = [0.6067307692307693, 0.9028846153846153, 0.9673076923076922, 0.9798076923076924, 0.9961538461538462, 0.9971153846153846, 0.9990384615384615, 1.0, 0.998076923076923, 0.998076923076923, 0.9990384615384615, 0.998076923076923, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

plt.plot(x_values, acc_train_1, label="Greyscale", linewidth=1)
plt.plot(x_values, acc_train_2, label="Contrast increased", linewidth=1)
plt.plot(x_values, acc_train_3, label="Histogram equalizer", linewidth=1) 

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Average model accuracy on ALL-IDB2 train set by applied filters')
plt.legend(loc='best')
plt.show()
'''

# 200X200
'''
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.5576923168622531, 0.44230769460017866, 0.44230769460017866, 0.5576923168622531, 0.5576923168622531, 0.5576923168622531, 0.5576923168622531, 0.5576923168622531, 0.634615380030412, 0.44230769460017866, 0.5769230860930222, 0.7115384615384616, 0.634615380030412, 0.5576923168622531, 0.6538461492611811, 0.44230769460017866, 0.5192307692307693, 0.4807692307692308, 0.5769230860930222, 0.6923076877227197, 0.8076923076923077, 0.7500000045849726, 0.7115384569534888, 0.7884615338765658, 0.6923076923076923]
accuracy_2 = [0.4807692330617171, 0.5192307784007146, 0.5384615476314838, 0.5192307784007146, 0.5384615476314838, 0.6923076831377469, 0.6538461584311265, 0.6538461584311265, 0.6923076831377469, 0.5384615338765658, 0.5192307784007146, 0.5192307784007146, 0.5384615476314838, 0.5192307784007146, 0.7115384707084069, 0.7115384707084069, 0.5384615476314838, 0.6538461538461539, 0.6346153892003573, 0.8076923122772803, 0.7692307692307693, 0.7884615338765658, 0.6730769184919504, 0.6923076877227197, 0.6538461492611811]
accuracy_3 = [0.6346153754454392, 0.4807692330617171, 0.6346153754454392, 0.6153846062146701, 0.36538461309212905, 0.4038461492611812, 0.6346153754454392, 0.6346153754454392, 0.6346153754454392, 0.36538461309212905, 0.38461538232289827, 0.5000000022924863, 0.5576923076923077, 0.5000000022924863, 0.36538461309212905, 0.36538461309212905, 0.36538461309212905, 0.36538461309212905, 0.36538461309212905, 0.36538461309212905, 0.40384615613864017, 0.5000000022924863, 0.5000000022924863, 0.5576923076923077, 0.7500000091699454]
accuracy_4 = [0.5192307715232556, 0.48076923993917614, 0.48076923993917614, 0.48076923993917614, 0.48076923993917614, 0.48076923993917614, 0.48076923993917614, 0.48076923993917614, 0.48076923993917614, 0.48076923993917614, 0.5192307784007146, 0.5769230723381042, 0.6153846107996427, 0.6346153892003573, 0.6538461538461539, 0.5769230769230769, 0.6153846153846154, 0.5576922985223624, 0.5769230677531316, 0.557692309984794, 0.6730769276618958, 0.5576922985223624, 0.6153846153846154, 0.6153846153846154, 0.6730769276618958]
accuracy_5 = [0.5192307738157419, 0.692307696892665, 0.6346153846153846, 0.6923076831377469, 0.6153846107996427, 0.7115384661234342, 0.6730769184919504, 0.4807692261842581, 0.4999999954150273, 0.4807692261842581, 0.4807692261842581, 0.4807692261842581, 0.5769230723381042, 0.4807692261842581, 0.4807692261842581, 0.5961538415688735, 0.5769230723381042, 0.4999999954150273, 0.6538461446762085, 0.6538461492611811, 0.4807692261842581, 0.5192307738157419, 0.5769230723381042, 0.5769230723381042, 0.5769230723381042]
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB2 test set using larger rescale (200x200)')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [4.982059368720422, 7.499619263869065, 5.4887279363778925, 7.129157653221717, 7.129157653221717, 7.129157653221717, 6.200233752910908, 4.66158390045166, 0.6761705050101647, 1.4766591695638804, 1.2436208541576679, 0.5123988756766686, 1.0594929456710815, 2.112713281924908, 0.6935319808813242, 2.6231665978064904, 1.2404829538785493, 1.2319189401773305, 2.480406724489652, 1.144694814315209, 0.48372020629736096, 0.9033579734655527, 1.2302001898105328, 0.426294948046024, 0.5249123710852402]
loss_2 = [8.369011292090782, 7.630395082327036, 3.5424854938800516, 4.686658235696646, 2.7884764671325684, 0.6223131968424871, 0.6596618478114789, 0.6888827085494995, 0.6332421577893771, 1.2781624794006348, 7.749084399296687, 4.4355857372283936, 2.1203142129457913, 3.7865264415740967, 0.8332429253138028, 0.7764756954633273, 1.9694395798903246, 0.5375565886497498, 1.467429023522597, 0.48678895372610825, 0.652891585460076, 0.6457274785408607, 0.5297302191074078, 0.757012243454273, 0.680192388021029]
loss_3 = [2.159650133206294, 2.1051666736602783, 3.6249737556164083, 2.9178103667039137, 9.710843673119179, 1.549729090470534, 2.492724455319918, 1.2617974602259123, 3.980119283382709, 6.098807188180777, 6.690628308516282, 3.1858737468719482, 1.1644628231342022, 2.754676965566782, 8.607815522413988, 10.228791603675255, 10.220561834482046, 10.174321834857647, 9.75655541053185, 8.564399719238281, 7.318191381601187, 5.366579789381761, 2.232848992714515, 1.7645368392650898, 0.6501999910061176]
loss_4 = [6.515333102299617, 8.362872710594765, 8.369011438809908, 4.665110698113074, 5.778916872464693, 8.369011438809908, 7.238543547116793, 3.901915880349966, 4.299383053412805, 2.309619747675382, 0.9650633105864892, 1.052106683070843, 0.7577012181282043, 1.5224143679325397, 0.7688498336535233, 1.2203605083318858, 1.3157590994468102, 2.4689319959053626, 0.985666939845452, 2.583569416633019, 0.945761501789093, 1.353179931640625, 1.353179931640625, 1.353179931640625, 0.945761501789093]
loss_5 = [7.749083959139311, 1.301987648010254, 3.181245657113882, 1.1336782712202806, 2.7307101029616137, 1.311001025713407, 0.9412345427733201, 2.5764471842692447, 1.121784311074477, 1.462799439063439, 1.4813347229590783, 2.587785702485305, 0.9212086292413565, 2.112020914371197, 2.9297667283278246, 0.9867414327768179, 1.1213542819023132, 1.2389437968914325, 0.7213122844696045, 0.7970273265471826, 8.369010668534498, 1.2389437968914325, 1.2389437968914325, 1.2389437968914325, 1.2389437968914325]
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALL-IDB2 test set using larger rescale (200x200)')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.5961538461538461, 0.8317307692307693, 0.8798076923076923, 0.9423076923076923, 0.9663461538461539, 0.9855769230769231, 0.9807692307692307, 1.0, 1.0, 0.9903846153846154, 1.0, 0.9951923076923077, 0.9951923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_2 = [0.6394230769230769, 0.8269230769230769, 0.9326923076923077, 0.9519230769230769, 0.9855769230769231, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_3 = [0.6009615384615384, 0.8221153846153846, 0.8894230769230769, 0.9423076923076923, 0.9807692307692307, 0.9855769230769231, 1.0, 1.0, 1.0, 0.9951923076923077, 1.0, 1.0, 1.0, 1.0, 0.9903846153846154, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_4 = [0.6875, 0.8076923076923077, 0.8942307692307693, 0.9567307692307693, 0.9615384615384616, 0.9807692307692307, 0.9903846153846154, 0.9951923076923077, 0.9951923076923077, 1.0, 1.0, 0.9759615384615384, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9951923076923077, 1.0, 1.0, 0.9951923076923077]
acc_train_5 = [0.6057692307692307, 0.7596153846153846, 0.7692307692307693, 0.8942307692307693, 0.9230769230769231, 0.9423076923076923, 0.9807692307692307, 0.9855769230769231, 1.0, 0.9951923076923077, 1.0, 0.9951923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9903846153846154, 0.9519230769230769, 0.9759615384615384, 0.9807692307692307, 0.9951923076923077, 1.0]
avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)

plt.plot(x_values, acc_train_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, acc_train_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, acc_train_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, acc_train_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, acc_train_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB2 train set using larger rescale (200x200)')
plt.legend(loc='best')
plt.show()
'''

# Noise test 

'''
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.5384615384615384, 0.5384615384615384, 0.5384615384615384, 0.5384615384615384, 0.5384615384615384, 0.5576923076923077, 0.5384615384615384, 0.5384615384615384, 0.5384615384615384, 0.5384615384615384, 0.5384615384615384, 0.5384615384615384, 0.6730769230769231, 0.5384615384615384, 0.6153846062146701, 0.5576923076923077, 0.6538461630160992, 0.6346153937853299, 0.7115384569534888, 0.6923076877227197, 0.5384615476314838, 0.6923076877227197, 0.7115384569534888, 0.6153846107996427, 0.7115384569534888]
accuracy_2 = [0.5192307738157419, 0.6153846245545608, 0.4807692261842581, 0.5192307692307693, 0.4807692261842581, 0.6346153892003573, 0.6730769139069778, 0.5384615430465112, 0.5192307738157419, 0.5192307738157419, 0.5192307738157419, 0.5192307738157419, 0.5192307738157419, 0.5192307738157419, 0.5192307738157419, 0.5192307738157419, 0.5192307738157419, 0.6346153892003573, 0.6346153892003573, 0.6346153892003573, 0.6346153892003573, 0.6346153892003573, 0.6346153892003573, 0.6346153892003573, 0.6346153892003573]
accuracy_3 = [0.4807692261842581, 0.6153846062146701, 0.7692307784007146, 0.6730769322468684, 0.5769230815080496, 0.6153846062146701, 0.7115384615384616, 0.5576923122772803, 0.5961538553237915, 0.7115384615384616, 0.5192307738157419, 0.5192307738157419, 0.5192307738157419, 0.5192307738157419, 0.5384615430465112, 0.6538461446762085, 0.6346153754454392, 0.6923076877227197, 0.7692307784007146, 0.7115384661234342, 0.6730769322468684, 0.5769230815080496, 0.5192307738157419, 0.5192307738157419, 0.5]
accuracy_4 = [0.4423076923076923, 0.5, 0.5576923122772803, 0.5769230815080496, 0.75, 0.6730769322468684, 0.7115384569534888, 0.6923077014776376, 0.6538461538461539, 0.5961538507388189, 0.4423076877227196, 0.4038461492611812, 0.38461538461538464, 0.4230769230769231, 0.4423076923076923, 0.4423076923076923, 0.4423076923076923, 0.4423076923076923, 0.4423076923076923, 0.4423076923076923, 0.4038461492611812, 0.4038461492611812, 0.4807692330617171, 0.5576923076923077, 0.5576923076923077]
accuracy_5 = [0.8076923168622531, 0.807692303107335, 0.5192307784007146, 0.5192307784007146, 0.5576922985223624, 0.5192307784007146, 0.5576923168622531, 0.6923076923076923, 0.6538461538461539, 0.5769230769230769, 0.5192307715232556, 0.5384615338765658, 0.5384615338765658, 0.5384615338765658, 0.5576923076923077, 0.5961538507388189, 0.4807692261842581, 0.5384615384615384, 0.5769230769230769, 0.5384615430465112, 0.5576923076923077, 0.6153846107996427, 0.5192307646457965, 0.5192307646457965, 0.4615384661234342]

plt.plot(x_values, accuracy_1, label="noise=0.1", linewidth=1)
plt.plot(x_values, accuracy_2, label="noise=0.2", linewidth=1)
plt.plot(x_values, accuracy_3, label="noise=0.4", linewidth=1) 
plt.plot(x_values, accuracy_4, label="noise=0.6", linewidth=1) 
plt.plot(x_values, accuracy_5, label="noise=0.8", linewidth=1)  


plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB2 test set with different level of noise')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [7.4391213196974535, 7.4391213196974535, 5.766486204587496, 7.1234451073866625, 1.5899803363359892, 1.6449347917850201, 5.503423617436336, 5.797484251169058, 4.8281857417179985, 2.9965591614062967, 4.338238275968111, 7.3219769184405985, 0.6550855453197773, 3.2697559136610765, 0.8868151490504925, 1.524737495642442, 0.9819048368013822, 0.6578392523985642, 0.5702143953396723, 0.5326268099821531, 1.2666994058168852, 2.2943214086385875, 1.4110445426060603, 0.8094273484670199, 1.4110445426060603]
loss_2 = [6.4863601464491625, 1.517673446581914, 8.369010925292969, 2.4035222163567176, 2.3495286244612474, 1.127088189125061, 0.7961217852739187, 1.9098386122630193, 3.1229472160339355, 4.38646151469304, 5.431007348574125, 6.107018507443941, 1.7863480494572566, 5.659690343416655, 7.694297827207125, 7.74908447265625, 7.067710839785063, 2.3495286244612474, 2.3495286244612474, 2.3495286244612474,2.3495286244612474 , 2.3495286244612474, 2.3495286244612474, 2.3495286244612474, 2.3495286244612474]
loss_3 = [8.152320128220778, 1.3981741941892183, 0.49430203437805176, 0.4936648698953482, 1.7786323932500987, 0.9592216381659875, 0.6353071607076205, 4.897355703207163, 2.329252939957839, 0.7199263939490685, 1.7855597184254572, 5.2140075243436375, 6.980923946087177, 7.103380863483135, 1.2311977789952204, 1.010231600357936, 1.4114389236156757, 0.6320687853373014, 0.5510071470187261, 0.7323200290019696, 0.6242412145321186, 1.3179649389707124, 2.4189418095808763, 3.422295093536377, 3.603995708318857]
loss_4 = [0.5170711622788355, 0.5332335990208846, 1.8158462230975811, 1.4209600870425885, 1.027502940251277, 1.2343847935016339, 1.3774497142204871, 0.7435143544123723, 0.6072213878998389, 1.1257347510411189, 2.32842126259437, 2.0712108612060547, 2.2375875619741588, 3.183138755651621, 2.845165656163142, 2.9218654449169454, 8.021936710064228, 4.0789947142967815, 1.7178882268758922, 2.250123482484084, 4.705425225771391, 2.7028373388143687, 4.815201832697942, 6.45685049203726, 6.45685049203726]
loss_5 = [5.047262265132024, 4.035416236290565, 3.140872936982375, 2.112898881618793, 1.017857056397658, 1.2844120080654438, 0.833819737801185, 0.5873160408093379, 0.7084123171292819, 1.6293712579287016, 3.282587821667011, 4.615933803411631, 8.203241641704853, 8.88569399026724, 8.988938991840069, 8.988938258244442, 8.988938258244442, 8.988938258244442, 8.988938258244442, 8.988938258244442, 8.936671367058388, 8.396700895749605, 5.5789959614093485, 6.368090959695669, 7.12915772658128]

plt.plot(x_values, loss_1, label="noise=0.1", linewidth=1)
plt.plot(x_values, loss_2, label="noise=0.2", linewidth=1)
plt.plot(x_values, loss_3, label="noise=0.4", linewidth=1) 
plt.plot(x_values, loss_4, label="noise=0.6", linewidth=1) 
plt.plot(x_values, loss_5, label="noise=0.8", linewidth=1)  

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALL-IDB2 test set with different level of noise')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.5865384615384616, 0.8221153846153846, 0.8461538461538461, 0.9182692307692307, 0.9615384615384616, 0.9663461538461539, 0.9855769230769231, 0.9903846153846154, 0.9759615384615384, 1.0, 1.0, 1.0, 0.9951923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9951923076923077, 1.0, 1.0, 1.0, 0.9951923076923077]
acc_train_2 = [0.6490384615384616, 0.8269230769230769, 0.8894230769230769, 0.9278846153846154, 0.9807692307692307, 0.9807692307692307, 0.9663461538461539, 0.9903846153846154, 0.9807692307692307, 0.9903846153846154, 0.9903846153846154, 0.9951923076923077, 1.0, 1.0, 0.9951923076923077, 0.9903846153846154, 1.0, 0.9951923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9951923076923077, 1.0]
acc_train_3 = [0.625, 0.7115384615384616, 0.7596153846153846, 0.8076923076923077, 0.8365384615384616, 0.8846153846153846, 0.8701923076923077, 0.9086538461538461, 0.9278846153846154, 0.9086538461538461, 0.9086538461538461, 0.9663461538461539, 0.9615384615384616, 0.9807692307692307, 0.9807692307692307, 0.9663461538461539, 0.9663461538461539, 0.9519230769230769, 0.9807692307692307, 0.9567307692307693, 0.9711538461538461, 0.9759615384615384, 0.9807692307692307, 0.9807692307692307, 0.9951923076923077]
acc_train_4 = [0.5192307692307693, 0.6875, 0.6875, 0.7403846153846154, 0.75, 0.7932692307692307, 0.8028846153846154, 0.8605769230769231, 0.8173076923076923, 0.8509615384615384, 0.9086538461538461, 0.9230769230769231, 0.9278846153846154, 0.9471153846153846, 0.9326923076923077, 0.9471153846153846, 0.9471153846153846, 0.9711538461538461, 0.9807692307692307, 0.9759615384615384, 0.9855769230769231, 0.9855769230769231, 0.9855769230769231, 0.9807692307692307, 0.9855769230769231]
acc_train_5 = [0.5480769230769231, 0.6971153846153846, 0.6826923076923077, 0.6971153846153846, 0.7211538461538461, 0.7259615384615384, 0.7596153846153846, 0.7259615384615384, 0.75, 0.8221153846153846, 0.8605769230769231, 0.8653846153846154, 0.8701923076923077, 0.8605769230769231, 0.8557692307692307, 0.9326923076923077, 0.9182692307692307, 0.9182692307692307, 0.9230769230769231, 0.9375, 0.9471153846153846, 1.0, 0.9855769230769231, 0.9711538461538461, 0.9855769230769231]


plt.plot(x_values, acc_train_1, label="noise=0.1", linewidth=1)
plt.plot(x_values, acc_train_2, label="noise=0.2", linewidth=1)
plt.plot(x_values, acc_train_3, label="noise=0.4", linewidth=1) 
plt.plot(x_values, acc_train_4, label="noise=0.6", linewidth=1) 
plt.plot(x_values, acc_train_5, label="noise=0.8", linewidth=1)  

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB2 train set with different level of noise')
plt.legend(loc='best')
plt.show()
'''



#########################################################################################################################################################################


# LEUK-SUBTYPES DATASET 


# Baseline results (no dropout, no data augmentation) with color 
'''
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.3387978137190876, 0.22950819582561327, 0.3825136620164569, 0.2185792348098234, 0.2185792348098234, 0.2185792348098234, 0.2185792348098234, 0.2185792348098234, 0.2185792348098234, 0.2185792348098234, 0.2240437156841403, 0.3060109280660504, 0.2568306006043335, 0.29508196558457256, 0.2896174847102556, 0.4918032780371077, 0.5245901642601347, 0.6010928978034056, 0.4098360663880416, 0.3770491785364724, 0.5027322384829078, 0.3606557359135216, 0.6010928991062393, 0.48087431514849427, 0.5683060076718773]
accuracy_2 = [0.2240437156841403, 0.3169398915246536, 0.41530054579667053, 0.1857923492382133, 0.1857923492382133, 0.1857923492382133, 0.1857923492382133, 0.23497267580423198, 0.2732240420873048, 0.20765027273548106, 0.19125683043823868, 0.20218579218687255, 0.18579234956392174, 0.20218579218687255, 0.2349726774327742, 0.26775956267867584, 0.22950819655845725, 0.4043715838037553, 0.21311475360979798, 0.2896174845474014, 0.24043715798138268, 0.19125683011253022, 0.1857923492382133, 0.1857923492382133, 0.39890710317371975]
accuracy_3 = [0.23497267726991997, 0.2404371581442369, 0.22404371625413008, 0.20218579275686233, 0.31147540820752334, 0.4207650255310079, 0.43715846815395876, 0.3333333341476044, 0.36612021678783857, 0.4262295088481382, 0.24043715757424713, 0.24590164015853339, 0.3606557359135216, 0.2185792333441354, 0.26775956365580117, 0.19672131057971162, 0.3114754093475029, 0.40437158290805714, 0.5081967219628923, 0.4754098342741773, 0.4644808725255435, 0.5191256837115261, 0.5300546464372854, 0.5355191286144361, 0.44808743120542643]
accuracy_4 = [0.40437158421089087, 0.322404371258991, 0.3661202193935061, 0.20218579255329455, 0.4153005448195452, 0.30601092733320645, 0.3169398915246536, 0.3114754106503367, 0.28415300627875195, 0.40437158290805714, 0.23497267840989952, 0.46448087105985547, 0.3770491798393062, 0.38251366071362314, 0.4480874297397384, 0.4535519132197229, 0.45355191061405536, 0.5136612025115008, 0.44808743462536504, 0.33879781241625384, 0.33879781241625384, 0.33879781241625384, 0.45355191061405536, 0.45355191061405536, 0.5136612025115008]
accuracy_5 = [0.20218579218687255, 0.2677595625158216, 0.20765027232834551, 0.20765027232834551, 0.20765027232834551, 0.23497267726991997, 0.251366119322881, 0.2786885242644555, 0.17486338781528785, 0.36065573721635535, 0.27868852540443506, 0.4699453532370062, 0.21857923464696916, 0.22950819509276926, 0.3224043710961368, 0.2349726759670862, 0.4316939898853094, 0.5027322410885754, 0.5792349743061378, 0.4972677602142584, 0.573770489849028, 0.5027322384829078, 0.5409836033002926, 0.49180327933994145, 0.5519125650489265]
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3,color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALLIDB+DEMIR test set using baseline')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [2.591219724853182, 5.710655759592525, 2.710087565125012, 12.127485462876617, 12.595014504396199, 12.595014504396199, 12.5866949362833, 10.67765611638137, 6.247295595909077, 5.948221839842249, 6.7472274993938175, 3.1897796398954963, 4.078535556793213, 3.426963255053661, 2.9401508706514954, 1.5910142594999304, 1.539076566696167, 1.2597022297603837, 2.8129551814553517, 3.700270813019549, 1.8235278539970272, 3.643377874718338, 1.505458689126812, 2.002067421303421, 2.38910434545715]
loss_2 = [12.50693743867301, 3.4310546729082616, 5.651362747442527, 6.99107511447427, 12.890464021859925, 10.082278569539389, 7.643246317170357, 7.421958696646769, 5.328717565275932, 7.146985762757682, 10.199256902183992, 9.233345115119642, 10.451031622339467, 5.805378241617172, 4.8913871629642, 3.738167121762135, 5.965180511683063, 3.0241856210218754, 10.283792115300079, 8.540286134500972, 9.123572995753888, 11.278661894667996, 12.023095672899256, 12.94650721940838, 6.595096038338917]
loss_3 = [8.570413026653352, 7.257885117348426, 4.1613851635833905, 6.335439569963132, 7.323810340276832, 6.19847875084382, 3.2438782798787935, 2.282585654753805, 1.5325168807649874, 1.5583033333710634, 2.9513268783444264, 2.7528392069978143, 2.027705337180466, 4.779313629442226, 3.157043696752663, 6.2357598341227884, 2.3221499079563577, 1.7773067781834002, 1.5508842494318393, 1.6056557085996117, 2.670171484921148, 1.7214628764189006, 1.5952256308878705, 2.2115364511156343, 2.324509259781551]
loss_4 = [2.874170967789947, 8.35220113868922, 3.6492637832308077, 5.9957452080940286, 2.6404593981028905, 3.3370420997911463, 2.9191290316034535, 3.249372517476316, 4.184560809630514, 3.0452065415721123, 5.106777953319862, 2.149841576326089, 4.074754936447561, 4.684504107699368, 2.6022532129548286, 2.266509454107024, 1.4963279988596347, 2.1606884041770558, 2.1063453818930955, 4.749818314620055, 3.0452065415721123, 3.0452065415721123, 2.1063453818930955, 2.1063453818930955, 2.149841576326089] 
loss_5 = [12.859245368040325, 4.856840571419138, 10.179553000653376, 12.771168714012605, 10.667604722611891, 7.668404287327834, 5.561506503266715, 3.3153927638882497, 6.51837622533079, 6.248098256158047, 4.347670998078226, 1.5201544325208403, 7.643951598412352, 5.130207098246924, 4.334670255744392, 4.460694569707568, 3.444978063875209, 1.563160793377402, 1.5162437789427126, 1.6613336163140386, 1.425495145425119, 1.6115336092443413, 1.4476947523857076, 2.2885290091155004, 1.2669792520543917]
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3,color='black')

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALLIDB+DEMIR test set using baseline')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.439890711359639, 0.6297814204393188, 0.7213114760612529, 0.8633879787934934, 0.9289617492852966, 0.9576502732240437, 0.9863387974884992, 0.9890710382513661, 0.9877049180327869, 0.9959016393442623, 0.9959016393442623, 0.9959016393442623, 0.9959016393442623, 0.9959016399956792, 0.9959016393442623, 0.9986338797814208, 0.9972677602142584, 0.9972677595628415, 0.9959016393442623, 0.9945355197771, 0.9959016393442623, 0.9959016393442623, 0.9945355197771, 0.9959016393442623, 0.9959016393442623]
acc_train_2 = [0.44125683011253025, 0.6010928971519887, 0.6939890713639598, 0.804644808417461, 0.9016393445880035, 0.9562841536568814, 0.9795081973727283, 0.9904371584699454, 0.9849726775956285, 0.9849726782470453, 0.9877049180327869, 0.9959016393442623, 0.9986338804328376, 0.9986338797814208, 0.9986338797814208, 0.9986338797814208, 0.9972677595628415, 0.9986338797814208, 0.9972677595628415, 0.9781420765027322, 0.9836065573770492, 0.9931693989071039, 0.9849726782470453, 0.9959016393442623, 0.9972677595628415]
acc_train_3 = [0.44808743201969753, 0.6010928968262803, 0.6516393439365866, 0.7213114757355445, 0.8415300536676834, 0.9385245908153513, 0.9562841520283392, 0.994535519125683, 0.9972677595628415, 0.9972677595628415, 0.9972677595628415, 0.9972677595628415, 0.9986338797814208, 0.9986338797814208, 0.9972677595628415, 0.9972677595628415, 0.9972677595628415, 1.0, 0.9986338797814208, 0.9986338797814208, 0.9986338797814208, 0.9986338797814208, 0.9972677595628415, 0.9986338797814208, 0.9972677595628415]
acc_train_4 = [0.44808743201969753, 0.6010928968262803, 0.6516393439365866, 0.7213114757355445, 0.8415300536676834, 0.9016393445880035, 0.9562841520283392, 0.9904371584699454, 0.9972677595628415, 0.9972677595628415, 0.9972677595628415, 0.9972677595628415, 0.9986338797814208, 0.9986338797814208, 0.9972677595628415, 0.9972677595628415, 0.9972677595628415, 1.0, 0.9986338797814208, 0.9986338797814208, 0.9986338797814208, 0.9986338797814208, 0.9972677595628415, 0.9986338797814208, 0.9986338797814208]
acc_train_5 = [0.4453551912568306, 0.6215846991278434, 0.6639344272066335, 0.8128415303803532, 0.8306010919190495, 0.9221311465638583, 0.9754098367169907, 0.9890710382513661, 0.9836065580284661, 0.9863387978142076, 0.9795081967213115, 0.9931693989071039, 0.9904371584699454, 0.9959016393442623, 0.9959016393442623, 0.9959016393442623, 0.9959016393442623, 0.9959016393442623, 0.9959016399956792, 0.9931693989071039, 0.9972677595628415, 0.9959016393442623, 0.9972677595628415, 0.994535519125683, 0.9959016393442623]
avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)

plt.plot(x_values, acc_train_1, label="Run 1")
plt.plot(x_values, acc_train_2, label="Run 2")
plt.plot(x_values, acc_train_3, label="Run 3") 
plt.plot(x_values, acc_train_4, label="Run 4") 
plt.plot(x_values, acc_train_5, label="Run 5")  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALLIDB+DEMIR train set using baseline')
plt.legend(loc='best')
plt.show()
'''

# ---------------------------------------------------------------------- 


# Greyscale
'''
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.31693989022181984, 0.3606557360763758, 0.2568306007671877, 0.3661202193935061, 0.35519125650489264, 0.44808742843690463, 0.40983606622518737, 0.4371584666882708, 0.33879781257910807, 0.3715847001049688, 0.22404371666126563, 0.5300546451344517, 0.4972677602142584, 0.4316939898853094, 0.5300546477401191, 0.5901639324719788, 0.4426229503311095, 0.49180327933994145, 0.5683060076718773, 0.5191256824086924, 0.5628415267975604, 0.6065573799805563, 0.5628415281003941, 0.5956284133462958, 0.5901639350776464]
accuracy_2 = [0.33879781502192136, 0.40437158421089087, 0.4754098355770111, 0.4098360663880416, 0.28415300383593867, 0.28415300627875195, 0.2622950803386709, 0.3879781415879401, 0.2622950827814842, 0.3551912563420384, 0.453551915499682, 0.31693989022181984, 0.2622950803386709, 0.2076502715955015, 0.393442620996569, 0.45901639637399894, 0.5081967193572248, 0.5519125673288856, 0.5245901668658022, 0.5300546464372854, 0.43169398581395385, 0.5901639311691451, 0.4043715840480367, 0.6174863355407298, 0.6120218559692466]
accuracy_3 = [0.2240437160505623, 0.2950819670502605, 0.5027322397857416, 0.4918032780371077, 0.34426229548910275, 0.2240437160505623, 0.21311475430192844, 0.3715846992906977, 0.45355191297544156, 0.3169398898146843, 0.20765027232834551, 0.19125682970539468, 0.1803278679567608, 0.3333333328447707, 0.3278688532732875, 0.45901639376833137, 0.5027322407628669, 0.5683060125575039, 0.42622951112809726, 0.5245901668658022, 0.5737704921289871, 0.5737704921289871, 0.46994535600552795, 0.4371584666882708, 0.46994535600552795]
accuracy_4 = 
accuracy_5 = 
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)
print(avg_acc)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB1 test set using greyscale')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [4.425570580477271, 2.253943425058667, 4.056541227903522, 2.977964543253998, 3.169405698776245, 1.9242183478152166, 2.519675366865481, 1.7165577952327624, 4.18698787689209, 4.09709556115781, 5.5303628978833475, 1.1371929111376486, 1.381389316965322, 2.568364303620135, 1.1368650507405806, 1.2996552641925916, 2.239288309232785, 2.4800470878517693, 1.7525996406221651, 1.9687513458272798, 1.6854966761635952, 1.4230441565070648, 2.1711183975303108, 2.015753377330759, 2.297089111609537]
loss_2 = [4.39285028697363, 2.0590471426645913, 1.3752144047471344, 1.8106112486677743, 2.0939715846640166, 2.182789389552966, 2.622692452102411, 1.8604570679325876, 2.559007889586068, 2.4910922102589423, 2.186224990855149, 2.352856180055545, 3.4234983478087546, 5.224485646180116, 2.629980923699551, 2.2702602962327134, 1.5633669537924677, 1.8850747692129, 1.7133047202897203, 1.6413113973179803, 2.0046064019854604, 1.4581661888810455, 2.607825337863359, 1.3235607134188458, 1.3799933214656641]
loss_3 = [7.451093361025951, 4.218328538488169, 1.7824108170681312, 1.092654362402327, 2.4942039479323426, 9.649344517233594, 7.9242940287772425, 2.8114412755914073, 6.047504852378303, 4.842437431460521, 5.231088776406043, 7.46035684783602, 7.810540725624627, 3.3980510599626217, 2.475027651083274, 2.02517189354193, 1.9517316205905435, 1.8239110330414903, 1.8696146099293818, 1.8423358788255786, 1.562441438273654, 1.8564262025343263, 2.674174755648837, 3.98797462807327, 2.674174755648837]
loss_4 = 
loss_5 = 
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)
print(avg_loss)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALL-IDB1 test set using greyscale')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.43579235070390127, 0.6461748637136866, 0.7062841523540476, 0.7581967216371839, 0.8169398900589656, 0.8592896165092134, 0.9139344259037998, 0.9289617486338798, 0.9535519115911807, 0.9521857920240183, 0.9713114760612529, 0.9576502732240437, 0.9795081973727283, 0.9685792356240944, 0.9754098367169907, 0.9863387978142076, 0.9959016393442623, 0.9877049180327869, 0.989071038902783, 0.9972677595628415, 0.9959016393442623, 0.994535519125683, 0.9931693989071039, 0.9931693989071039, 0.9931693989071039]
acc_train_2 = [0.4918032796656499, 0.6625683063366374, 0.7581967213114754, 0.823770492780404, 0.8756830594578727, 0.8948087428436905, 0.9685792356240944, 0.9808743169398907, 0.9863387984656246, 0.9740437148698692, 0.9863387968370824, 0.9931693989071039, 0.9877049180327869, 0.9863387984656246, 0.9931693989071039, 0.9931693995585207, 0.9931693989071039, 0.9959016393442623, 0.994535519125683, 0.9959016393442623, 0.9959016399956792, 0.9945355197771, 0.9931693989071039, 0.9959016399956792, 0.994535519125683]
acc_train_3 = [0.46584699404695645, 0.6270491800021604, 0.755464480874317, 0.8442622947562588, 0.9002732243694243, 0.9494535525639852, 0.978142075525607, 0.9713114754098361, 0.9836065573770492, 0.9603825136612022, 0.9863387968370824, 0.9781420765027322, 0.9918032786885246, 0.994535519125683, 0.9972677595628415, 0.9986338797814208, 0.9972677595628415, 0.9986338797814208, 0.9986338797814208, 0.9972677595628415, 0.9972677595628415, 1.0, 0.994535519125683, 0.9972677595628415, 0.9986338797814208]
acc_train_4 = 
acc_train_5 = 
avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)
print(avg_acc_train)

plt.plot(x_values, acc_train_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, acc_train_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, acc_train_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, acc_train_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, acc_train_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB1 train set using greyscale')
plt.legend(loc='best')
plt.show()
'''

# ---------------------------------------------------------------------- 


'''
# Contrast increase
# Accuracy 

x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.3387978137190876, 0.3060109286360402, 0.2677595625158216, 0.3169398915246536, 0.30601092847318595, 0.19672131188254538, 0.26775956365580117, 0.4098360637823741, 0.30601092847318595, 0.5191256798030249, 0.3005464464588895, 0.5081967206600585, 0.37158469766215546, 0.40437158290805714, 0.46448087496835677, 0.4972677576085909, 0.4754098354141569, 0.5573770495060363, 0.6010928965005718, 0.5737704934318208, 0.5792349743061378, 0.5737704921289871, 0.5573770495060363, 0.6229508186950058, 0.6174863378206888]
accuracy_2 = [0.20765027289833526, 0.16939890751096068, 0.33333333398475024, 0.3169398890818403, 0.29508196802738584, 0.2131147537726522, 0.28415300383593867, 0.34972677432774196, 0.3224043723989706, 0.32786885197045373, 0.5027322397857416, 0.5792349720261788, 0.43715847075962627, 0.5245901645858431, 0.49180327933994145, 0.4972677577714451, 0.5573770472260772, 0.5573770472260772, 0.5573770472260772, 0.6010928991062393, 0.5683060076718773, 0.5683060089747111, 0.573770489849028, 0.5737704885461943, 0.5081967195200789]
accuracy_3 = [0.1584699450294828, 0.3497267754677215, 0.344262293453425, 0.2786885242644555, 0.23497267800276397, 0.2896174854430996, 0.24043715887708092, 0.25683060019719794, 0.26775956194583184, 0.24043715757424713, 0.37704917869932664, 0.46448087399123145, 0.5409836060688143, 0.4644808738283772, 0.4043715838037553, 0.5081967206600585, 0.37158470026782303, 0.48633879862847873, 0.5737704926175498, 0.5300546430173467, 0.5792349710490534, 0.5628415308689159, 0.5792349710490534, 0.5628415308689159, 0.5792349710490534]
accuracy_4 = [0.40437158290805714, 0.38251365941078935, 0.6120218608548732, 0.37158469766215546, 0.3169398915246536, 0.35519125650489264, 0.2950819668874063, 0.4699453558426737, 0.5683060076718773, 0.4153005470995043, 0.3989071044765535, 0.573770489849028, 0.3989071044765535, 0.5355191237288095, 0.37158469896498925, 0.573770489849028, 0.4918032780371077, 0.573770489849028, 0.5519125663517602, 0.6502732256722581, 0.5792349694205112, 0.5683060076718773, 0.6010928991062393, 0.5519125676545941, 0.5956284169290886]
accuracy_5 = [0.4207650255310079, 0.31147540918464867, 0.21857923464696916, 0.322404371258991, 0.22950819655845725, 0.2240437156841403, 0.2240437156841403, 0.2240437156841403, 0.2622950818043589, 0.5027322384829078, 0.4699453558426737, 0.42622950770815865, 0.5464480854774434, 0.5081967193572248, 0.4972677576085909, 0.5191256824086924, 0.42622950640532486, 0.44808743234540593, 0.33333333398475024, 0.5081967242428513, 0.453551915499682, 0.5464480841746095, 0.5683060099518364, 0.5901639360547717, 0.633879784352141]
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)
print(avg_acc)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALLIDB+DEMIR test set with contrast increase')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [2.7282927909184025, 2.2036857722235506, 2.6887059732864462, 2.515066609356573, 1.940661267504666, 3.1802173559782934, 2.6845534759792473, 3.4742354213214313, 3.232678300044576, 1.221724882151911, 1.9554595510816313, 1.4142895239949878, 1.88874335888305, 1.9538383014866563, 1.8490265998683992, 1.748782191771627, 2.319230573424876, 1.2917121134169114, 1.2730891860899378, 1.4539508995462636, 1.3912620173125971, 1.3972021458578892, 1.5640213092168171, 1.4108343674836914, 1.541343789608752]
loss_2 = [6.396800903674683, 7.809519473320799, 2.0616482444148247, 2.381576512029262, 2.9323519175169896, 3.659671137241718, 3.0581422282046957, 2.20646541626727, 2.307065542929811, 3.312564664851121, 1.850207471456684, 1.3056676680924462, 1.6337439486237824, 1.4921927888536715, 1.6196217009278595, 1.5744636000179855, 1.2809219731659185, 1.3716490236136432, 1.4125723330700983, 1.4057405757122352, 1.2848269079552321, 1.3589516454707078, 1.2577416245403186, 1.2839004850127007, 2.7711972369522346]
loss_3 = [10.137020413341418, 3.3289385832072607, 4.934171895511815, 2.8289134398184186, 5.202573377577985, 3.111963219981376, 3.304373769812245, 3.225920548204516, 3.3729160209822524, 4.3963580366040835, 2.389105223567108, 2.153621291853691, 1.223957363373595, 1.7042459373265668, 3.038354623513144, 1.8481281181502212, 3.171201489662212, 1.6983906805840998, 1.5237883752812453, 1.7888634074581125, 2.254192374443096, 1.8004873202798144, 2.1467589628501016, 3.387779233234176, 2.9884841546334857]
loss_4 = [3.099360344839878, 2.342600930583933, 1.0588500688636238, 2.100556264158155, 1.767346406894955, 1.859626642993239, 7.799509572201088, 4.357478219954694, 1.2204628238261073, 2.787821238158179, 2.555160397388896, 1.2669820303473969, 1.8949270600178203, 1.3264232274613095, 2.0392782544829156, 1.5599210184128558, 1.8033183982463483, 1.3701681510998251, 1.5630187519261094, 1.098752289847598, 1.2992054758176126, 1.4425903636901105, 1.2275265367304693, 1.3759158406752707, 1.608363107253945]
loss_5 = [3.2030807244973105, 6.992905275417807, 5.6510124154429615, 9.528641101441096, 8.690435492927259, 12.378743791840767, 6.9342199752891, 5.111359830762519, 3.332171672028922, 1.5593287925251196, 2.10382980336257, 2.0791763790318223, 1.7873786850705173, 1.771910959254197, 1.9132431752043344, 2.1450795736469206, 2.1609528260152846, 1.8956005690527744, 2.4683481428792566, 1.7967387056741557, 2.3070219442492625, 1.8677465120951335, 1.3735711968661657, 1.3683351167564184, 1.3585625626350362]
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)
print(avg_loss)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALLIDB+DEMIR test set with contrast increase')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.4672131150798068, 0.695355191582539, 0.8306010938733002, 0.9166666669923751, 0.9549180327868853, 0.9726775956284153, 0.9781420771541491, 0.989071038902783, 0.9972677595628415, 0.9986338797814208, 0.9959016393442623, 0.9986338797814208, 0.9972677595628415, 0.9972677595628415, 0.9986338797814208, 0.9986338797814208, 0.9972677595628415, 0.994535519125683, 0.9986338797814208, 0.9972677595628415, 0.9972677595628415, 0.9986338797814208, 0.9986338797814208, 0.9986338797814208, 0.9986338797814208]
acc_train_2 = [0.4808743162884738, 0.7786885255672893, 0.8879781430536281, 0.9494535525639852, 0.9836065573770492, 0.98224043715847, 0.9890710385770746, 0.9972677595628415, 0.9959016393442623, 0.9972677595628415, 0.9972677595628415, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
acc_train_3 = [0.48087431645132805, 0.7267759556327361, 0.8292349720261788, 0.904371585025162, 0.9713114744327107, 0.9781420771541491, 0.9863387978142076, 0.9918032786885246, 0.9931693989071039, 0.994535519125683, 0.994535519125683, 0.9931693989071039, 0.9959016393442623, 0.994535519125683, 0.994535519125683, 0.9945355197771, 0.9959016393442623, 0.9972677595628415, 0.9959016399956792, 0.9959016393442623, 0.9959016393442623, 0.994535519125683, 0.994535519125683, 0.994535519125683, 0.994535519125683]
acc_train_4 = [0.43306010880105483, 0.6885245895125175, 0.7841530057901893, 0.8866120228350488, 0.9631147547497776, 0.9672131144283899, 0.9795081957441861, 0.9863387978142076, 0.9918032786885246, 0.9959016393442623, 0.9890710382513661, 0.9918032786885246, 0.9972677595628415, 0.9959016393442623, 0.9972677602142584, 0.994535519125683, 0.9972677595628415, 0.9959016393442623, 0.9986338797814208, 0.994535519125683, 0.9972677595628415, 0.9986338797814208, 0.9959016393442623, 0.9959016393442623, 0.994535519125683]
acc_train_5 = [0.4562841530054645, 0.6775956293924259, 0.7718579228458509, 0.7472677605399669, 0.8360655731190749, 0.9153005464480874, 0.9453551902797053, 0.97267759465129, 0.9781420765027322, 0.994535519125683, 0.9918032793399415, 0.9918032786885246, 0.9972677595628415, 0.9972677602142584, 0.9959016399956792, 0.9986338797814208, 0.9959016393442623, 0.9986338797814208, 0.9972677595628415, 0.9972677595628415, 0.9972677595628415, 0.9986338797814208, 0.9972677595628415, 0.9972677595628415, 0.9986338797814208]
avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)
print(avg_acc_train)

plt.plot(x_values, acc_train_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, acc_train_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, acc_train_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, acc_train_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, acc_train_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALLIDB+DEMIR train set with contrast increase')
plt.legend(loc='best')
plt.show()
'''
# ---------------------------------------------------------------------- 

'''
# hist eq
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.2896174860130894, 0.3442622932905708, 0.1803278672239168, 0.3224043710961368, 0.36612021678783857, 0.3825136605507689, 0.4590163901855385, 0.508196718054391, 0.5573770508088701, 0.5737704908261534, 0.2131147537726522, 0.24043715928421647, 0.540983609488753, 0.5245901668658022, 0.5901639321462704, 0.6174863378206888, 0.5464480877574024, 0.601092895197738, 0.5628415329860208, 0.5792349756089716, 0.5792349756089716, 0.6174863404263564, 0.5846994564832886, 0.6174863404263564, 0.6174863404263564]
accuracy_2 = 
accuracy_3 = 
accuracy_4 = 
accuracy_5 = 
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)
print(avg_acc)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALLIDB+DEMIR test set with histogram equalizer')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [6.7838870293455695, 3.4985352695965375, 13.211553547551723, 4.44242984219327, 2.5028455022905693, 1.6996050499827484, 1.9084221320074113, 1.3436928472883714, 1.159939416445018, 1.2012767169644925, 4.027214215752857, 4.309287103798871, 1.3750155532294934, 1.5902417318417075, 1.1800747624511927, 1.1049713687818559, 1.354889043693334, 1.1703828719795728, 1.3542548401759622, 1.3231866379253199, 2.1104766097876544, 1.3999523165447465, 1.6172979855146565, 1.3411124048988676, 1.634891880665972]
loss_2 = 
loss_3 = 
loss_4 = 
loss_5 = 
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)
print(avg_loss)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALLIDB+DEMIR test set with histogram equalizer')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.4685792343212607, 0.7568306020700215, 0.9125683050338036, 0.9767759553070277, 0.9918032786885246, 0.9918032786885246, 0.994535519125683, 0.9972677595628415, 0.994535519125683, 0.9972677595628415, 0.9972677595628415, 0.9931693989071039, 0.9959016393442623, 0.9931693989071039, 0.9945355197771, 0.994535519125683, 0.9931693989071039, 0.9959016393442623, 0.9945355197771, 0.9959016399956792, 0.9972677595628415, 0.9959016393442623, 0.9972677595628415, 0.9931693989071039, 0.9972677595628415]
acc_train_2 = 
acc_train_3 = 
acc_train_4 = 
acc_train_5 = 
avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)
print(avg_acc_train)

plt.plot(x_values, acc_train_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, acc_train_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, acc_train_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, acc_train_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, acc_train_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='lightgreen', markeredgewidth=2,
         markersize=12, markevery=3)

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALLIDB+DEMIR train set with histogram equalizer')
plt.legend(loc='best')
plt.show()
'''

# ---------------------------------------------------------------------- 

'''
# 3 filters comparison 
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.31693989022181984, 0.3606557360763758, 0.2568306007671877, 0.3661202193935061, 0.35519125650489264, 0.44808742843690463, 0.40983606622518737, 0.4371584666882708, 0.33879781257910807, 0.3715847001049688, 0.22404371666126563, 0.5300546451344517, 0.4972677602142584, 0.4316939898853094, 0.5300546477401191, 0.5901639324719788, 0.4426229503311095, 0.49180327933994145, 0.5683060076718773, 0.5191256824086924, 0.5628415267975604, 0.6065573799805563, 0.5628415281003941, 0.5956284133462958, 0.5901639350776464]
accuracy_2 = [0.30601092801719415, 0.3038251360420321, 0.35519125709116783, 0.3213114747584192, 0.27650273251728935, 0.25573770465746604, 0.2622950817880735, 0.3420765019668256, 0.3453551904588449, 0.40109289498602757, 0.40983606505263703, 0.5103825128469311, 0.45901639288891866, 0.4874316928816624, 0.44590163893712675, 0.5191256816595631, 0.4644808734700979, 0.5245901635110053, 0.5234972673361418, 0.5726775970941033, 0.5519125675894523, 0.56393442476382, 0.5759562838924387, 0.5803278683638963, 0.5868852459342101]
accuracy_3 = [0.2896174860130894, 0.3442622932905708, 0.1803278672239168, 0.3224043710961368, 0.36612021678783857, 0.3825136605507689, 0.4590163901855385, 0.508196718054391, 0.5573770508088701, 0.5737704908261534, 0.4590163901855385, 0.508196718054391, 0.540983609488753, 0.5245901668658022, 0.5901639321462704, 0.6174863378206888, 0.5464480877574024, 0.601092895197738, 0.5628415329860208, 0.5792349756089716, 0.5792349756089716, 0.6174863404263564, 0.5846994564832886, 0.6174863404263564, 0.6174863404263564]

plt.plot(x_values, accuracy_1, label="Greyscale", linewidth=1)
plt.plot(x_values, accuracy_2, label="Contrast increased", linewidth=1)
plt.plot(x_values, accuracy_3, label="Histogram equalizer", linewidth=1) 

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Average model accuracy on ALLIDB+DEMIR test set by applied filters')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [4.425570580477271, 2.253943425058667, 4.056541227903522, 2.977964543253998, 3.169405698776245, 1.9242183478152166, 2.519675366865481, 1.7165577952327624, 4.18698787689209, 4.09709556115781, 5.5303628978833475, 1.1371929111376486, 1.381389316965322, 2.568364303620135, 1.1368650507405806, 1.2996552641925916, 2.239288309232785, 2.4800470878517693, 1.7525996406221651, 1.9687513458272798, 1.6854966761635952, 1.4230441565070648, 2.1711183975303108, 2.015753377330759, 2.297089111609537]
loss_2 = [5.112911035454339, 4.535530006950671, 3.2788777195039343, 3.8709507853607006, 4.106673692484371, 4.838044429607079, 4.756159804297275, 3.6750918873020866, 2.6930588719623336, 2.655559522858083, 2.170752489371378, 1.643947378664069, 1.6857500831937529, 1.64972224287648, 2.0919048707993304, 1.775274900399922, 2.147125052102928, 1.5255041075534508, 1.6481633578493295, 1.5088091756476731, 1.70730174395556, 1.5733955974787313, 1.5139239260407744, 1.7653530086324516, 2.0535901702166908]
loss_3 = [6.7838870293455695, 3.4985352695965375, 11.211553547551723, 4.44242984219327, 2.5028455022905693, 1.6996050499827484, 1.9084221320074113, 1.3436928472883714, 1.159939416445018, 1.2012767169644925, 1.5902417318417075, 1.5902417318417075, 1.3750155532294934, 1.5902417318417075, 1.1800747624511927, 1.1049713687818559, 1.354889043693334, 1.1703828719795728, 1.3542548401759622, 1.3231866379253199, 2.1104766097876544, 1.3999523165447465, 1.6172979855146565, 1.3411124048988676, 1.634891880665972]

plt.plot(x_values, loss_1, label="Greyscale", linewidth=1)
plt.plot(x_values, loss_2, label="Contrast increased", linewidth=1)
plt.plot(x_values, loss_3, label="Histogram equalizer", linewidth=1) 

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Average model loss on ALLIDB+DEMIR test set by applied filters')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.46584699404695645, 0.6270491800021604, 0.755464480874317, 0.8442622947562588, 0.9002732243694243, 0.9494535525639852, 0.978142075525607, 0.9713114754098361, 0.9836065573770492, 0.9603825136612022, 0.9863387968370824, 0.9781420765027322, 0.9918032786885246, 0.994535519125683, 0.9972677595628415, 0.9986338797814208, 0.9972677595628415, 0.9986338797814208, 0.9986338797814208, 0.9972677595628415, 0.9972677595628415, 1.0, 0.994535519125683, 0.9972677595628415, 0.9986338797814208]
acc_train_2 = [0.46366120192522564, 0.7133879783375016, 0.8207650275178295, 0.8808743175913076, 0.9418032784930993, 0.9631147541635023, 0.9756830599138645, 0.9874316939239293, 0.9912568306010929, 0.9961748633879782, 0.9937158471248189, 0.9950819672131148, 0.9975409836065573, 0.996994535649409, 0.9972677598234083, 0.997267759693125, 0.9972677595628415, 0.9972677595628415, 0.9980874318242725, 0.9969945355191256, 0.9975409836065573, 0.9980874316939892, 0.9972677595628415, 0.9972677595628415, 0.9972677595628415]
acc_train_3 = [0.4685792343212607, 0.7568306020700215, 0.9125683050338036, 0.9767759553070277, 0.9918032786885246, 0.9918032786885246, 0.994535519125683, 0.9972677595628415, 0.994535519125683, 0.9972677595628415, 0.9972677595628415, 0.9931693989071039, 0.9959016393442623, 0.9931693989071039, 0.9945355197771, 0.994535519125683, 0.9931693989071039, 0.9959016393442623, 0.9945355197771, 0.9959016399956792, 0.9972677595628415, 0.9959016393442623, 0.9972677595628415, 0.9931693989071039, 0.9972677595628415]

plt.plot(x_values, acc_train_1, label="Greyscale", linewidth=1)
plt.plot(x_values, acc_train_2, label="Contrast increased", linewidth=1)
plt.plot(x_values, acc_train_3, label="Histogram equalizer", linewidth=1) 

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Average model accuracy on ALLIDB+DEMIR train set by applied filters')
plt.legend(loc='best')
plt.show()
'''

# ---------------------------------------------------------------------- 

# Noise test 
'''
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.17486338781528785, 0.1967213113125556, 0.39890710349942815, 0.16939890694097093, 0.16939890694097093, 0.4098360637823741, 0.29508196631741657, 0.3715846991278435, 0.2076502730611895, 0.21311475393550644, 0.2076502730611895, 0.2185792348098234, 0.2076502730611895, 0.3060109280660504, 0.2076502730611895, 0.23497267800276397, 0.23497267800276397, 0.2240437156841403, 0.2076502730611895, 0.29508196631741657, 0.38797814044796053, 0.2786885249972995, 0.44262294919112993, 0.5136612016972297, 0.5136612016972297]
accuracy_2 = [0.42076502699669593, 0.2185792333441354, 0.17486338818170985, 0.17486338818170985, 0.17486338818170985, 0.17486338818170985, 0.17486338818170985, 0.17486338818170985, 0.17486338818170985, 0.17486338818170985, 0.17486338818170985, 0.18579234883107773, 0.20765027232834551, 0.2841530058716164, 0.21311475450549622, 0.37704917943217064, 0.1803278690560268, 0.21857923537981314, 0.17486338818170985, 0.17486338818170985, 0.2732240428201488, 0.24043715830709114, 0.2185792348098234, 0.35519125650489264, 0.3278688532732875]
accuracy_3 = [0.48633879455712326, 0.4972677563057571, 0.49726775891142466, 0.45355191191688915, 0.38251366071362314, 0.18032786925959457, 0.40437158421089087, 0.18579234883107773, 0.17486338781528785, 0.21311475246981845, 0.19672131057971162, 0.19672131057971162, 0.2240437155212861, 0.19672131057971162, 0.19672131057971162, 0.19672131057971162, 0.19672131057971162, 0.20765027232834551, 0.2513661206257148, 0.22950819639560302, 0.2786885249972995, 0.322404371258991, 0.2622950810715149, 0.34426229459340457, 0.2841530058716164]
accuracy_4 = [0.39344262115942324, 0.3551912563420384, 0.19672130984686764, 0.37158469766215546, 0.34426229312771656, 0.16393442663664376, 0.010928961850417768, 0.2459016391814081, 0.34972677677055525, 0.33879781502192136, 0.18579234883107773, 0.22404371666126563, 0.18579234883107773, 0.22404371666126563, 0.14207650313937598, 0.1803278679567608, 0.17486338838527762, 0.1584699457623268, 0.18579235013391152, 0.20218579202401835, 0.22404371421845232, 0.2240437155212861, 0.2568306019071673, 0.3442622932905708, 0.2568306019071673]
accuracy_5 = [0.4262295088481382, 0.32786885213330796, 0.32786885213330796, 0.20765027363117927, 0.24590163901855386, 0.21311475393550644, 0.0710382514679041, 0.18579235013391152, 0.1693989067781167, 0.18032786925959457, 0.26775956194583184, 0.26775956194583184, 0.24043715757424713, 0.251366119322881, 0.21311475320266243, 0.1530054643180201, 0.19125683100822846, 0.20218579218687255, 0.08743169382621682, 0.14207650313937598, 0.09289617470053375, 0.10382513644916763, 0.10928961716063036, 0.1530054635851761, 0.14754098328084894]


plt.plot(x_values, accuracy_1, label="noise=0.1", linewidth=1)
plt.plot(x_values, accuracy_2, label="noise=0.2", linewidth=1)
plt.plot(x_values, accuracy_3, label="noise=0.4", linewidth=1) 
plt.plot(x_values, accuracy_4, label="noise=0.6", linewidth=1) 
plt.plot(x_values, accuracy_5, label="noise=0.8", linewidth=1)  


plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALLIDB+DEMIR test set with different level of noise')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [5.472679424807022, 4.984033378746991, 3.6987722975308777, 8.543407664272955, 3.911852628155484, 1.6326389840391815, 10.175617994506503, 5.34468204467023, 8.226915771192541, 5.576167135290761, 7.527333374231891, 5.912932036352939, 12.754849736156359, 8.897470839036618, 10.246847319472684, 5.572786018496654, 5.413936734850941, 6.419533961457633, 8.327957538959106, 4.215596501293078, 2.2875513730804777, 4.465449007482476, 2.045001462509072, 2.2463250551067415, 2.837812332507691]
loss_2 = [2.492085082934854, 3.629643767257857, 9.245448190657818, 8.314712831882831, 5.55719013161998, 11.69829487409748, 13.299630920743681, 11.677675846495916, 12.228067643004037, 13.288558579533477, 12.082405272728758, 11.151338535579827, 12.771168714012605, 7.554553907425677, 6.9802880860417265, 5.707084543718015, 7.1442151668944645, 7.802608414425876, 8.762400001776022, 9.968769855186588, 4.846942263222783, 5.3726948519222075, 7.265281127450245, 2.9731858675597143, 4.231282791804746]
loss_3 = [2.2002221143962255, 1.9488493093375951, 2.1129565466948548, 1.8035886320260053, 3.468086694759098, 6.656306772284169, 5.777745470974614, 7.610329797359112, 6.999312247083487, 6.8454746783105405, 12.947322678696262, 11.709596336865035, 7.399444150142982, 8.733927763224951, 8.313518594522945, 8.335841134597695, 9.451889981337583, 7.88227361147521, 5.799517514275723, 6.334159981357596, 5.623927991898333, 3.4495721684127556, 5.066842443956052, 3.012590743153473, 4.920124324944501]
loss_4 = [2.4188657966467852, 2.638704431512968, 5.886314519767553, 3.7773878040209494, 4.503137007437117, 10.097288100445857, 15.820351657971658, 7.39735851913202, 7.038699692064296, 5.029836852693818, 6.975931553241334, 6.790047371973757, 8.225308522500628, 8.642163547661786, 10.598404717575656, 9.90800853635444, 9.669053499815893, 9.891416786798363, 9.146833894031296, 8.403812106189832, 6.851312293380987, 8.21282548331172, 5.996565753644933, 3.7428447105845466, 5.641979483307385]
loss_5 = [1.9646656643497489, 2.112106608562782, 2.7576544076367155, 3.8159029314426776, 4.54800019759298, 5.413889561845957, 9.57646533570003, 12.063839245363663, 12.750890033492626, 11.62126880395608, 11.349495283241481, 11.309999351293012, 11.208367634340714, 9.993361061388025, 10.741594007106427, 9.481831373412753, 8.853418350219727, 9.055220306896773, 9.381013166709025, 10.33258647606021, 9.033281576438029, 9.791607481534363, 9.123205067681484, 8.817623432868166, 8.809999809890497]

plt.plot(x_values, loss_1, label="noise=0.1", linewidth=1)
plt.plot(x_values, loss_2, label="noise=0.2", linewidth=1)
plt.plot(x_values, loss_3, label="noise=0.4", linewidth=1) 
plt.plot(x_values, loss_4, label="noise=0.6", linewidth=1) 
plt.plot(x_values, loss_5, label="noise=0.8", linewidth=1)  

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 17)
plt.title('Model loss on ALLIDB+DEMIR test set with different level of noise')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]

acc_train_1 = [0.45218579218687255, 0.5915300539933919, 0.6502732246951327, 0.7185792352983861, 0.7950819675388232, 0.8647540980349473, 0.9357923507039013, 0.9644808743169399, 0.98224043715847, 0.9849726775956285, 0.9904371584699454, 0.9890710382513661, 0.9877049180327869, 0.9904371584699454, 0.9918032786885246, 0.994535519125683, 0.9972677595628415, 0.9959016393442623, 0.9959016393442623, 0.9972677595628415, 0.994535519125683, 0.9972677602142584, 0.9986338797814208, 0.9972677602142584, 0.9959016393442623]
acc_train_2 = [0.4808743169398907, 0.6147540980349473, 0.6639344259037998, 0.72267759465129, 0.8210382507147034, 0.8770491806535773, 0.922131147866692, 0.9193989067781166, 0.9658469942098107, 0.9836065580284661, 0.989071038902783, 0.9385245891868091, 0.8346994535519126, 0.845628414974838, 0.900273223392299, 0.9508196721311475, 0.9617486345311983, 0.9849726775956285, 0.9822404378098868, 0.9904371584699454, 0.9931693989071039, 0.9959016393442623, 0.9931693995585207, 0.994535519125683, 0.9931693989071039]
acc_train_3 = [0.4726775957912695, 0.6133879781420765, 0.6229508198349853, 0.6693989061266998, 0.7049180324611768, 0.7937158469945356, 0.8073770501574532, 0.8415300556219341, 0.8989071028480113, 0.845628414974838, 0.8346994542033295, 0.9139344265552166, 0.9166666673180836, 0.9494535519125683, 0.9808743175913076, 0.9767759559584446, 0.9781420765027322, 0.9836065573770492, 0.9808743169398907, 0.9904371591213622, 0.9822404378098868, 0.9863387984656246, 0.9849726782470453, 0.9918032786885246, 0.9931693989071039]
acc_train_4 = [0.412568306010929, 0.5204918032786885, 0.6065573763977634, 0.6092896165092134, 0.6653005464480874, 0.6898907103825137, 0.7472677589114246, 0.7131147550754859, 0.6994535525639852, 0.7663934416458255, 0.797814206673148, 0.852459016719151, 0.8688524583649766, 0.8948087428436905, 0.9084699460066081, 0.9453551902797053, 0.9685792349726776, 0.9699453542141315, 0.9617486345311983, 0.9726775956284153, 0.9877049170556615, 0.976775956284153, 0.9726775962798322, 0.9767759569355698, 0.9617486338797814]
acc_train_5 = [0.40437158421089087, 0.5109289612600713, 0.5245901642601347, 0.5587431697246156, 0.5751366121847121, 0.5901639334491042, 0.6666666656895414, 0.7021857930011437, 0.7418032777113993, 0.7855191247059348, 0.8306010932218834, 0.8729508193464227, 0.8907103815365359, 0.9084699443780659, 0.9166666673180836, 0.9303278698295844, 0.9576502732240437, 0.9467213104982846, 0.9631147540983607, 0.9617486329026561, 0.9767759553070277, 0.9726775956284153, 0.9754098360655737, 0.9754098367169907, 0.9726775962798322]

plt.plot(x_values, acc_train_1, label="noise=0.1", linewidth=1)
plt.plot(x_values, acc_train_2, label="noise=0.2", linewidth=1)
plt.plot(x_values, acc_train_3, label="noise=0.4", linewidth=1) 
plt.plot(x_values, acc_train_4, label="noise=0.6", linewidth=1) 
plt.plot(x_values, acc_train_5, label="noise=0.8", linewidth=1)  

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALLIDB+DEMIR train set with different level of noise')
plt.legend(loc='best')
plt.show()
'''

# ---------------------------------------------------------------------- 


# Dropout with color 

# Accuracy 
'''
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.20218579316399787, 0.4207650281366755, 0.3224043710961368, 0.4043715843737451, 0.18032786852675056, 0.18032786852675056, 0.31147541048748245, 0.1912568289725507, 0.18032786852675056, 0.42076502569386215, 0.3661202180906723, 0.36612021825352653, 0.3989071021965944, 0.2950819668874063, 0.20765027289833526, 0.19672130984686764, 0.19672130984686764, 0.40437158307091137, 0.19125683027538445, 0.42076502569386215, 0.31147541024320113, 0.22404371421845232, 0.18032786852675056, 0.18579234809823375, 0.18579234809823375]
accuracy_2 = [0.3715846978250097, 0.20765027232834551, 0.30601092977601974, 0.3989071021965944, 0.38251366071362314, 0.3114754106503367, 0.4207650255310079, 0.3934426213222775, 0.344262293453425, 0.1530054641551659, 0.1967213111497014, 0.42076502797382126, 0.3551912576448722, 0.20218579202401835, 0.20218579202401835, 0.20218579202401835, 0.20218579202401835, 0.20218579202401835, 0.20218579202401835, 0.2896174847102556, 0.20218579202401835, 0.20218579202401835, 0.20218579202401835, 0.20218579202401835, 0.2349726777991962]
accuracy_3 = [0.38797814044796053, 0.3606557360763758, 0.3606557373792096, 0.4098360650852078, 0.3989071020337402, 0.4972677602142584, 0.44808742990259265, 0.5300546415516587, 0.28961748674593335, 0.398907103336574, 0.28415300383593867, 0.4098360637823741, 0.31147541024320113, 0.33333333243763513, 0.20218579145402857, 0.2185792348098234, 0.48633879846562456, 0.34972677677055525, 0.45901639295406027, 0.5081967193572248, 0.44808743234540593, 0.46994535470269416, 0.2240437156841403, 0.2185792348098234, 0.2185792348098234]
accuracy_4 = [0.40437158551372465, 0.42622950640532486, 0.3333333330076249, 0.37158470026782303, 0.34972677432774196, 0.3879781428907738, 0.41530054726235854, 0.3825136620164569, 0.40437158421089087, 0.33879781257910807, 0.4316939871167876, 0.3005464464588895, 0.4153005448195452, 0.37158470026782303, 0.43169398744249604, 0.3879781428907738, 0.4918032770599824, 0.3770491798393062, 0.36065573851918914, 0.40983606524806204, 0.34972677432774196, 0.3825136620164569, 0.43715846945679254, 0.33879781257910807, 0.2896174860130894]
accuracy_5 = [0.4098360650852078, 0.32240437068900124, 0.2677595625158216, 0.3551912576448722, 0.34972677432774196, 0.33879781257910807, 0.2896174854430996, 0.16939890694097093, 0.21311475450549622, 0.16939890694097093, 0.18579234956392174, 0.322404371258991, 0.2732240428201488, 0.16393442606665398, 0.16393442606665398, 0.16393442606665398, 0.16393442606665398, 0.20765027232834551, 0.2459016391814081, 0.344262293453425, 0.36612021825352653, 0.3333333317047911, 0.2622950823743487, 0.29508196558457256, 0.36612021695069275]
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALLIDB+DEMIR test set using dropout = 0.1')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [2.693069448887976, 2.445639513880829, 1.5264840842596168, 3.687286736535244, 13.211553485015703, 7.508834510553078, 2.0336895028098683, 5.044724094411714, 5.43851774507533, 2.075048256441544, 2.1385259042020706, 5.390591712597289, 7.164734777857046, 2.514674614036018, 3.2270294825236, 3.5917224050219594, 3.6670769068712743, 2.0261667504336667, 3.9444809702576182, 1.566264915987442, 2.197381642346825, 2.415804791971634, 8.328926451219235, 3.5626277376393802, 4.779072834494335]
loss_2 = [2.9692387072766415, 12.012846623613536, 1.649860044646133, 1.4674840357785668, 1.3200442647673394, 2.145025595289762, 1.4319287460358416, 1.8532926235042635, 2.095233674909248, 4.636460521833492, 8.676289094601824, 1.474983466778948, 1.8587807052122438, 3.4879846299280888, 7.309061673169579, 5.212392507355069, 8.182637378817699, 8.734810743175569, 10.344753901163736, 2.880767439232498, 11.374264618086684, 10.13387480459578, 4.3767357471862125, 11.504029967094379, 5.6302411881952334]
loss_3 = [1.674820255060665, 1.7475495638091707, 2.183867806293925, 1.3016242414224344, 1.5561471721513676, 0.9989523021249823, 1.5557685132886543, 1.0598316329424498, 1.7246832235263345, 1.4612445694501284, 2.642239640970699, 1.471368241831253, 1.7686277504175738, 1.4559538318811218, 2.558892194039183, 3.8710453940219565, 1.508767593102377, 2.1236824429100327, 1.6026765564100338, 1.633855465982781, 1.9350986233174474, 1.2805477042015785, 2.90181428617467, 7.150691326850099, 4.758724587862609]
loss_4 = [2.3558383092202777, 1.5639879436440807, 6.679869258338637, 2.547241450658913, 2.123357041937406, 1.9811242773233215, 1.4370178642168723, 1.3562876324836022, 1.2631895704998997, 1.8191496622366983, 1.26777527566816, 2.8301180307982396, 4.187960145251998, 2.2983859705794702, 1.455769529759558, 1.1847661095238775, 1.1081563051932497, 1.356420741706598, 1.6526435040385345, 1.8817756840440094, 2.134313892145626, 1.4041895859879874, 1.210930436035323, 1.6860090279188313, 2.235162222971682]
loss_5 = [2.9577671856176657, 2.336709148896848, 5.103659317141673, 3.7182937463124595, 2.4316580074081005, 2.778043352189611, 2.194022602070876, 3.469565215657969, 2.3138893302021133, 3.2571146449104686, 2.9738535581390715, 2.072636576949573, 2.2290956739519463, 2.5147051967558314, 3.198095474086824, 3.5725365284362125, 5.8186263543009105, 12.771168547249882, 2.3017979176318057, 1.3963708988304346, 1.4631442346208083, 1.4160902571808445, 1.759385286133146, 1.715069917381787, 1.3689282546277906]
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALLIDB+DEMIR test set using dropout = 0.1')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.4016393439365866, 0.45628415333117295, 0.4275956280895921, 0.4713114763869614, 0.47267759513985264, 0.43852459032678864, 0.42759562857815475, 0.44262295098252635, 0.4863387981399161, 0.48907103759994924, 0.4822404366699073, 0.4713114749212734, 0.4508196718054391, 0.4603825131726395, 0.4781420760141696, 0.4726775949769984, 0.48633879797706187, 0.5286885241016013, 0.5122950816415047, 0.5054644812000254, 0.4603825136612022, 0.4726775949769984, 0.46857923464696916, 0.46174863387978143, 0.4603825139869106]
acc_train_2 = [0.37021857890926424, 0.452185792512581, 0.4426229508196721, 0.44672131147540983, 0.43715846945679254, 0.4562841531683187, 0.4658469946983734, 0.4617486332283645, 0.4972677595628415, 0.495901639832825, 0.4644808733398146, 0.4713114754098361, 0.46994535551696526, 0.48770491754422424, 0.4672131147540984, 0.4590163944197483, 0.4808743171027449, 0.4945355194513915, 0.5396174856873809, 0.46857923464696916, 0.4931693984185412, 0.5177595625158216, 0.550546449064557, 0.5478142078131274, 0.4562841539825898]
acc_train_3 = [0.3866120215322151, 0.4084699463323166, 0.44535519076826796, 0.46311475312123535, 0.4385245906524971, 0.4767759559584446, 0.4754098354141569, 0.4672131144283899, 0.4631147544240691, 0.47950819672131145, 0.43989071005680525, 0.4918032780371077, 0.5109289617486339, 0.508196720985767, 0.48770491770707847, 0.4890710379256577, 0.5122950822929215, 0.5546448080917525, 0.5259562851301308, 0.5314207660044478, 0.5259562839901513, 0.51775956284153, 0.504098360167175, 0.5109289619114881, 0.5163934426229508]
acc_train_4 = [0.3907103825136612, 0.4180327870481001, 0.463114755075486, 0.4535519120797433, 0.438524589838226, 0.4658469950240818, 0.45491803278688525, 0.45355191273116024, 0.4795081970470199, 0.5204918032786885, 0.5300546441573263, 0.5027322397857416, 0.47404371519557764, 0.463114753609798, 0.476775956284153, 0.48497267726992, 0.4849726775956284, 0.4590163944197483, 0.49726775891142466, 0.4726775956284153, 0.4999999990228747, 0.4822404366699073, 0.5150273217529547, 0.5300546444830347, 0.532786886223027]
acc_train_5 = [0.40163934458800354, 0.3934426232765281, 0.42622950721959596, 0.40710382529946626, 0.4098360658994789, 0.46994535470269416, 0.44125683068252003, 0.4672131147540984, 0.4644808738283772, 0.46584699486122755, 0.48770491803278687, 0.4918032786885246, 0.44945355158685985, 0.4918032786885246, 0.48224043732132416, 0.4795081970470199, 0.5245901629573009, 0.49726775988855, 0.48497267710706576, 0.4713114754098361, 0.47404371617270297, 0.4808743162884738, 0.5204918034415428, 0.508196720985767, 0.5136612021857924]

avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)

plt.plot(x_values, acc_train_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, acc_train_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, acc_train_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, acc_train_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, acc_train_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALLIDB+DEMIR train set using dropout = 0.1')
plt.legend(loc='best')
plt.show() 
'''

# ---------------------------------------------------------------------- 


# Data aug results with color 
'''
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.19945355215684965, 0.30601092904317573, 0.29508196770167744, 0.254098360900019, 0.254098360900019, 0.23224043740275127, 0.42349726792241704, 0.40710382562517466, 0.3387978143705045, 0.3661202186606621, 0.6338797807693481, 0.40710382529946626, 0.5409836068830854, 0.6885245908153513, 0.3169398907918096, 0.7021857930011437, 0.48360655705134076, 0.650273223392299, 0.7377049186842037, 0.7349726769442115, 0.6666666673180836, 0.7404371587956537, 0.7568306004414793, 0.7732240430644302, 0.7704918023015632]
accuracy_2 = [0.2213114755726903, 0.2240437163355572, 0.29508196770167744, 0.34699453584483414, 0.34699453584483414, 0.34699453584483414, 0.42349726792241704, 0.42349726792241704, 0.42349726792241704, 0.40710382529946626, 0.40710382529946626, 0.3114754095103571, 0.3196721314732494, 0.37978142109073576, 0.3469945356819799, 0.4071038254623205, 0.40710382529946626, 0.3743169399721375, 0.42622950827814843, 0.48633879797706187, 0.48633879797706187, 0.5819672127890456, 0.5819672131147541, 0.6666666673180836, 0.6666666673180836]
accuracy_3 = [0.330601092977602, 0.5054644810371711, 0.2213114756541174, 0.39344262343938236, 0.42349726784098995, 0.237704918114214, 0.15573770504017345, 0.19125683084537423, 0.25136612046286055, 0.3989071043136993, 0.25956284161148174, 0.27049180336011563, 0.22131147553197672, 0.469945355354111, 0.3005464481688588, 0.21311475417978776, 0.467213115242661, 0.5765027319147287, 0.6256830607607065, 0.5765027319147287, 0.5765027319147287, 0.5765027319147287, 0.6256830607607065, 0.6256830607607065, 0.6256830607607065]
accuracy_4 = [0.24590163966997072, 0.46174863436834407, 0.21038251414976486, 0.2786885250787266, 0.3852459018021985, 0.3060109294503113, 0.37704918049072306, 0.21584699502408178, 0.38797814223935695, 0.42896174863387976, 0.2814207655158851, 0.31420765035465115, 0.17486338846670474, 0.2814207655158851, 0.23224043764703262, 0.39344262343938236, 0.2786885248344453, 0.4480874326711144, 0.286885246390202, 0.44262295098252635, 0.52732240534871, 0.28142076527160376, 0.513661202674355, 0.32786885278472483, 0.5519125692831363]
accuracy_5 = [0.24863388026998343, 0.3224043719104079, 0.18852459065249708, 0.1748633880595692, 0.18852459040821576, 0.34153005480766296, 0.23497267792133686, 0.319672131147541, 0.5601092902689032, 0.3879781424022112, 0.23224043764703262, 0.286885246390202, 0.43169398923389246, 0.37978142109073576, 0.39890710415084507, 0.461748633554073, 0.31693989071038253, 0.6065573777005973, 0.30601092912460287, 0.30601092912460287, 0.3087431693989071, 0.6092896181377557, 0.6229508196721312, 0.6420765020808236, 0.6830601086382007]
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALLIDB+DEMIR test set using data augmentation')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [8.237075253262546, 4.214488365611092, 2.843353744413032, 2.777915486872522, 3.0665933994647583, 3.019416289251359, 2.3411985733469978, 1.4329527935695128, 1.9943192200582536, 1.6515689515025238, 1.0478871705753556, 2.1200136213354726, 1.6362853219600324, 0.8581300224762797, 2.6299128623608032, 1.1138479028894601, 2.7265484938856033, 1.3558720187411282, 0.979927122592926, 0.9351704097836395, 1.3013485552834683, 0.8565824758159658, 0.83139262629337, 0.7965486111536704, 0.7417350233904]
loss_2 = [3.2671777309615755, 3.387500558394552, 4.542758541680425, 5.246765785529965, 3.2684443296630525, 3.4019499776141893, 5.042505980840797, 3.7063550258594784, 3.7960164468796527, 4.8827836096612485, 6.674751273921279, 4.840113734938408, 4.16175356458445, 3.514829291672003, 4.611058137455925, 3.7126027756049984, 4.703378570535795, 4.912336344275969, 4.3236264465936545, 4.2711408542153615, 3.3503408940112003, 2.144147477514757, 2.27299228001162, 3.2548379702646226, 2.7549868828611945]
loss_3 = [2.479071217156499, 1.2267592142188484, 2.3344549520419595, 1.7408282457153654, 1.1722081769359567, 3.659409259837833, 8.536896653514091, 12.340791874244564, 3.866610110131769, 2.712734472556192, 3.5107986679494054, 2.986141639980462, 3.587856060820199, 2.1034373598672, 5.459834361988339, 6.171023923842633, 1.7343187514550047, 1.212948825841393, 1.2673501701302867, 1.2673501701302867, 2.451446593133478, 2.451446593133478, 2.451446593133478, 2.0910516006699025, 1.2673501701302867]
loss_4 = [1.6949259277249946, 1.095904315755667, 3.1281084362926377, 2.8984954161722154, 1.9147140647544236, 2.026454093026333, 2.833657018473891, 5.1458560677825425, 3.4602869977065125, 1.4764593637706152, 2.9155551735820664, 2.7407178370679013, 9.076099838715434, 2.9804788560815196, 4.269890032179369, 1.720219045388894, 1.9341673447134717, 1.8516891686642756, 2.328793171976433, 1.92672635557873, 1.322305004779107, 5.108778299529696, 2.3892716084673107, 4.351258806843576, 1.6458825732840867]
loss_5 = [3.6804772087785063, 1.9205147770584607, 4.317218721890058, 4.78913609447375, 7.85103136854745, 3.4783744056368135, 5.260141119930913, 4.769541021253242, 1.8088860414067254, 2.430856685169408, 8.006265655892793, 8.424693347326393, 7.006577494365922, 6.408375578499883, 8.102024714152018, 3.389709638116138, 6.554722840668725, 1.1357848553058227, 5.054746552243259, 6.2404390319449, 5.762422981157981, 1.3627078171636238, 1.213093126406435, 1.3860952205996695, 1.3945328023264316]
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALLIDB+DEMIR test set using data augmentation')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.40710382529946626, 0.4931693989071038, 0.6120218582492057, 0.6297814210907358, 0.6605191256830601, 0.7062841530054644, 0.7459016390185539, 0.8039617483081714, 0.85450819704702, 0.8770491800021604, 0.8989071038251366, 0.9036885245901639, 0.9255464484131402, 0.935109289291778, 0.947404371258991, 0.9467213114754098, 0.9562841526797561, 0.9569672131147541, 0.9637978138819419, 0.9658469942098107, 0.9603825133354937, 0.9760928961748634, 0.9774590163934426, 0.9822404374841784, 0.9733606554119965]
acc_train_2 = [0.40915300546448086, 0.5218579231715593, 0.5648907100568052, 0.6120218579234973, 0.6980874320196975, 0.7383879778163681, 0.8012295081967213, 0.8142076502732241, 0.8702185795606812, 0.9023224040458763, 0.9036885242644555, 0.9153005464480874, 0.9405737708175117, 0.9556010928961749, 0.9651639344262295, 0.953551912568306, 0.9590163934426229, 0.9556010932218834, 0.9624316943147795, 0.9733606554119965, 0.9781420765027322, 0.9760928958491549, 0.9842896171606303, 0.974043716172703, 0.9692622954076756]
acc_train_3 = [0.43169398907103823, 0.5170765030579488, 0.6099726779213368, 0.6653005467737959, 0.6980874320196975, 0.7650273224043715, 0.7479508196721312, 0.773224043715847, 0.7957650269966959, 0.8469945358448341, 0.892076502406532, 0.9289617486338798, 0.9371584702710636, 0.9228142076502732, 0.9419398903846741, 0.9569672127890456, 0.9549180327868853, 0.9658469945355191, 0.9836065573770492, 0.9596994535519126, 0.9016393442622951, 0.8688524590163934, 0.7862021861180581, 0.8975409836065574, 0.9398907100568052]
acc_train_4 = [0.40368852467159105, 0.5245901642601347, 0.5642076499475156, 0.6673497267759563, 0.7267759566098615, 0.756147541309315, 0.8258196718054391, 0.8183060112546702, 0.8333333330076249, 0.8872950816415047, 0.909836065248062, 0.8285519122425976, 0.7015027322404371, 0.7984972674338544, 0.8531420765027322, 0.8825136612021858, 0.9207650276481129, 0.9405737708175117, 0.9549180327868853, 0.9508196721311475, 0.9713114754098361, 0.9706284153005464, 0.97950819704702, 0.9842896171606303, 0.980191256830601]
acc_train_5 = [0.4241803281945609, 0.5689890710382514, 0.6659836065573771, 0.7704918032786885, 0.8709016390185539, 0.9392076499475156, 0.9692622947562588, 0.9808743169398907, 0.9829234972677595, 0.9897540980349473, 0.9788251362863134, 0.9870218579234973, 0.9883879778163681, 0.9911202185792349, 0.9931693989071039, 0.9918032786885246, 0.9897540980349473, 0.9918032786885246, 0.9938524590163934, 0.9959016393442623, 0.9965846994535519, 0.9972677595628415, 0.9965846994535519, 0.9965846994535519, 0.9979508196721312]
avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)

plt.plot(x_values, acc_train_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, acc_train_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, acc_train_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, acc_train_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, acc_train_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALLIDB+DEMIR train set using data augmentation')
plt.legend(loc='best')
plt.show() 
'''

# ---------------------------------------------------------------------- 

# Data aug + dropout results with color 
'''
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.3306010932218833, 0.35245901688200526, 0.34972677595628415, 0.284153005545908, 0.3579234974306138, 0.27322404420440966, 0.26502732289293424, 0.2978142081388359, 0.24590163958854364, 0.3743169400535646, 0.3825136612836129, 0.37978142092788153, 0.22404371592842165, 0.3934426232765281, 0.4043715848623078, 0.49453551912568305, 0.366120218579235, 0.34699453600768837, 0.31420765059893246, 0.21038251374262928, 0.3524590163934426, 0.3469945356819799, 0.46448087480550254, 0.3196721312289681, 0.426229508685284]
accuracy_2 = [0.24316939939566648, 0.34426229540767567, 0.2349726776770555, 0.2021857925940081, 0.30054644841314015, 0.21038251390548351, 0.2704918034415427, 0.3142076504360783, 0.2950819672945419, 0.24863387986284788, 0.21584699477980046, 0.3114754099174927, 0.35245901688200526, 0.3196721313103952, 0.3497267762819926, 0.3524590164748697, 0.2486338800257021, 0.26775956292295716, 0.19672131171969118, 0.3005464482502859, 0.3497267764448468, 0.21038251390548351, 0.28961748642022495, 0.22677595636558012, 0.22404371592842165]
accuracy_3 = [0.40437158551372465, 0.42622950640532486, 0.3333333330076249, 0.37158470026782303, 0.34972677432774196, 0.3879781428907738, 0.41530054726235854, 0.3825136620164569, 0.40437158421089087, 0.33879781257910807, 0.4316939871167876, 0.3005464464588895, 0.4153005448195452, 0.37158470026782303, 0.43169398744249604, 0.3879781428907738, 0.4918032770599824, 0.3770491798393062, 0.36065573851918914, 0.40983606524806204, 0.34972677432774196, 0.3825136620164569, 0.43715846945679254, 0.33879781257910807, 0.2896174860130894]
accuracy_4 = [0.4098360650852078, 0.32240437068900124, 0.2677595625158216, 0.3551912576448722, 0.34972677432774196, 0.33879781257910807, 0.2896174854430996, 0.16939890694097093, 0.21311475450549622, 0.16939890694097093, 0.18579234956392174, 0.322404371258991, 0.2732240428201488, 0.16393442606665398, 0.2732240428201488, 0.16393442606665398, 0.344262293453425, 0.322404371258991, 0.2459016391814081, 0.344262293453425, 0.36612021825352653, 0.3333333317047911, 0.2622950823743487, 0.29508196558457256, 0.344262293453425]
accuracy_5 =[0.2677595633300927, 0.24590163983282495, 0.26229508294433845, 0.19672131155683695, 0.25136612070714187, 0.2240437163355572, 0.3633879784677849, 0.2021857925940081, 0.2240437163355572, 0.24316939898853093, 0.3306010932218833, 0.27595628415300544, 0.22950819720987414, 0.20491803327544791, 0.43442622967105093, 0.40710382611373735, 0.20218579283828944, 0.29781420781312745, 0.20765027330547084, 0.3524590163934426, 0.26502732273008, 0.2349726780841911, 0.2076502737126064, 0.25409836098144617, 0.2868852462273478]
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALLIDB+DEMIR test set using data augmentation and dropout')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [1.9124735639394959, 1.491849150162577, 1.6206613062509423, 1.7763082902939593, 1.4106693945295823, 1.7719365208526778, 1.9599538494328983, 2.528447070408389, 2.14491722362289, 1.34158857142339, 1.3810192072977785, 1.5219735369656255, 3.6910256531720607, 1.5605021597909146, 1.147530108853116, 1.0620481293709552, 2.009812682052779, 1.3685353792430273, 2.1360228849890452, 3.8702498290056737, 2.941298591634615, 1.4245978378858724, 1.029655955528301, 2.29507959214716, 1.354418768908808]
loss_2 = [1.8175204562359168, 2.0990693438899974, 3.7527426683186182, 4.174033248359389, 1.6208027868322987, 2.977559014096286, 1.6587762793556589, 1.5436540731315405, 1.9991477460809093, 2.5163104390837456, 3.3763776672342436, 1.51722524661184, 1.2909323068264404, 1.6919341491219775, 1.3898446501278487, 1.4423915688457385, 1.9677825449594384, 1.669082850054965, 3.8313341831248966, 2.162777722207575, 1.2491428884652143, 2.7611073652903237, 2.1209699195590828, 3.0040857896127338, 2.7642081591600927]
loss_3 = [2.3558383092202777, 1.5639879436440807, 6.679869258338637, 2.547241450658913, 2.123357041937406, 1.9811242773233215, 1.4370178642168723, 1.3562876324836022, 1.2631895704998997, 1.8191496622366983, 1.26777527566816, 2.8301180307982396, 4.187960145251998, 2.2983859705794702, 1.455769529759558, 1.1847661095238775, 1.1081563051932497, 1.356420741706598, 1.6526435040385345, 1.8817756840440094, 2.134313892145626, 1.4041895859879874, 1.210930436035323, 1.6860090279188313, 1.8817756840440094]
loss_4 = [2.9577671856176657, 2.336709148896848, 5.103659317141673, 3.7182937463124595, 2.4316580074081005, 2.778043352189611, 2.194022602070876, 3.469565215657969, 2.3138893302021133, 3.2571146449104686, 2.9738535581390715, 2.072636576949573, 2.2290956739519463, 2.5147051967558314, 3.198095474086824, 3.5725365284362125, 5.8186263543009105, 11.771168547249882, 2.3017979176318057, 1.3963708988304346, 1.4631442346208083, 1.4160902571808445, 1.759385286133146, 1.715069917381787, 1.3689282546277906]
loss_5 =[1.9904256850643887, 2.412754628176246, 1.633545983684519, 2.632456066829911, 2.0507777251832473, 3.5366590935024407, 1.3895359234731706, 1.9773204756564782, 4.25107865906804, 3.0496837936463903, 1.4789417747591362, 1.8438085135214968, 4.728841596613816, 4.096316758400755, 1.1627222481972532, 1.4495959900767426, 3.5110590536086286, 3.7064879982849286, 2.97477596314227, 1.4739127015806939, 2.0611919203742604, 2.4583019141942426, 8.113095731683115, 3.0362055835828103, 2.0250444288462237]
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALLIDB+DEMIR test set using data augmentation and dropout')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.32650273215901005, 0.3941256828972551, 0.4050546449715974, 0.4180327870481001, 0.4460382515289744, 0.4726775957912695, 0.49999999983714577, 0.5013661202185792, 0.49658469977926034, 0.4494535519125683, 0.5143442626207904, 0.4972677593999873, 0.5375683063366374, 0.5293715843737451, 0.540300546122379, 0.5628415297289364, 0.5437158466688271, 0.4767759561212988, 0.5129781420765027, 0.4508196719682933, 0.43920765059893246, 0.45355191224259755, 0.5047814206021731, 0.5621584696196468, 0.5744535515868598]
acc_train_2 = [0.34153005464480873, 0.3722677593999873, 0.3866120217764964, 0.38524590163934425, 0.4255464480874317, 0.4596994537147668, 0.44125683092680135, 0.4351092894546321, 0.4528688522961622, 0.4487704919661329, 0.42281420781312745, 0.39685792366012196, 0.4105191258459143, 0.42691256830601093, 0.43237704901747365, 0.47950819672131145, 0.47267759595412373, 0.4672131147540984, 0.42349726759670864, 0.45081967229400177, 0.44603825136612024, 0.4487704918032787, 0.4583333333333333, 0.4815573767234719, 0.44603825136612024]
acc_train_3 = [0.24590163966997072, 0.46174863436834407, 0.21038251414976486, 0.2786885250787266, 0.3852459018021985, 0.3060109294503113, 0.37704918049072306, 0.21584699502408178, 0.38797814223935695, 0.42896174863387976, 0.2814207655158851, 0.31420765035465115, 0.17486338846670474, 0.2814207655158851, 0.23224043764703262, 0.39344262343938236, 0.2786885248344453, 0.4480874326711144, 0.286885246390202, 0.44262295098252635, 0.52732240534871, 0.28142076527160376, 0.513661202674355, 0.32786885278472483, 0.5519125692831363]
acc_train_4 =  [0.40163934458800354, 0.3934426232765281, 0.42622950721959596, 0.40710382529946626, 0.4098360658994789, 0.46994535470269416, 0.44125683068252003, 0.4672131147540984, 0.4644808738283772, 0.46584699486122755, 0.48770491803278687, 0.4918032786885246, 0.44945355158685985, 0.4918032786885246, 0.48224043732132416, 0.4795081970470199, 0.5245901629573009, 0.49726775988855, 0.48497267710706576, 0.4713114754098361, 0.47404371617270297, 0.4808743162884738, 0.5204918034415428, 0.508196720985767, 0.5204918034415428]
acc_train_5 = [0.344945355354111, 0.3920765025693862, 0.39617486338797814, 0.41188524590163933, 0.4357923500524844, 0.43101092912460287, 0.4077868852459016, 0.405054644645889, 0.4378415298917906, 0.4521857923497268, 0.47062841530054644, 0.47404371584699456, 0.4583333333333333, 0.48019125666774687, 0.5047814206021731, 0.5307377049180327, 0.5437158469945356, 0.560109289291778, 0.4931693989071038, 0.48292349710490534, 0.4993169402164188, 0.546448087431694, 0.5129781417507943, 0.5409836068830854, 0.5963114755726903]
avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)

plt.plot(x_values, acc_train_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, acc_train_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, acc_train_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, acc_train_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, acc_train_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALLIDB+DEMIR train set using data augmentation and dropout')
plt.legend(loc='best')
plt.show() 
'''

# ---------------------------------------------------------------------- 

# 200X200
'''
# Accuracy 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
accuracy_1 = [0.22404371625413008, 0.28415300513877245, 0.22404371421845232, 0.322404371258991, 0.3278688508304742, 0.4972677624942175, 0.4371584692939383, 0.44808742990259265, 0.27322404322728433, 0.27868852540443506, 0.21311475320266243, 0.2349726766999302, 0.2896174847102556, 0.24590163901855386, 0.47540983280848936, 0.4480874310425722, 0.4808743175913076, 0.37158469896498925, 0.4480874310425722, 0.39344262360223653, 0.4316939871167876, 0.4153005470995043, 0.4480874297397384, 0.4972677624942175, 0.6502732230665905]
accuracy_2 = [0.4207650255310079, 0.31147540918464867, 0.21857923464696916, 0.322404371258991, 0.22950819655845725, 0.322404371258991, 0.322404371258991, 0.2240437156841403, 0.4699453558426737, 0.5027322384829078, 0.4699453558426737, 0.5027322384829078, 0.5464480854774434, 0.5081967193572248, 0.4972677576085909, 0.5191256824086924, 0.42622950640532486, 0.44808743234540593, 0.33333333398475024, 0.5081967242428513, 0.633879784352141, 0.5464480841746095, 0.5683060099518364, 0.6502732230665905, 0.6775956293924259]
accuracy_3 = [0.2349726774327742, 0.30054644873884856, 0.2240437155212861, 0.2185792333441354, 0.3333333341476044, 0.2568306007671877, 0.20218579218687255, 0.20218579218687255, 0.37704918114214, 0.28961748585023517, 0.2076502730611895, 0.33879781502192136, 0.3770491798393062, 0.3224043723989706, 0.5081967219628923, 0.3224043723989706, 0.41530054726235854, 0.4644808725255435, 0.26229508164150467, 0.3661202180906723, 0.4863387960228112, 0.4808743175913076, 0.5409836046031264, 0.5245901632830093, 0.5628415267975604]
accuracy_4 = [0.14754098401369292, 0.36612021825352653, 0.43715847075962627, 0.14754098401369292, 0.20218579275686233, 0.2513661206257148, 0.42076502569386215, 0.2513661206257148, 0.2622950823743487, 0.2677595632486656, 0.3333333317047911, 0.3278688515633182, 0.29508196631741657, 0.21311475450549622, 0.1584699457623268, 0.38797814044796053, 0.3169398911175181, 0.41530054726235854, 0.26775956267867584, 0.2568306007671877, 0.464480875131211, 0.486338797325645, 0.46994535470269416, 0.5355191250316432, 0.5409836059059602]
accuracy_5 = [0.3989071020337402, 0.40437158290805714, 0.40437158290805714, 0.20218579186116412, 0.3169398889189861, 0.21857923448411493, 0.22404371535843187, 0.31147541048748245, 0.4098360650852078, 0.4207650266709875, 0.3278688532732875, 0.3278688518075995, 0.3278688532732875, 0.5081967219628923, 0.5136612003943959, 0.26775956219011315, 0.3169398913617994, 0.39344262246225703, 0.53005464546016, 0.5355191237288095, 0.5956284182319225, 0.5300546477401191, 0.5464480867802771, 0.601092892917779, 0.5683060089747111]
avg_acc = createListToAverage(accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5)

plt.plot(x_values, accuracy_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, accuracy_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, accuracy_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, accuracy_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, accuracy_5, label="Run 5", linewidth=0.5)  

plt.plot(x_values, avg_acc, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB1 test set using larger rescale (200x200)')
plt.legend(loc='best')
plt.show()


# Loss 
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
loss_1 = [10.768433414521764, 2.728190145857347, 3.599143654922319, 2.5438487177989524, 2.7181677909496704, 2.5113882881696106, 2.765125798397377, 2.046702894356733, 2.414267214269586, 1.9599375522853246, 5.396904265294309, 2.9577271651700547, 1.9862142872940647, 3.0866736610079073, 2.338773889619796, 1.2611458425313398, 1.2029495135031112, 1.7801925647454184, 8.900011385724843, 1.7801925647454184, 3.953296523276574, 2.5786344249391817, 1.8208015622988425, 3.570555835473733, 0.9765434971924036]
loss_2 = [3.2030807244973105, 6.992905275417807, 5.6510124154429615, 9.528641101441096, 8.690435492927259, 12.378743791840767, 6.9342199752891, 5.111359830762519, 3.332171672028922, 1.5593287925251196, 2.10382980336257, 2.0791763790318223, 1.7873786850705173, 1.771910959254197, 1.9132431752043344, 2.1450795736469206, 2.1609528260152846, 1.8956005690527744, 2.4683481428792566, 1.7967387056741557, 2.3070219442492625, 1.8677465120951335, 1.3735711968661657, 1.3683351167564184, 1.3683351167564184]
loss_3 = [6.982764249290925, 2.4976322833306153, 7.389445471633327, 4.405121760290177, 3.974306649849063, 6.757576801737801, 8.100920744932415, 8.008100624292926, 2.9022461416942824, 4.277194156021368, 2.781916751236212, 5.690210566494634, 7.364306178900714, 4.312062262185936, 1.4820703000970226, 1.7472478301147294, 2.4502056413660935, 1.828638424638842, 3.9949452942186365, 2.8641484786903924, 1.9642639336038807, 2.6715053339473536, 1.0752299952376736, 1.2805339729851062, 1.6598507224536332]
loss_4 = [8.46061260973821, 5.037586545683647, 3.061820978675384, 11.623473433197521, 4.372254989186271, 10.731359403641498, 3.649572247364482, 9.742947797306249, 7.70705006813091, 4.5843042441404585, 5.75194302543265, 5.858735029814674, 3.908939530940655, 6.652265475747364, 11.298435539495749, 5.430110811535778, 2.6341181791545263, 4.51866816692665, 3.489970221545527, 4.372702030536256, 4.1831274631896305, 1.6307326724620466, 3.07607770487259, 1.599168863452849, 1.4559232615382294]
loss_5 = [5.005561841641619, 5.2643351997834085, 3.643981794190537, 6.370445652737644, 2.369212275645772, 3.343487942805056, 2.531298481701502, 1.8953304349399003, 1.6770585892630405, 2.39603166958022, 2.545932966503289, 1.927772379312359, 3.3168693956781605, 2.177898044794635, 1.50958575446749, 2.72274558856839, 2.3939634509425347, 2.1502381354733244, 1.8375175298888826, 1.4503503588379407, 1.2271838741875738, 1.4286890388186513, 1.5995898031797566, 1.108480113451598, 1.0412174684753834]
avg_loss = createListToAverage(loss_1, loss_2, loss_3, loss_4, loss_5)

plt.plot(x_values, loss_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, loss_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, loss_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, loss_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, loss_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_loss, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.ylim(0, 12)
plt.title('Model loss on ALL-IDB1 test set using larger rescale (200x200)')
plt.legend(loc='best')
plt.show()


# Accuracy train
x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
acc_train_1 = [0.4562841523540476, 0.5560109283103317, 0.6967213104982846, 0.7500000009771253, 0.7800546457858685, 0.8456284156262549, 0.8729508193464227, 0.9098360662251874, 0.9726775956284153, 0.9822404368327615, 0.9890710382513661, 0.994535519125683, 0.9986338797814208, 0.9972677602142584, 0.9931693989071039, 0.9959016393442623, 0.9986338797814208, 0.9986338797814208, 0.9877049170556615, 0.9972677602142584, 0.9972677595628415, 0.9918032786885246, 0.994535519125683, 0.9972677595628415, 0.9972677595628415]
acc_train_2 = [0.4562841530054645, 0.5560109283103317, 0.6775956293924259, 0.7472677605399669, 0.8360655731190749, 0.9153005464480874, 0.9453551902797053, 0.97267759465129, 0.9781420765027322, 0.994535519125683, 0.9918032793399415, 0.9918032786885246, 0.9972677595628415, 0.9972677602142584, 0.9959016399956792, 0.9986338797814208, 0.9959016393442623, 0.9986338797814208, 0.9972677595628415, 0.9972677595628415, 0.9972677595628415, 0.9986338797814208, 0.9972677595628415, 0.9972677595628415, 0.9986338797814208]
acc_train_3 = [0.4439890707125429, 0.6461748633879781, 0.7691256833858178, 0.8852459019650527, 0.9180327878623712, 0.9603825136612022, 0.9890710382513661, 0.9808743169398907, 0.9877049180327869, 0.9918032786885246, 0.9849726775956285, 0.9959016393442623, 0.9918032786885246, 0.9931693989071039, 0.9972677595628415, 0.9959016399956792, 0.9972677595628415, 0.9959016393442623, 0.9972677595628415, 0.9972677595628415, 0.9959016393442623, 0.9972677595628415, 0.9959016393442623, 0.9959016393442623, 0.9931693995585207]
acc_train_4 = [0.4084699455180455, 0.6270491809792857, 0.7377049170556615, 0.8019125692831363, 0.856557376072055, 0.9303278698295844, 0.9426229508196722, 0.9767759569355698, 0.9849726775956285, 0.9877049180327869, 0.994535519125683, 0.9890710382513661, 0.9904371584699454, 0.9877049180327869, 0.9808743169398907, 0.9931693989071039, 0.9972677595628415, 0.9959016393442623, 0.9959016393442623, 0.9972677595628415, 0.9959016393442623, 0.9959016393442623, 0.9972677595628415, 0.994535519125683, 0.9972677595628415]
acc_train_5 = [0.4234972682481255, 0.5696721321246663, 0.647540982629432, 0.7882513654688017, 0.8101092896174863, 0.9330601092896175, 0.9781420771541491, 0.994535519125683, 0.9918032786885246, 0.9959016393442623, 0.9986338797814208, 0.9972677595628415, 0.9959016393442623, 0.9972677595628415, 0.9959016393442623, 0.9986338797814208, 0.9986338797814208, 0.9972677595628415, 0.9986338797814208, 0.9986338797814208, 0.9986338797814208, 0.9986338797814208, 0.9986338804328376, 0.9986338797814208, 0.9986338797814208]
avg_acc_train = createListToAverage(acc_train_1, acc_train_2, acc_train_3, acc_train_4, acc_train_5)

plt.plot(x_values, acc_train_1, label="Run 1", linewidth=0.5)
plt.plot(x_values, acc_train_2, label="Run 2", linewidth=0.5)
plt.plot(x_values, acc_train_3, label="Run 3", linewidth=0.5) 
plt.plot(x_values, acc_train_4, label="Run 4", linewidth=0.5) 
plt.plot(x_values, acc_train_5, label="Run 5", linewidth=0.5)  
plt.plot(x_values, avg_acc_train, label="Average", linewidth=4,
         marker='h', markerfacecolor='red', markeredgewidth=2,
         markersize=12, markevery=3, color='black')

plt.ylabel('Accuracy (%)')
plt.xlabel('Epochs')
plt.ylim(0, 1.1)
plt.title('Model accuracy on ALL-IDB1 train set using larger rescale (200x200)')
plt.legend(loc='best')
plt.show()
'''